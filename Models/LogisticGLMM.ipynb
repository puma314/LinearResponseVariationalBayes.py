{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'mu_prior_mean', 'beta_prior_var', 'mu_prior_epsilon', 'mu_prior_var', 'NG', 'tau_prior_alpha', 'y', 'y_group', 'beta_prior_mean', 'mu_prior_var_c', 'tau_prior_beta', 'mu_prior_t', 'K', 'N', 'mu_prior_mean_c'])\n",
      "0.171046565237\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "    analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    json_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    stan_dat = json_dat['stan_dat']\n",
    "    vp_base = json_dat['vp_base']\n",
    "\n",
    "    print(stan_dat.keys())\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    #N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    glmm_par = logit_glmm.get_glmm_parameters(\n",
    "        K=K, NG=NG, \n",
    "        mu_info_min=vp_base['mu_info_min'][0],\n",
    "        tau_alpha_min=vp_base['tau_alpha_min'][0],\n",
    "        tau_beta_min=vp_base['tau_beta_min'][0],\n",
    "        beta_diag_min=vp_base['beta_diag_min'][0],\n",
    "        u_info_min=vp_base['u_info_min'][0])\n",
    "\n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    prior_par['beta_prior_mean'].set(np.array(stan_dat['beta_prior_mean']))\n",
    "\n",
    "    beta_prior_info = np.linalg.inv(np.array(stan_dat['beta_prior_var']))\n",
    "    prior_par['beta_prior_info'].set(beta_prior_info)\n",
    "\n",
    "    prior_par['mu_prior_mean'].set(stan_dat['mu_prior_mean'][0])\n",
    "    prior_par['mu_prior_info'].set(1 / stan_dat['mu_prior_var'][0])\n",
    "    \n",
    "    prior_par['tau_prior_alpha'].set(stan_dat['tau_prior_alpha'][0])\n",
    "    prior_par['tau_prior_beta'].set(stan_dat['tau_prior_beta'][0])\n",
    "    \n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(\n",
    "        K=K, NG=NG, \n",
    "        mu_info_min=0.001, tau_alpha_min=0.001,\n",
    "        tau_beta_min=0.001, beta_diag_min=0.001,\n",
    "        u_info_min=0.001)\n",
    "\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "glmm_init = False\n",
    "if glmm_init and not simulate_data:\n",
    "    # Initialize with GLMM.\n",
    "    # If you use this, don't forget to add the computation time to your final VB time!\n",
    "    glmm_time = 0.\n",
    "\n",
    "    glmm_fit = json_dat['glmm_fit']\n",
    "    glmm_par['mu'].mean.set(glmm_fit['mu_mean'][0])\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    tau_mean = 1.0 / glmm_fit['mu_sd'][0] ** 2\n",
    "    tau_var = 1.0\n",
    "    glmm_par['tau'].shape.set((tau_mean ** 2) / tau_var)\n",
    "    glmm_par['tau'].rate.set(tau_var / tau_mean)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.array(glmm_fit['beta_mean']))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.array(glmm_fit['u_map']))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "    free_par_vec = glmm_par.get_free()\n",
    "else:\n",
    "    glmm_time = 0.\n",
    "    glmm_par['mu'].mean.set(0.0)\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    glmm_par['tau'].shape.set(2.0)\n",
    "    glmm_par['tau'].rate.set(2.0)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.full(K, 0.0))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.full(NG, 0.0))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.014363089499966009\n",
      "\tGrad time: 0.04709802970000965\n",
      "\tHessian vector product time: 0.07263983820002977\n",
      "\tPrior hess time:  0.10903358459472656\n"
     ]
    }
   ],
   "source": [
    "# Define moment parameters\n",
    "\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector)\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "def get_e_log_prior(prior_vec, free_par):\n",
    "    model.glmm_par.set_free(free_par)\n",
    "    model.prior_par.set_vector(prior_vec)\n",
    "    return model.get_e_log_prior()\n",
    "\n",
    "get_prior_model_grad = autograd.grad(get_e_log_prior, argnum=0)\n",
    "get_prior_hess = autograd.jacobian(get_prior_model_grad, argnum=1)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "def tr_optimize(trust_init, num_gh_points, gtol=1e-6, maxiter=500):\n",
    "    model.set_gh_points(num_gh_points)\n",
    "    objective.logger.initialize()\n",
    "    objective.logger.print_every = 5\n",
    "    vb_opt = optimize.minimize(\n",
    "        lambda par: objective.fun_free(par, verbose=True),\n",
    "        x0=trust_init,\n",
    "        method='trust-ncg',\n",
    "        jac=objective.fun_free_grad,\n",
    "        hessp=objective.fun_free_hvp,\n",
    "        tol=1e-6, options={'maxiter': maxiter, 'disp': True, 'gtol': gtol })\n",
    "    return vb_opt.x\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#print(glmm_par)\n",
    "\n",
    "x_t_x = np.matmul(x_mat.transpose(), x_mat)\n",
    "x_t_y = np.matmul(x_mat.transpose(), y_vec)\n",
    "beta_init = np.linalg.solve(x_t_x, x_t_y)\n",
    "#print(beta_init)\n",
    "#plt.plot(sp.special.expit(np.matmul(x_mat, beta_init)), y_vec, 'k.')\n",
    "\n",
    "df = pd.DataFrame({ 'y_g': y_g_vec, 'y': y_vec}).groupby('y_g')\n",
    "#print(df.sum())\n",
    "u_init = np.array(df.sum()) / np.array(df.count()['y'])\n",
    "#plt.figure()\n",
    "print(np.min(y_g_vec))\n",
    "#plt.plot(u_init[y_g_vec], y_vec, 'k.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region with few draws.\n",
      "Iter  0  value:  [ 34731.73676621]\n",
      "\tx_diff:  inf\n",
      "Iter  5  value:  [ 7447.76860784]\n",
      "\tx_diff:  0.0290850879322\n",
      "Iter  10  value:  [ 5517.80221738]\n",
      "\tx_diff:  1.48214832455\n",
      "Iter  15  value:  [ 4794.34373636]\n",
      "\tx_diff:  0.0101254725636\n",
      "Iter  20  value:  [ 4714.57602913]\n",
      "\tx_diff:  0.000254108658268\n",
      "Iter  25  value:  [ 4712.79381746]\n",
      "\tx_diff:  0.294464237807\n",
      "Iter  30  value:  [ 4711.63658791]\n",
      "\tx_diff:  13.55352292\n",
      "Iter  35  value:  [ 4710.64509092]\n",
      "\tx_diff:  0.375605370898\n",
      "Iter  40  value:  [ 4714.66843535]\n",
      "\tx_diff:  14.543680558\n",
      "Iter  45  value:  [ 4709.35471338]\n",
      "\tx_diff:  8.9425166127\n",
      "Iter  50  value:  [ 4709.08628814]\n",
      "\tx_diff:  9.92595160522\n",
      "Iter  55  value:  [ 4708.89310118]\n",
      "\tx_diff:  0.0709237426232\n",
      "Iter  60  value:  [ 4708.65398027]\n",
      "\tx_diff:  18.5187143881\n",
      "Iter  65  value:  [ 4708.38781363]\n",
      "\tx_diff:  0.0303124203249\n",
      "Iter  70  value:  [ 4707.98363453]\n",
      "\tx_diff:  0.0193929017615\n",
      "Iter  75  value:  [ 4707.82585855]\n",
      "\tx_diff:  4.06480536964\n",
      "Iter  80  value:  [ 4707.74705619]\n",
      "\tx_diff:  2.47392410999\n",
      "Iter  85  value:  [ 4707.69354878]\n",
      "\tx_diff:  6.63577827042\n",
      "Iter  90  value:  [ 4707.6932215]\n",
      "\tx_diff:  0.000120886601266\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 4707.693221\n",
      "         Iterations: 90\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 87\n",
      "         Hessian evaluations: 0\n",
      "VB time:  212.6690697669983\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region with few draws.')\n",
    "num_gh_points = 4\n",
    "vb_time = time.time()\n",
    "opt_x = tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=200)\n",
    "vb_time_opt_1 = time.time() - vb_time\n",
    "#print('vb_time_opt_1: ', vb_time_opt_1)\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "# print('Running Newton Trust Region with more draws')\n",
    "# num_gh_points = 20\n",
    "# # vb_time = time.time()\n",
    "# opt_x = tr_optimize(opt_x, num_gh_points, gtol=1e-6, maxiter=100)\n",
    "# vb_time = time.time() - vb_time\n",
    "\n",
    "print('VB time: ', vb_time)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glmm_par.set_free(opt_x)\n",
    "if simulate_data:\n",
    "    print('Fit beta: ', glmm_par['beta'].e())\n",
    "    print('True beta: ', true_beta)\n",
    "    \n",
    "    print('Fit mu: ', glmm_par['mu'].e())\n",
    "    print('True mu: ', true_mu)\n",
    "    \n",
    "    print('Fit tau: ', glmm_par['tau'].e())\n",
    "    print('True tau: ', true_tau)\n",
    "    \n",
    "    plt.plot(true_u, true_u, 'r.')\n",
    "    plt.plot(true_u, glmm_par['u'].e(), 'k.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212.66903281211853\n",
      "3.695487976074219e-05\n"
     ]
    }
   ],
   "source": [
    "print(vb_time_opt_1)\n",
    "print(vb_time - vb_time_opt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB time:  212.6690697669983\n",
      "[ 1.24107894 -0.16874764  0.13603781 -0.12919702  0.14581823]\n",
      "GLMM Parameters:\n",
      "\tmu:\n",
      "mu_mean: [ 0.58438531]\n",
      "mu_info: [ 59.71768387]\n",
      "\ttau:\n",
      "tau_shape: [ 53.]\n",
      "tau_rate: [ 88.76579456]\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 1.24107894 -0.16874764  0.13603781 -0.12919702  0.14581823]\n",
      "beta_info:\n",
      "[[  5821.07931589   7441.49135394   8215.9506898    6818.18825213\n",
      "    7150.50498172]\n",
      " [  7441.49135394  10625.38527355  10961.77101301   8838.66505649\n",
      "    9340.83608366]\n",
      " [  8215.9506898   10961.77101301  12418.28159801   9559.04219438\n",
      "   10203.18325772]\n",
      " [  6818.18825213   8838.66505649   9559.04219438   9626.12052033\n",
      "    8173.14778609]\n",
      " [  7150.50498172   9340.83608366  10203.18325772   8173.14778609\n",
      "    9147.33321248]]\n",
      "\tu:\n",
      "u_mean:\n",
      "[ -1.72344930e+00  -6.60552063e-01   2.10505234e-01   1.50865436e+00\n",
      "   2.59720945e+00   1.26163535e+00   3.43432564e-01  -1.78324886e+00\n",
      "  -1.50580683e+00   1.65809212e+00   1.07856492e+00   1.47764610e-01\n",
      "   2.59556201e+00   8.01875672e-01   2.06002986e+00   1.09312821e+00\n",
      "   8.59965006e-01   1.24648234e+00   1.39502552e+00  -3.44269543e-01\n",
      "   4.60684949e-01   4.41906186e-01  -6.77917180e-04   1.61456936e+00\n",
      "   3.34118670e+00   1.73474309e+00   8.36781957e-02   8.57326408e-02\n",
      "   1.26006193e+00  -6.41250118e-01  -8.06919419e-01  -2.06534330e-01\n",
      "   1.63710989e+00   1.52584749e+00  -2.61090611e-01  -8.65817841e-01\n",
      "   2.94569435e+00  -2.26208821e-01  -4.44504256e-01   6.62801957e-01\n",
      "   9.34864228e-01  -2.38811792e-01   8.57867344e-01  -1.22455129e+00\n",
      "  -7.85470686e-02  -9.17660576e-01   1.51162396e+00  -7.33022002e-01\n",
      "   4.79366384e-01   2.31374092e+00   2.22586272e+00   1.67023766e-02\n",
      "   1.35555662e+00  -6.94652325e-01  -2.42482455e+00  -1.86693164e+00\n",
      "  -6.07380134e-01  -4.06648115e-01   1.17124030e+00  -1.49348179e+00\n",
      "  -7.98823155e-01   1.63331892e+00   2.34637686e-01   1.85812040e+00\n",
      "   2.08112005e+00   1.54419486e+00  -7.35344676e-01   2.52117692e-01\n",
      "  -7.23223949e-02  -7.17043211e-02   1.77857009e+00   2.10581660e+00\n",
      "   8.17978857e-01  -1.30201477e+00   1.56521350e-01   4.96242022e-01\n",
      "  -6.56441609e-01   1.41194788e+00   1.59644266e+00   2.36630770e+00\n",
      "   5.23909481e-01   3.97687166e-01   2.97861369e-01  -1.56823755e+00\n",
      "   1.22344404e+00   4.54235143e-01  -1.14970263e-02   2.39276313e-01\n",
      "   1.92248603e+00   2.72620681e+00   1.86395148e+00   1.83817930e+00\n",
      "   6.12638830e-01  -6.91610713e-01   3.20532197e+00   3.74015878e-01\n",
      "   1.57865696e+00   4.36001500e-02   1.19354689e+00   2.16603215e+00]\n",
      "u_info:\n",
      "[  2.93122805   8.9716595    9.78596891  12.31331147  24.01470767\n",
      "  29.07748282   3.30337509   3.95356492   3.77310053  16.28024021\n",
      "  16.77889088   2.60876626   6.44931767  24.43343504  27.45095523\n",
      "  12.48555474   2.05137996   2.42050173  47.6216025    2.01064356\n",
      "   4.12597553  26.78168522  21.88434009  12.30206402  29.25513244\n",
      "   8.31479386  16.39717428  11.93020974  36.05592833   3.16368422\n",
      "  10.05644964   5.64665663  59.60461568  17.11989398   4.74440713\n",
      "   7.21092728  37.05425129   9.47973716   2.08425838  12.21658421\n",
      "  11.15744012   1.94911909  34.07953043   1.62812739  19.47476559\n",
      "   6.26789675  48.64732124   3.22316405  14.69816028  22.43231658\n",
      "  19.7580735    6.39778105   1.62357472   2.24838148   2.37212519\n",
      "   4.00291848   1.24126764   2.97137037  32.48954163   1.79478457\n",
      "   5.21472131  25.99212737   1.61964123  21.84330583  52.27241889\n",
      "  43.99454563   9.0501117   22.6954919    4.60530429  17.67705104\n",
      "  51.60871502   9.60185833   8.80222814   5.59371028   6.30834484\n",
      "   6.74842789   8.94967247  22.56175765   2.10285025  27.88533469\n",
      "   2.19512972  15.71306106  16.02328279   1.84071776  19.2468742\n",
      "   2.34719338   8.3315504    3.43017385   6.35671096   7.96036592\n",
      "  51.95306504  24.47071997  29.20282631   6.08676662  15.83009454\n",
      "  11.41368131  34.01159346  19.31884047  13.89293552  20.16239386]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f4ca49ca748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ca4b75128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4cc74c3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('VB time: ', vb_time)\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "#glmm_par_opt.set_free(init_par_vec)\n",
    "print(glmm_par_opt['beta'].e())\n",
    "print(glmm_par_opt)\n",
    "\n",
    "#plt.plot(glmm_par_opt['u'].e(), glmm_par_opt['u'].var(), 'k.')\n",
    "\n",
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "\n",
    "z_mean = e_u + np.matmul(model.x_mat, e_beta)\n",
    "#plt.plot(sp.special.expit(z_mean), model.y_vec, 'k.')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 0], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 5.515293\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization.\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian...\\n')\n",
    "kl_hess = objective.fun_free_hessian(opt_x)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_jac = get_moment_jacobian(opt_x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'run_name': run_name,\n",
    "                    'vb_time': vb_time, 'hess_time': hess_time, 'num_gh_points': num_gh_points, \n",
    "                    'moment_indices': moment_indices.dictval(),\n",
    "                    'prior_indices': prior_indices.dictval(),\n",
    "                    'vp_indices': vp_indices.dictval(),\n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "\n",
    "    print(json_output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
