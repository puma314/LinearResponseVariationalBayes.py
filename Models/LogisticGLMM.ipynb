{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "# from VariationalBayes.NormalParams import MVNParam, UVNParam, UVNParamVector\n",
    "# from VariationalBayes.GammaParams import GammaParam\n",
    "# from VariationalBayes.ExponentialFamilies import \\\n",
    "#     univariate_normal_entropy, multivariate_normal_entropy, gamma_entropy, \\\n",
    "#     mvn_prior, uvn_prior, gamma_prior\n",
    "\n",
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from autograd import jacobian\n",
    "# import autograd.numpy as np\n",
    "# import autograd.numpy.random as npr\n",
    "# import autograd.scipy as sp\n",
    "# import scipy as osp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mu_prior_var', 'NG', 'tau_prior_alpha', 'mu_prior_var_c', 'mu_prior_t', 'mu_prior_mean', 'mu_prior_mean_c', 'tau_prior_beta', 'K', 'mu_prior_epsilon', 'y_group', 'beta_prior_var', 'x', 'N', 'y', 'beta_prior_mean'])\n",
      "0.171046565237\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "simulate_data = False\n",
    "prior_par = vb.ModelParamsDict('Prior Parameters')\n",
    "\n",
    "if not simulate_data:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "    analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    json_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    stan_dat = json_dat['stan_dat']\n",
    "    vp_base = json_dat['vp_base']\n",
    "\n",
    "    print(stan_dat.keys())\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    #N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par.push_param(vb.VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "    beta_prior_info = np.linalg.inv(np.array(stan_dat['beta_prior_var']))\n",
    "    prior_par.push_param(vb.PosDefMatrixParam('beta_prior_info', K, val=beta_prior_info))\n",
    "\n",
    "    prior_par.push_param(vb.ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "    prior_par.push_param(vb.ScalarParam('mu_prior_info', val=1 / stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "    prior_par.push_param(vb.ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "    prior_par.push_param(vb.ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "\n",
    "    prior_par.push_param(vb.VectorParam('beta_prior_mean', K, val=np.zeros(K)))\n",
    "    prior_par.push_param(vb.PosDefMatrixParam('beta_prior_info', K, val=0.01 * np.eye(K)))\n",
    "\n",
    "    prior_par.push_param(vb.ScalarParam('mu_prior_mean', val=0))\n",
    "    prior_par.push_param(vb.ScalarParam('mu_prior_info', val=0.5))\n",
    "\n",
    "    prior_par.push_param(vb.ScalarParam('tau_prior_alpha', val=3.0))\n",
    "    prior_par.push_param(vb.ScalarParam('tau_prior_beta', val=10.0))\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = vb.ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "glmm_par.push_param(vb.UVNParam('mu', min_info=vp_base['mu_info_min'][0]))\n",
    "glmm_par.push_param(vb.GammaParam('tau',\n",
    "                               min_shape=vp_base['tau_alpha_min'][0],\n",
    "                               min_rate=vp_base['tau_beta_min'][0]))\n",
    "glmm_par.push_param(vb.MVNParam('beta', K, min_info=vp_base['beta_diag_min'][0]))\n",
    "glmm_par.push_param(vb.UVNParamVector('u', NG, min_info=vp_base['u_info_min'][0]))\n",
    "\n",
    "advi_init = False\n",
    "if advi_init:\n",
    "    pass\n",
    "# Initialize with ADVI.  Don't forget to add the ADVI computation time to your final VB time!\n",
    "#     advi_fit = json_dat['advi_results']\n",
    "#     glmm_par['mu'].mean.set(advi_fit['mu_mean'][0])\n",
    "#     glmm_par['mu'].info.set(1 / advi_fit['mu_var'][0])\n",
    "\n",
    "#     tau_mean = advi_fit['tau_mean'][0]\n",
    "#     tau_var = advi_fit['tau_var'][0]\n",
    "#     glmm_par['tau'].shape.set((tau_mean ** 2) / tau_var)\n",
    "#     glmm_par['tau'].rate.set(tau_var / tau_mean)\n",
    "\n",
    "#     glmm_par['beta'].mean.set(np.array(advi_fit['beta_mean']))\n",
    "#     glmm_par['beta'].info.set(np.array(advi_fit['beta_info']))\n",
    "\n",
    "#     glmm_par['u'].mean.set(np.array(advi_fit['u_mean']))\n",
    "#     glmm_par['u'].info.set(1 / np.array(advi_fit['u_var']))\n",
    "\n",
    "#     free_par_vec = glmm_par.get_free()\n",
    "else:\n",
    "    glmm_par['mu'].mean.set(0.0)\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    glmm_par['tau'].shape.set(2.0)\n",
    "    glmm_par['tau'].rate.set(2.0)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.full(K, 0.0))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.full(NG, 0.0))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = jacobian(moment_wrapper.get_moments)\n",
    "\n",
    "# Moment indices.\n",
    "moment_indices = copy.deepcopy(moment_wrapper.moment_par)\n",
    "moment_indices.set_vector(1 + np.array(range(moment_indices.vector_size())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-37163.69292815])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "# PriorModelGrad = grad(kl_wrapper.ExpectedLogPrior, argnum=0)\n",
    "# PriorHess = jacobian(PriorModelGrad, argnum=1)\n",
    "\n",
    "# kl_wrapper.ExpectedLogPrior(free_par_vec, prior_par.get_vector())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.019944580800074618\n",
      "Grad time:\n",
      "0.06685253989999182\n",
      "Hessian vector product time:\n",
      "0.14991978250000101\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print('Function time:')\n",
    "print(timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('Grad time:')\n",
    "print(timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('Hessian vector product time:')\n",
    "print(timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/trlib:/home/rgiordan/Documents/git_repos/trlib/build:/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py:/home/rgiordan/Documents/git_repos/autograd::/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py:\n",
      "Iter  7  value:  [-40263.18255138]\n",
      "-40263.1825514\n",
      "[  2.91922810e+03  -2.37994873e+03  -8.17091190e+02 ...,   4.99811802e-01\n",
      "   4.99609968e-01  -1.88490341e+01]\n",
      "[  2.89430206e+03   2.39024793e+03  -8.44822087e+02 ...,   1.83750764e-04\n",
      "   9.64963818e-05   1.58162989e+01]\n",
      "it   obj         ‖g‖        radius     step       rho          ?  nhv\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-69e209c014f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_free_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mhessvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_free_hvp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     x=init_par_vec)\n\u001b[0m",
      "\u001b[0;32mtrlib.pyx\u001b[0m in \u001b[0;36mtrlib.umin (/home/rgiordan/Documents/git_repos/trlib/build/bindings/python/_trlib3.c:10997)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtrlib.pyx\u001b[0m in \u001b[0;36mtrlib.trlib_solve (/home/rgiordan/Documents/git_repos/trlib/build/bindings/python/_trlib3.c:7693)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['PYTHONPATH'])\n",
    "\n",
    "import trlib\n",
    "\n",
    "#print(init_par_vec)\n",
    "print(objective.fun_free(init_par_vec, verbose=True)[0])\n",
    "print(objective.fun_free_grad(init_par_vec))\n",
    "print(objective.fun_free_hvp(init_par_vec, init_par_vec))\n",
    "\n",
    "init_par_vec = np.random.random(model.glmm_par.free_size())\n",
    "\n",
    "tr_min = trlib.umin(\n",
    "    obj=objective.fun_free,\n",
    "    grad=objective.fun_free_grad,\n",
    "    hessvec=objective.fun_free_hvp,\n",
    "    x=init_par_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "def tr_optimize(trust_init, num_draws):\n",
    "    model.set_draws(num_draws)\n",
    "    objective.logger.initialize()\n",
    "    objective.logger.print_every = 5\n",
    "    vb_opt = optimize.minimize(\n",
    "        lambda par: objective.fun_free(par, verbose=True),\n",
    "        x0=trust_init,\n",
    "        method='trust-ncg',\n",
    "        jac=objective.fun_free_grad,\n",
    "        hessp=objective.fun_free_hvp,\n",
    "        tol=1e-6, options={'maxiter': 500, 'disp': True, 'gtol': 1e-6 })\n",
    "    return vb_opt.x\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Optimize.\n",
    "num_mc_draws = 3\n",
    "\n",
    "print('Running Newton Trust Region')\n",
    "vb_time = time.time()\n",
    "opt_x = tr_optimize(init_par_vec, num_mc_draws)\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(opt_x))\n",
    "print(glmm_par.free_size())\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "set_moments(glmm_par_opt, moment_par)\n",
    "\n",
    "print(vb_time / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Investigate the performance of different numbers of draws.   It doesn't appear to\n",
    "    # converge.\n",
    "    opt_x_20 = tr_optimize(init_par_vec, 20)\n",
    "    opt_x_60 = tr_optimize(opt_x_20, 60)\n",
    "    opt_x_100 = tr_optimize(opt_x_60, 100)\n",
    "    opt_x_200 = tr_optimize(opt_x_100, 200)\n",
    "    opt_x_400 = tr_optimize(opt_x_200, 400)\n",
    "    opt_x_800 = tr_optimize(opt_x_400, 800)\n",
    "    \n",
    "    mom_20 = get_moment_vec(opt_x_20)\n",
    "    mom_60 = get_moment_vec(opt_x_60)\n",
    "    mom_100 = get_moment_vec(opt_x_100)\n",
    "    mom_200 = get_moment_vec(opt_x_200)\n",
    "    mom_400 = get_moment_vec(opt_x_400)\n",
    "    mom_800 = get_moment_vec(opt_x_800)\n",
    "\n",
    "    print np.max(np.abs((mom_20 - mom_60) / mom_20))\n",
    "    print np.max(np.abs((mom_60 - mom_100) / mom_60))\n",
    "    print np.max(np.abs((mom_100 - mom_200) / mom_100))\n",
    "    print np.max(np.abs((mom_200 - mom_400) / mom_200))\n",
    "    print np.max(np.abs((mom_400 - mom_800) / mom_400))\n",
    "\n",
    "    print '-------\\n'\n",
    "    print np.max(np.abs((mom_20 - mom_60)))\n",
    "    print np.max(np.abs((mom_60 - mom_100)))\n",
    "    print np.max(np.abs((mom_100 - mom_200)))\n",
    "    print np.max(np.abs((mom_200 - mom_400)))\n",
    "    print np.max(np.abs((mom_400 - mom_800)))\n",
    "\n",
    "    #diff_inds = np.where(np.abs(mom_60 - mom_100) > 1e-2)\n",
    "    #print diff_inds\n",
    "    #print moment_indices\n",
    "\n",
    "    #print (get_moment_vec(opt_x_60) - get_moment_vec(opt_x_100)) / np.abs(get_moment_vec(opt_x_100))\n",
    "    get_moment_vec(opt_x_200)\n",
    "    u200 = copy.deepcopy(moment_par['e_u'].get())\n",
    "    get_moment_vec(opt_x_400)\n",
    "    u400 = copy.deepcopy(moment_par['e_u'].get())\n",
    "    get_moment_vec(opt_x_800)\n",
    "    u800 = copy.deepcopy(moment_par['e_u'].get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine why the means are different for different number of simulations.\n",
    "def get_logit_terms(num_draws):\n",
    "    model.set_draws(num_draws)\n",
    "    std_draws = model.std_draws\n",
    "\n",
    "    e_beta = glmm_par_opt['beta'].mean.get()\n",
    "    info_beta = glmm_par_opt['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "\n",
    "    e_u = glmm_par_opt['u'].mean.get()[y_g_vec]\n",
    "    info_u = glmm_par_opt['u'].info.get()[y_g_vec]\n",
    "    var_u = 1 / info_u\n",
    "\n",
    "    z_mean = e_u + np.matmul(x_mat, e_beta)\n",
    "    z_sd = np.sqrt(var_u + np.einsum('nk,kj,nj->n', x_mat, cov_beta, x_mat))\n",
    "    z = np.einsum('i,j->ij', z_sd, std_draws) + np.expand_dims(z_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # p = exp(z) / (1 + exp(z))\n",
    "    # log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "    logit_terms = np.log1p(np.exp(z))\n",
    "    logit_term = -np.sum(logit_terms) / std_draws.size\n",
    "\n",
    "    return logit_term, logit_terms, z\n",
    "    \n",
    "logit_term_50, logit_terms_50, z_50 = get_logit_terms(50)    \n",
    "logit_term_800, logit_terms_800, z_800 = get_logit_terms(800)\n",
    "\n",
    "print logit_term_50\n",
    "print logit_term_800\n",
    "\n",
    "logit_terms_50_mean = np.mean(logit_terms_50, 1)\n",
    "logit_terms_800_mean = np.mean(logit_terms_800, 1)\n",
    "\n",
    "print np.max(np.abs(logit_terms_50_mean - logit_terms_800_mean))\n",
    "print np.where(np.abs(logit_terms_50_mean - logit_terms_800_mean) > 1e-3)\n",
    "\n",
    "ind = 3\n",
    "plt.plot(z_800[ind, :], logit_terms_800[ind, :])\n",
    "plt.plot(z_50[ind, :], logit_terms_50[ind, :])\n",
    "print logit_terms_50_mean[ind]\n",
    "print logit_terms_800_mean[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the Hessians at the number of draws used for optimization.\n",
    "\n",
    "model.set_draws(num_mc_draws)\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian:\\n')\n",
    "kl_hess = objective.fun_free_hessian(opt_x)\n",
    "\n",
    "print('Log prior Hessian:\\n')\n",
    "log_prior_hess = PriorHess(opt_x, prior_par.get_vector())\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_jac = MomentJacobian(opt_x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'run_name': run_name,\n",
    "                    'vb_time': vb_time, 'hess_time': hess_time, 'num_mc_draws': num_mc_draws, \n",
    "                    'moment_indices': moment_indices.dictval(),\n",
    "                    'prior_indices': prior_indices.dictval(),\n",
    "                    'vp_indices': vp_indices.dictval(),\n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "\n",
    "    print(json_output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
