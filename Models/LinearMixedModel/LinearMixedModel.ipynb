{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "from VariationalBayes.NormalParams import UVNParam, UVNParamVector\n",
    "from VariationalBayes.ExponentialFamilies import univariate_normal_entropy, uvn_prior\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as asp\n",
    "import scipy as sp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.26660167 -0.8429095   0.62232385 ..., -0.08710899 -0.16869404\n",
      "  0.01746562]\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "simulate_data = False\n",
    "prior_par = ModelParamsDict('Prior Parameters')\n",
    "\n",
    "# Simulate data\n",
    "N = 200     # observations per group\n",
    "K = 5      # dimension of regressors\n",
    "NG = 200      # number of groups\n",
    "\n",
    "# Generate data\n",
    "NObs = NG * N\n",
    "true_beta = np.array(range(5))\n",
    "true_beta = true_beta - np.mean(true_beta)\n",
    "true_y_info = 1.0\n",
    "\n",
    "true_mu = 0.0\n",
    "true_mu_info = 40.0\n",
    "true_u = np.random.normal(true_mu, 1 / np.sqrt(true_mu_info), NG)\n",
    "\n",
    "x_mat = np.random.random(K * NObs).reshape(NObs, K) - 0.5\n",
    "y_g_vec = np.array([ g for g in range(NG) for n in range(N) ])\n",
    "true_mean = np.matmul(x_mat, true_beta) + true_u[y_g_vec]\n",
    "print true_mean\n",
    "y_vec = np.random.normal(true_mean, 1 / np.sqrt(true_y_info), NG * N)\n",
    "\n",
    "prior_par.push_param(ScalarParam('beta_mean', val=0.0))\n",
    "prior_par.push_param(ScalarParam('beta_info', val=0.01))\n",
    "\n",
    "prior_par.push_param(ScalarParam('mu_mean', val=0.))\n",
    "prior_par.push_param(ScalarParam('mu_info', val=0.5))\n",
    "\n",
    "prior_par.push_param(ScalarParam('mu_log_info_mean', val=0.))\n",
    "prior_par.push_param(ScalarParam('mu_log_info_info', val=10.0))\n",
    "\n",
    "prior_par.push_param(ScalarParam('y_log_info_mean', val=0.0))\n",
    "prior_par.push_param(ScalarParam('y_log_info_info', val=10.0))\n",
    "\n",
    "print N * NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "\n",
    "# ADVI-style, we will represent each parameter as a univariate normal.\n",
    "# Note: you need to include the Jacobian of the transform because the log prior is not a density\n",
    "# with respect to the transformed space.\n",
    "lmm_par = ModelParamsDict('LMM Parameters')\n",
    "\n",
    "lmm_par.push_param(UVNParamVector('beta', K))\n",
    "lmm_par.push_param(UVNParam('mu'))\n",
    "lmm_par.push_param(UVNParam('mu_log_info'))\n",
    "lmm_par.push_param(UVNParam('y_log_info'))\n",
    "lmm_par.push_param(UVNParamVector('u', NG))\n",
    "\n",
    "lmm_par['beta'].mean.set(np.full(K, -0.2))\n",
    "lmm_par['beta'].info.set(np.full(K, 1.0))\n",
    "\n",
    "lmm_par['mu'].mean.set(0.2)\n",
    "lmm_par['mu'].info.set(1.5)\n",
    "\n",
    "lmm_par['mu_log_info'].mean.set(0.3)\n",
    "lmm_par['mu_log_info'].info.set(1.1)\n",
    "\n",
    "lmm_par['y_log_info'].mean.set(0.4)\n",
    "lmm_par['y_log_info'].info.set(1.1)\n",
    "\n",
    "lmm_par['u'].mean.set(np.full(NG, -0.1))\n",
    "lmm_par['u'].info.set(np.full(NG, 0.8))\n",
    "\n",
    "free_par_vec = lmm_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.100981173748\n",
      "0.811362148186\n"
     ]
    }
   ],
   "source": [
    "# A single draw from the variational distribution.\n",
    "lmm_draw = ModelParamsDict('LMM Parameter draw')\n",
    "\n",
    "lmm_draw.push_param(VectorParam('beta', K))\n",
    "lmm_draw.push_param(ScalarParam('mu'))\n",
    "lmm_draw.push_param(ScalarParam('mu_log_info'))\n",
    "lmm_draw.push_param(ScalarParam('y_log_info'))\n",
    "lmm_draw.push_param(VectorParam('u', NG))\n",
    "\n",
    "def trans_normal_param(draw, par):\n",
    "    return draw.get() / np.sqrt(par.info.get()) + par.mean.get()\n",
    "\n",
    "# Set the draw object from the normal parameters in lmm_par by scaling and centering the\n",
    "# standard normal vector std_normal_vec.\n",
    "def set_draw(lmm_draw, lmm_par, std_normal_vec):\n",
    "    lmm_draw.set_vector(std_normal_vec)\n",
    "\n",
    "    lmm_draw['beta'].set(trans_normal_param(lmm_draw['beta'], lmm_par['beta']))\n",
    "    lmm_draw['mu'].set(trans_normal_param(lmm_draw['mu'], lmm_par['mu']))\n",
    "    lmm_draw['mu_log_info'].set(trans_normal_param(lmm_draw['mu_log_info'], lmm_par['mu_log_info']))\n",
    "    lmm_draw['y_log_info'].set(trans_normal_param(lmm_draw['y_log_info'], lmm_par['y_log_info']))\n",
    "    lmm_draw['u'].set(trans_normal_param(lmm_draw['u'], lmm_par['u']))\n",
    "\n",
    "num_draws = 10\n",
    "std_normal_mat = np.random.normal(size=(num_draws, lmm_draw.vector_size()))\n",
    "std_normal_vec = std_normal_mat[0, :]\n",
    "set_draw(lmm_draw, lmm_par, std_normal_vec)\n",
    "\n",
    "# Sanity check\n",
    "print np.mean(lmm_draw['u'].get())\n",
    "print 1 / np.var(lmm_draw['u'].get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "moment_par = ModelParamsDict('Moment Parameters')\n",
    "moment_par.push_param(VectorParam('e_beta', K))\n",
    "moment_par.push_param(ScalarParam('e_mu'))\n",
    "moment_par.push_param(ScalarParam('e_mu_log_info'))\n",
    "moment_par.push_param(ScalarParam('e_y_log_info'))\n",
    "moment_par.push_param(VectorParam('e_u', NG))\n",
    "\n",
    "def set_moments(lmm_par, moment_par):\n",
    "    moment_par['e_beta'].set(lmm_par['beta'].e())\n",
    "    moment_par['e_mu'].set(lmm_par['mu'].e())\n",
    "    moment_par['e_mu_log_info'].set(lmm_par['mu_log_info'].e())\n",
    "    moment_par['e_y_log_info'].set(lmm_par['y_log_info'].e())\n",
    "    moment_par['e_u'].set(lmm_par['u'].e())\n",
    "    \n",
    "set_moments(lmm_par, moment_par)\n",
    "\n",
    "# Moment indices.\n",
    "moment_indices = copy.deepcopy(moment_par)\n",
    "moment_indices.set_vector(1 + np.array(range(moment_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0429294323498111"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normal_log_prior(draw, prior_mean, prior_info):\n",
    "    return -0.5 * prior_info * np.sum((draw - prior_mean) ** 2)\n",
    "\n",
    "def LogPriorDraw(lmm_draw, prior_par):\n",
    "    return \\\n",
    "        normal_log_prior(lmm_draw['beta'].get(),\n",
    "                         prior_par['beta_mean'].get(),\n",
    "                         prior_par['beta_info'].get()) + \\\n",
    "        normal_log_prior(lmm_draw['mu'].get(),\n",
    "                         prior_par['mu_mean'].get(),\n",
    "                         prior_par['mu_info'].get()) + \\\n",
    "        normal_log_prior(lmm_draw['mu_log_info'].get(),\n",
    "                         prior_par['mu_log_info_mean'].get(),\n",
    "                         prior_par['mu_log_info_info'].get()) + \\\n",
    "        normal_log_prior(lmm_draw['y_log_info'].get(),\n",
    "                         prior_par['y_log_info_mean'].get(),\n",
    "                         prior_par['y_log_info_info'].get())\n",
    "\n",
    "LogPriorDraw(lmm_draw, prior_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-55236.76558814798"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DataLogLikelihoodDraw(x_mat, y_vec, y_g_vec, draw):\n",
    "    # TODO: this could be way faster by cacheing certain matrix calculations.  See notes.\n",
    "    y_centered = y_vec - (np.matmul(x_mat, draw['beta'].get()) + draw['u'].get()[y_g_vec])\n",
    "    y_log_info = draw['y_log_info'].get()[0]\n",
    "    return -0.5 * np.exp(y_log_info) * np.dot(y_centered, y_centered) + 0.5 * len(y_vec) * y_log_info\n",
    "    \n",
    "DataLogLikelihoodDraw(x_mat, y_vec, y_g_vec, lmm_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-166.37661526265069"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def RandomEffectLogLikelihoodDraw(draw):\n",
    "    u_center = draw['u'].get() - draw['mu'].get()\n",
    "    mu_log_info = draw['mu_log_info'].get()[0]\n",
    "    return -0.5 * np.exp(mu_log_info) * np.dot(u_center, u_center) + 0.5 * len(u_center) * mu_log_info\n",
    "\n",
    "RandomEffectLogLikelihoodDraw(lmm_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-51709.5166493\n",
      "-51709.5166493\n"
     ]
    }
   ],
   "source": [
    "class DataCache(object):\n",
    "    def __init__(self, x_mat, y_vec, y_g_vec):\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        self.y_t_y = np.dot(np.transpose(y_vec), y_vec)\n",
    "        self.y_t_x = np.dot(np.transpose(y_vec), x_mat)\n",
    "        self.x_t_x = np.dot(np.transpose(x_mat), x_mat)\n",
    "        \n",
    "        num_g = np.max(y_g_vec)\n",
    "        k = x_mat.shape[1]\n",
    "        num_g = np.max(y_g_vec) + 1\n",
    "        self.num_g = num_g\n",
    "        self.n_g = np.full(num_g, 0.0)\n",
    "        self.y_sum_g = np.full(num_g, 0.0)\n",
    "        self.x_sum_g = np.full((num_g, k), 0.0)\n",
    "        for g in range(num_g):\n",
    "            g_rows = np.array(y_g_vec) == g\n",
    "            self.n_g[g] = np.sum(g_rows)\n",
    "            self.y_sum_g[g] = np.sum(y_vec[g_rows])\n",
    "            self.x_sum_g[g, :] = np.sum(x_mat[g_rows, :], 0)\n",
    "    \n",
    "data_cache = DataCache(x_mat, y_vec, y_g_vec)\n",
    "\n",
    "\n",
    "def DataCacheLogLikelihoodDraw(data_cache, draw):\n",
    "    beta = draw['beta'].get()\n",
    "    \n",
    "    ll_global_term = \\\n",
    "        data_cache.y_t_y + \\\n",
    "        -2 * np.matmul(data_cache.y_t_x, beta) + \\\n",
    "        np.dot(beta, np.matmul(data_cache.x_t_x, beta)) \n",
    "\n",
    "    u = draw['u'].get()\n",
    "#     ll_group_term = 0.0\n",
    "#     # TODO: this loop seems to make autodiff slow.\n",
    "#     for g in range(data_cache.num_g):\n",
    "#         u_g = u[g]\n",
    "#         ll_group_term += (u_g**2) * data_cache.n_g[g]\n",
    "#         ll_group_term += -2 * u_g * data_cache.y_sum_g[g]\n",
    "#         ll_group_term += 2 * u_g * np.dot(data_cache.x_sum_g[g, :], beta)\n",
    "\n",
    "    ll_group_term = np.sum(\n",
    "        u**2 * data_cache.n_g[g] + \\\n",
    "        -2 * u * data_cache.y_sum_g + \\\n",
    "        2 * u * np.matmul(data_cache.x_sum_g, beta))\n",
    "\n",
    "    y_log_info = draw['y_log_info'].get()[0]\n",
    "    return -0.5 * np.exp(y_log_info) * (ll_global_term + ll_group_term) + 0.5 * len(y_vec) * y_log_info\n",
    "\n",
    "# These should be equal.\n",
    "print DataCacheLogLikelihoodDraw(data_cache, lmm_draw)\n",
    "print DataLogLikelihoodDraw(x_mat, y_vec, y_g_vec, lmm_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88182.278858\n"
     ]
    }
   ],
   "source": [
    "def ELBODataTerm(data_cache, lmm_draw, prior_par):\n",
    "    ll_data = DataCacheLogLikelihoodDraw(data_cache, lmm_draw)\n",
    "    if np.isnan(ll_data):\n",
    "        print 'bad data log likelihood'\n",
    "        return -np.inf\n",
    "\n",
    "    ll_rf = RandomEffectLogLikelihoodDraw(lmm_draw)\n",
    "    if np.isnan(ll_rf):\n",
    "        print 'bad random effect log likelihood'\n",
    "        return -np.inf\n",
    "\n",
    "    e_log_prior = LogPriorDraw(lmm_draw, prior_par)\n",
    "    if np.isnan(e_log_prior):\n",
    "        print 'bad prior'\n",
    "        return -np.inf\n",
    "\n",
    "    return ll_data + ll_rf + e_log_prior\n",
    "\n",
    "def ELBOEntropyTerm(lmm_par):\n",
    "    return univariate_normal_entropy(lmm_par['beta'].info.get()) + \\\n",
    "           univariate_normal_entropy(lmm_par['mu'].info.get()) + \\\n",
    "           univariate_normal_entropy(lmm_par['u'].info.get()) + \\\n",
    "           univariate_normal_entropy(lmm_par['y_log_info'].info.get()) + \\\n",
    "           univariate_normal_entropy(lmm_par['mu_log_info'].info.get())\n",
    "\n",
    "def ELBO(data_cache, lmm_par, lmm_draw, prior_par, std_normal_mat):\n",
    "    entropy = ELBOEntropyTerm(lmm_par)\n",
    "    \n",
    "    data_term = 0.0\n",
    "    num_draws = std_normal_mat.shape[0]\n",
    "    for draw in range(num_draws):\n",
    "        set_draw(lmm_draw, lmm_par, std_normal_mat[draw, :])\n",
    "        data_term += ELBODataTerm(data_cache, lmm_draw, prior_par)\n",
    "\n",
    "    data_term /= num_draws\n",
    "    \n",
    "    return data_term + entropy\n",
    "        \n",
    "class KLWrapper(object):\n",
    "    def __init__(self, lmm_par, lmm_draw, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__lmm_par_ad = copy.deepcopy(lmm_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.__lmm_draw_ad = copy.deepcopy(lmm_draw)\n",
    "        self.__data_cache = DataCache(x_mat, y_vec, y_g_vec)\n",
    "        self.randomize(num_draws)\n",
    "\n",
    "    def randomize(self, num_draws):\n",
    "        self.std_normal_mat = np.random.normal(size=(num_draws, self.__lmm_draw_ad.vector_size()))\n",
    "        \n",
    "    def KL(self, free_par_vec, verbose=False):\n",
    "        self.__lmm_par_ad.set_free(free_par_vec)\n",
    "        #print self.__lmm_par_ad\n",
    "        kl = -ELBO(self.__data_cache,\n",
    "                   self.__lmm_par_ad,\n",
    "                   self.__lmm_draw_ad,\n",
    "                   self.__prior_par_ad,\n",
    "                   self.std_normal_mat)\n",
    "        if verbose: print kl\n",
    "\n",
    "        return kl\n",
    "        \n",
    "\n",
    "class MomentWrapper(object):\n",
    "    def __init__(self, lmm_par, moment_par):\n",
    "        self.__lmm_par_ad = copy.deepcopy(lmm_par)\n",
    "        self.__moment_par = copy.deepcopy(moment_par)\n",
    "\n",
    "    # Return a posterior moment of interest as a function of unconstrained parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__lmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__lmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par.get_vector()\n",
    "    \n",
    "    def GetMomentParameters(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par\n",
    "\n",
    "\n",
    "kl_wrapper = KLWrapper(lmm_par, lmm_draw, prior_par, x_mat, y_vec, y_g_vec, 20)\n",
    "KLGrad = grad(kl_wrapper.KL)\n",
    "KLHess = hessian(kl_wrapper.KL)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.KL)  \n",
    "print kl_wrapper.KL(free_par_vec)\n",
    "\n",
    "moment_wrapper = MomentWrapper(lmm_par, moment_par)\n",
    "MomentJacobian = jacobian(moment_wrapper.GetMoments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.00268239974976\n",
      "Grad time:\n",
      "0.0297542095184\n",
      "Hessian vector product time:\n",
      "0.0682099819183\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "kl_wrapper.randomize(10)\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.KL(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "# print 'Moment jacobian time:'\n",
    "# print timeit.timeit(lambda: MomentJacobian(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# time_num = 1\n",
    "# print 'Prior Hessian time:'\n",
    "# print timeit.timeit(lambda: PriorHess(combined_free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region\n",
      "96652.3284297\n",
      "56407.6340521\n",
      "47373.2734274\n",
      "42887.1548731\n",
      "39750.5861539\n",
      "37771.9778996\n",
      "33699.2687606\n",
      "32385.6956622\n",
      "27700.5968208\n",
      "27454.3771177\n",
      "23782.7111455\n",
      "23371.3736891\n",
      "22485.9149486\n",
      "22457.7065733\n",
      "21817.2949974\n",
      "20884.2459014\n",
      "20828.9519129\n",
      "20689.0479343\n",
      "20628.929425\n",
      "20178.7893983\n",
      "20176.0312593\n",
      "20174.2034437\n",
      "20168.4309441\n",
      "20061.6868945\n",
      "20061.5484542\n",
      "20060.70238\n",
      "20045.6260404\n",
      "20045.6158316\n",
      "20045.5849025\n",
      "20044.996034\n",
      "20044.9960092\n",
      "20044.9959206\n",
      "20044.9944941\n",
      "20044.9944937\n",
      "20044.9944937\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20044.994494\n",
      "         Iterations: 34\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 0\n",
      "Running Newton Trust Region\n",
      "20258.7191564\n",
      "20202.2351099\n",
      "20187.6894418\n",
      "20181.6648727\n",
      "20162.6523743\n",
      "20150.1661371\n",
      "20121.7185989\n",
      "20118.6179089\n",
      "20101.5478164\n",
      "20101.4551201\n",
      "20099.0548802\n",
      "20099.0547593\n",
      "20098.9193877\n",
      "20098.9109958\n",
      "20098.910988\n",
      "20098.910988\n",
      "20098.910988\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20098.910988\n",
      "         Iterations: 16\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 0\n",
      "Done.\n",
      "0.69868820111\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "kl_wrapper.randomize(30)\n",
    "\n",
    "class OptimizationPath(object):\n",
    "    def __init__(self):\n",
    "        self.x_history = []\n",
    "        pass\n",
    "    \n",
    "    def save(self, x):\n",
    "        self.x_history.append(x)\n",
    "\n",
    "bfgs_path = OptimizationPath()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "\n",
    "# Optimize.\n",
    "vb_time = time.time()\n",
    "\n",
    "# print 'Running BFGS'\n",
    "# vb_opt_bfgs = optimize.minimize(\n",
    "#     lambda par: kl_wrapper.KL(par, verbose=True), init_par_vec,\n",
    "#     method='bfgs', jac=KLGrad, tol=1e-2, callback=bfgs_path.save,\n",
    "#     options={'maxiter': 100, 'gtol': 1e-2, 'disp': True})\n",
    "\n",
    "kl_wrapper.randomize(5)\n",
    "\n",
    "trust_path = OptimizationPath()\n",
    "print 'Running Newton Trust Region'\n",
    "# trust_init = copy.deepcopy(vb_opt_bfgs.x)\n",
    "trust_init = copy.deepcopy(init_par_vec)\n",
    "vb_opt_1 = optimize.minimize(\n",
    "    lambda par: kl_wrapper.KL(par, verbose=True),\n",
    "    trust_init, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd,\n",
    "    tol=1e-6, callback=trust_path.save, options={'maxiter': 100, 'disp': True, 'gtol': 1e-6 })\n",
    "\n",
    "kl_wrapper.randomize(30)\n",
    "\n",
    "trust_path = OptimizationPath()\n",
    "print 'Running Newton Trust Region'\n",
    "# trust_init = copy.deepcopy(vb_opt_bfgs.x)\n",
    "trust_init = copy.deepcopy(init_par_vec)\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.KL(par, verbose=True),\n",
    "    vb_opt_1.x, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd,\n",
    "    tol=1e-6, callback=trust_path.save, options={'maxiter': 100, 'disp': True, 'gtol': 1e-6 })\n",
    "\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "lmm_par_opt = copy.deepcopy(lmm_par)\n",
    "lmm_par_opt.set_free(vb_opt.x)\n",
    "\n",
    "print 'Done.'\n",
    "\n",
    "print vb_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- beta:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'true_beta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d56b83e06f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(glmm_par_opt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'--------------- beta:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtrue_beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlmm_par_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_beta' is not defined"
     ]
    }
   ],
   "source": [
    "# print(glmm_par_opt)\n",
    "print '--------------- beta:\\n'\n",
    "print true_beta\n",
    "print lmm_par_opt['beta'].e()\n",
    "\n",
    "print '--------------- mu:\\n'\n",
    "print lmm_par_opt['mu'].e()[0]\n",
    "print true_mu\n",
    "\n",
    "print '--------------- mu log info:\\n'\n",
    "print lmm_par_opt['mu_log_info'].e()[0]\n",
    "print np.log(true_mu_info)\n",
    "\n",
    "print '--------------- y log info:\\n'\n",
    "print lmm_par_opt['y_log_info'].e()[0]\n",
    "print np.log(true_y_info)\n",
    "\n",
    "\n",
    "# Check the random effect estimates.  This requires simulated data.\n",
    "from ggplot import *\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "e_u = lmm_par_opt['u'].e()\n",
    "\n",
    "plot_df = pd.DataFrame({ 'opt': lmm_par_opt['u'].e(), 'true': true_u })\n",
    "print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "\n",
    "plot_df = pd.DataFrame({ 'opt': lmm_par_opt['beta'].e(), 'true': true_beta })\n",
    "print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating KL Hessian.\n",
      "\n",
      "Done.\n",
      "\n",
      "496273336.875\n",
      "hess_time: 54.143301\n"
     ]
    }
   ],
   "source": [
    "# Slow, but probably faster than using CG if you want the covariance of many parameters.\n",
    "hess_time = time.time()\n",
    "print 'Calculating KL Hessian.\\n'\n",
    "kl_hess = KLHess(vb_opt.x)\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "print 'Done.\\n'\n",
    "\n",
    "print 'hess_time: %f' % hess_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22277.1932001\n",
      "0.000350886396672\n"
     ]
    }
   ],
   "source": [
    "hess_norm = np.sqrt(np.sum(kl_hess**2))\n",
    "diag_norm = np.sqrt(np.sum(np.diag(kl_hess)**2))\n",
    "\n",
    "# How diagonal is the Hessian?\n",
    "print hess_norm \n",
    "print (hess_norm - diag_norm) / hess_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(lmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
