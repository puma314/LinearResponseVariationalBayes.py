{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['y_group', 'x', 'tau_prior_alpha', 'mu_prior_mean', 'mu_prior_info', 'beta_prior_info', 'y', 'N', 'beta_prior_mean', 'tau_prior_beta', 'NG', 'K'])\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "analysis_name = 'simulated_data_small'\n",
    "#analysis_name = 'criteo_subsampled'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "\n",
    "json_file = open(json_filename, 'r')\n",
    "json_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "stan_dat = json_dat['stan_dat']\n",
    "#vp_base = json_dat['vp_base']\n",
    "\n",
    "print(stan_dat.keys())\n",
    "K = stan_dat['K'][0]\n",
    "NObs = stan_dat['N'][0]\n",
    "NG = stan_dat['NG'][0]\n",
    "#N = NObs / NG\n",
    "y_g_vec = np.array(stan_dat['y_group'])\n",
    "y_vec = np.array(stan_dat['y'])\n",
    "x_mat = np.array(stan_dat['x'])\n",
    "\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "# Define a class to contain prior parameters.\n",
    "prior_par = logit_glmm.get_default_prior_params(K)\n",
    "prior_par['beta_prior_mean'].set(np.array(stan_dat['beta_prior_mean']))\n",
    "\n",
    "prior_par['beta_prior_info'].set(np.array(stan_dat['beta_prior_info']))\n",
    "\n",
    "prior_par['mu_prior_mean'].set(stan_dat['mu_prior_mean'][0])\n",
    "prior_par['mu_prior_info'].set(stan_dat['mu_prior_info'][0])\n",
    "\n",
    "prior_par['tau_prior_alpha'].set(stan_dat['tau_prior_alpha'][0])\n",
    "prior_par['tau_prior_beta'].set(stan_dat['tau_prior_beta'][0])\n",
    "\n",
    "# An index set to make sure jacobians match the order expected by R.\n",
    "prior_par_indices = copy.deepcopy(prior_par)\n",
    "prior_par_indices.set_name('Prior Indices')\n",
    "prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.0007016121991910041\n",
      "\tGrad time: 0.006159485597163439\n",
      "\tHessian vector product time: 0.012944937398424372\n",
      "\tPrior hess time:  0.06346654891967773\n"
     ]
    }
   ],
   "source": [
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector)\n",
    "moment_jac = get_moment_jacobian(init_par_vec)\n",
    "\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "def get_e_log_prior(prior_vec, free_par):\n",
    "    model.glmm_par.set_free(free_par)\n",
    "    model.prior_par.set_vector(prior_vec)\n",
    "    return model.get_e_log_prior()\n",
    "\n",
    "get_prior_model_grad = autograd.grad(get_e_log_prior, argnum=0)\n",
    "get_prior_hess = autograd.jacobian(get_prior_model_grad, argnum=1)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmm_par.set_free(np.random.random(glmm_par.free_size()))\n",
    "glmm_indices = copy.deepcopy(glmm_par)\n",
    "glmm_indices.set_vector(np.arange(0, glmm_indices.vector_size()))\n",
    "\n",
    "# Since we never use the free version of the observation parameters, we don't need to\n",
    "# set the minimum allowable values.\n",
    "def get_group_parameters(K):\n",
    "    group_par = vb.ModelParamsDict('Single group GLMM parameters')\n",
    "    group_par.push_param(vb.UVNParam('mu'))\n",
    "    group_par.push_param(vb.GammaParam('tau'))\n",
    "    group_par.push_param(vb.UVNParamVector('beta', K))\n",
    "    group_par.push_param(vb.UVNParamVector('u', 1))\n",
    "    return group_par\n",
    "\n",
    "# Since we never use the free version of the global parameters, we don't need to\n",
    "# set the minimum allowable values.\n",
    "def get_global_parameters(K):\n",
    "    global_par = vb.ModelParamsDict('Global GLMM parameters')\n",
    "    global_par.push_param(vb.UVNParam('mu'))\n",
    "    global_par.push_param(vb.GammaParam('tau'))\n",
    "    global_par.push_param(vb.UVNParamVector('beta', K))\n",
    "    return global_par\n",
    "\n",
    "\n",
    "group_par = get_group_parameters(K)\n",
    "global_par = get_global_parameters(K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "\n",
    "def get_global_entropy_args(info_mu, info_beta, tau_shape, tau_rate):\n",
    "    return \\\n",
    "        ef.univariate_normal_entropy(info_mu) + \\\n",
    "        ef.multivariate_normal_entropy(info_beta) + \\\n",
    "        ef.gamma_entropy(tau_shape, tau_rate)\n",
    "\n",
    "def get_data_log_lik(e_beta, var_beta, e_u, var_u,\n",
    "                     x_mat, y_vec, y_g_vec, gh_x, gh_w):\n",
    "    # Log likelihood from data.\n",
    "    z_mean = e_u[y_g_vec] + np.matmul(x_mat, e_beta)\n",
    "    z_sd = np.sqrt(\n",
    "        var_u[y_g_vec] + np.einsum('nk,k,nk->n',\n",
    "                          x_mat, var_beta, x_mat))\n",
    "    return \\\n",
    "        np.sum(y_vec * z_mean) - \\\n",
    "        logit_glmm.get_e_logistic_term_guass_hermite(\n",
    "            z_mean, z_sd, gh_x, gh_w, aggregate_all=True)\n",
    "\n",
    "        \n",
    "def get_re_log_lik(e_mu, var_mu, e_tau, e_log_tau, e_u, var_u):\n",
    "    return -0.5 * e_tau * np.sum(\n",
    "        ((e_mu - e_u) ** 2) + var_mu + var_u) + 0.5 * e_log_tau * len(e_u)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.104199869424968"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def set_group_parameters(glmm_par, group_par, group):\n",
    "    group_par['beta'].set_vector(glmm_par['beta'].get_vector())\n",
    "    group_par['mu'].set_vector(glmm_par['mu'].get_vector())\n",
    "    group_par['tau'].set_vector(glmm_par['tau'].get_vector())\n",
    "\n",
    "    group_par['u'].mean.set(glmm_par['u'].mean.get()[group])\n",
    "    group_par['u'].info.set(glmm_par['u'].info.get()[group])\n",
    "\n",
    "    \n",
    "def set_global_parameters(glmm_par, group_par):\n",
    "    global_par['beta'].set_vector(glmm_par['beta'].get_vector())\n",
    "    global_par['mu'].set_vector(glmm_par['mu'].get_vector())\n",
    "    global_par['tau'].set_vector(glmm_par['tau'].get_vector())\n",
    "\n",
    "\n",
    "class SparseModelObjective(logit_glmm.LogisticGLMM):\n",
    "    def __init__(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points):\n",
    "        super().__init__(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points)\n",
    "\n",
    "        self.glmm_indices = copy.deepcopy(self.glmm_par)\n",
    "        self.glmm_indices.set_vector(np.arange(0, self.glmm_indices.vector_size()))\n",
    "\n",
    "        # Parameters for a single observation.\n",
    "        K = glmm_par['beta'].size()\n",
    "        self.group_par = get_group_parameters(K)\n",
    "        self.group_indices = get_group_parameters(K)\n",
    "        self.group_indices.set_vector(np.arange(0, self.group_indices.vector_size()))\n",
    "        \n",
    "        self.group_rows = [ self.y_g_vec == g \\\n",
    "                            for g in range(np.max(self.y_g_vec) + 1)]\n",
    "        \n",
    "        self.global_par = get_global_parameters(K)\n",
    "        self.global_indices = get_global_parameters(K)\n",
    "        self.global_indices.set_vector(np.arange(0, self.global_indices.vector_size()))\n",
    "\n",
    "    # Set the group parameters from the global parameters and\n",
    "    # return a vector of the indices.\n",
    "    def set_group_parameters(self, group):\n",
    "        set_group_parameters(self.glmm_par, self.group_par, group)\n",
    "        set_group_parameters(self.glmm_indices, self.group_indices, group)  \n",
    "        return self.group_par.get_vector(), self.group_indices.get_vector()\n",
    "\n",
    "    def set_global_parameters(self, unused_group=-1):\n",
    "        set_global_parameters(self.glmm_par, self.global_par)\n",
    "        set_global_parameters(self.glmm_indices, self.global_indices)  \n",
    "        return self.global_par.get_vector(), self.global_indices.get_vector()\n",
    "\n",
    "    # Likelihood functions:        \n",
    "    def get_group_elbo(self, group):\n",
    "        e_beta = self.group_par['beta'].e()\n",
    "        var_beta = self.group_par['beta'].var()\n",
    "        e_u = np.array([self.group_par['u'].e()])\n",
    "        var_u = np.array([self.group_par['u'].var()])\n",
    "        info_u = np.array([self.group_par['u'].info.get()])\n",
    "        e_tau = self.group_par['tau'].e()\n",
    "        e_log_tau = self.group_par['tau'].e_log()\n",
    "        e_mu = self.group_par['mu'].e()\n",
    "        var_mu = self.group_par['mu'].var()\n",
    "        \n",
    "        assert(len(e_u) == 1)\n",
    "        assert(len(var_u) == 1)\n",
    "        assert(len(info_u) == 1)\n",
    "        \n",
    "        return \\\n",
    "            get_data_log_lik(\n",
    "                e_beta=e_beta,\n",
    "                var_beta=var_beta,\n",
    "                e_u=e_u,\n",
    "                var_u=var_u,\n",
    "                y_g_vec=[0],\n",
    "                x_mat=self.x_mat[self.group_rows[group], :],\n",
    "                y_vec=self.y_vec[self.group_rows[group]],\n",
    "                gh_x=self.gh_x,\n",
    "                gh_w=self.gh_w) + \\\n",
    "            get_re_log_lik(\n",
    "                e_mu=e_mu,\n",
    "                var_mu=var_mu,\n",
    "                e_tau=e_tau,\n",
    "                e_log_tau=e_log_tau,\n",
    "                e_u=np.array([e_u]),\n",
    "                var_u=np.array([var_u])) + \\\n",
    "            ef.univariate_normal_entropy(info_u)\n",
    "\n",
    "    def get_global_elbo(self):\n",
    "        e_beta = self.global_par['beta'].mean.get()\n",
    "        info_beta = np.diag(self.global_par['beta'].info.get())\n",
    "        cov_beta = np.diag(1. / self.global_par['beta'].info.get())\n",
    "        \n",
    "        e_mu = self.global_par['mu'].mean.get()\n",
    "        info_mu = self.global_par['mu'].info.get()\n",
    "        var_mu = 1 / info_mu\n",
    "        \n",
    "        tau_shape = self.global_par['tau'].shape.get()\n",
    "        tau_rate = self.global_par['tau'].rate.get()\n",
    "        e_tau = self.global_par['tau'].e()\n",
    "        e_log_tau = self.global_par['tau'].e_log()\n",
    "        \n",
    "        e_log_p_beta = ef.mvn_prior(\n",
    "            prior_mean=self.prior_par['beta_prior_mean'].get(),\n",
    "            prior_info=self.prior_par['beta_prior_info'].get(),\n",
    "            e_obs=e_beta, cov_obs=cov_beta)\n",
    "\n",
    "        e_log_p_mu = ef.uvn_prior(\n",
    "            prior_mean=self.prior_par['mu_prior_mean'].get(),\n",
    "            prior_info=self.prior_par['mu_prior_info'].get(),\n",
    "            e_obs=e_mu, var_obs=var_mu)\n",
    "\n",
    "        e_log_p_tau = ef.gamma_prior(\n",
    "            prior_shape=self.prior_par['tau_prior_alpha'].get(),\n",
    "            prior_rate=self.prior_par['tau_prior_beta'].get(),\n",
    "            e_obs=e_tau, e_log_obs=e_log_tau)\n",
    "\n",
    "        return \\\n",
    "            ef.univariate_normal_entropy(info_mu) + \\\n",
    "            ef.multivariate_normal_entropy(info_beta) + \\\n",
    "            ef.gamma_entropy(tau_shape, tau_rate) + \\\n",
    "            e_log_p_beta + e_log_p_mu + e_log_p_tau\n",
    "    \n",
    "    def get_group_elbo_from_vec(self, group_par_vec, group):\n",
    "        self.group_par.set_vector(group_par_vec)\n",
    "        return self.get_group_elbo(group)\n",
    "    \n",
    "    def get_global_elbo_from_vec(self, global_par_vec, group):\n",
    "        self.global_par.set_vector(global_par_vec)\n",
    "        return self.get_global_elbo()\n",
    "\n",
    "\n",
    "\n",
    "sparse_model = SparseModelObjective(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 4)\n",
    "\n",
    "sparse_model.set_group_parameters(1)\n",
    "sparse_model.get_group_elbo(1)\n",
    "\n",
    "sparse_model.set_global_parameters()\n",
    "sparse_model.get_global_elbo()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "1   1\n",
      "[-769.25021042]\n",
      "-770.6542278654944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "objective = Objective(sparse_model.glmm_par, sparse_model.get_elbo)\n",
    "full_elbo = objective.fun_vector(sparse_model.glmm_par.get_vector())\n",
    "\n",
    "sparse_model.set_global_parameters()\n",
    "sparse_elbo = sparse_model.get_global_elbo()\n",
    "for g in range(NG):\n",
    "    group_vec, group_inds = sparse_model.set_group_parameters(g)\n",
    "    sparse_elbo += sparse_model.get_group_elbo_from_vec(group_vec, g)\n",
    "\n",
    "print(sparse_elbo)\n",
    "print(full_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gettin' that ol' Hessian:\n",
      "Full Hessian time:  2.4029366970062256\n"
     ]
    }
   ],
   "source": [
    "print('Gettin\\' that ol\\' Hessian:')\n",
    "\n",
    "full_hess_time = time.time()\n",
    "full_hess = objective.fun_vector_hessian(sparse_model.glmm_par.get_vector())\n",
    "full_hess_time = time.time() - full_hess_time\n",
    "\n",
    "print('Full Hessian time: ', full_hess_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global hessian:\n",
      "Group 0 of 0\n",
      "Done.\n",
      "Local hessian:\n",
      "Group 0 of 99\n",
      "Group 10 of 99\n",
      "Group 20 of 99\n",
      "Group 30 of 99\n",
      "Group 40 of 99\n",
      "Group 50 of 99\n",
      "Group 60 of 99\n",
      "Group 70 of 99\n",
      "Group 80 of 99\n",
      "Group 90 of 99\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def get_sparse_hessian(\n",
    "    set_parameters_fun, get_group_hessian, group_range, full_hess_dim, print_every=20):\n",
    "\n",
    "    hess_vals = [] # These will be the entries of the Hessian\n",
    "    hess_rows = [] # These will be the z indices\n",
    "    hess_cols = [] # These will be the data indices\n",
    "\n",
    "    group_vector, full_indices = set_parameters_fun(0)  \n",
    "    group_hess_dim = len(group_vector)\n",
    "\n",
    "    for group in group_range:\n",
    "        if group % print_every == 0:\n",
    "            print('Group {} of {}'.format(group, group_range.stop - 1))\n",
    "        group_vector, full_indices = set_parameters_fun(group)  \n",
    "        row_hess_val = np.squeeze(get_group_hessian(group_vector, group))\n",
    "\n",
    "        for row in range(group_hess_dim):\n",
    "            for col in range(group_hess_dim):\n",
    "                if row_hess_val[row, col] != 0:\n",
    "                    hess_vals.append(row_hess_val[row, col])\n",
    "                    hess_rows.append(int(full_indices[row]))\n",
    "                    hess_cols.append(int(full_indices[col]))\n",
    "\n",
    "    print('Done.')\n",
    "    return csr_matrix((hess_vals, (hess_rows, hess_cols)),\n",
    "                      (full_hess_dim, full_hess_dim))\n",
    "\n",
    "\n",
    "get_group_hessian = autograd.hessian(sparse_model.get_group_elbo_from_vec)\n",
    "get_global_hessian = autograd.hessian(sparse_model.get_global_elbo_from_vec)\n",
    "\n",
    "sparse_hess_time = time.time()\n",
    "\n",
    "print('Global hessian:')\n",
    "sparse_global_hess = get_sparse_hessian(\n",
    "    set_parameters_fun=sparse_model.set_global_parameters,\n",
    "    get_group_hessian=get_global_hessian,\n",
    "    group_range=range(1),\n",
    "    full_hess_dim = sparse_model.glmm_par.vector_size(),    \n",
    "    print_every=1)\n",
    "\n",
    "print('Local hessian:')\n",
    "sparse_group_hess = get_sparse_hessian(\n",
    "    set_parameters_fun=sparse_model.set_group_parameters,\n",
    "    get_group_hessian=get_group_hessian,\n",
    "    group_range=range(NG),\n",
    "    full_hess_dim = sparse_model.glmm_par.vector_size(),\n",
    "    print_every=10)\n",
    "\n",
    "sparse_hess_time = time.time() - sparse_hess_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Hessian time:  8.975576639175415\n",
      "Sparse Hessian time per group:  0.08975576639175414\n",
      "Full Hessian time:  2.4029366970062256\n",
      "Sparse Hessian time:  8.975576639175415\n",
      "Max difference (should be zero): 91.2399229823\n",
      "Stdev (so you know it's not all zeros): 1.27188416711\n"
     ]
    }
   ],
   "source": [
    "sparse_hess = sparse_global_hess + sparse_global_hess\n",
    "\n",
    "print('Sparse Hessian time: ', sparse_hess_time)\n",
    "print('Sparse Hessian time per group: ', sparse_hess_time  / float(NG))\n",
    "\n",
    "print('Full Hessian time: ', full_hess_time)\n",
    "print('Sparse Hessian time: ', sparse_hess_time)\n",
    "\n",
    "print('Max difference (should be zero):', np.max(np.abs(full_hess - sparse_hess.todense())))\n",
    "print('Stdev (so you know it\\'s not all zeros):', np.std(full_hess[:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd324124ef0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFRtJREFUeJzt3XuMXnd95/H3x2PGjWhYaGMgxDEOkFY43SWFqWEE1Q44\ndYKXkkIoTRWuZdcUwQq2FS0hEopWKCm3pu3SJZ5CJJDoBopJiSAhFy+zLJtJwjgkkAsUk1IRJyVO\nVS4VuxnZ+e4fz3E1ZzJXj888z9jvl3Q05/J7fuc7Z8b+POd3zpknVYUkSUes63cBkqTBYjBIkloM\nBklSi8EgSWoxGCRJLQaDJKnFYJAktRgMkqQWg0GS1LK+3wUcjVNOOaW2bNnS7zIkaU3Zt2/fI1W1\ncbF2azIYtmzZwtTUVL/LkKQ1Jck/LKWdQ0mSpBaDQZLUYjBIkloMBklSi8EgSWoxGCRJLQaDJK0R\n4+PjnHvuuYyPj3e6nzX5HIMknWjGx8d561vfCsCNN94IwK5duzrZl2cMkrQG7NmzZ8HlY8lgkKQ1\n4IILLlhw+VhyKEmS1oAjw0Z79uzhggsu6GwYCSBV1VnnXRkZGSn/VpIkLU+SfVU1slg7h5IkSS0G\ngySpxWCQJLV0HgxJvp/kW0nuTPK4CwPp+Ysk+5N8M8nzu65JkjS/1bor6aVV9cg8214OnNlMLwQ+\n1nyVJPXBIAwlnQ98qnpuBZ6c5NR+FyVJJ6rVCIYCbkyyL8lcN96eBvxgxvIDzTpJUh+sxlDSS6rq\nQJKnAjcl+XZVfXW5nTShsgtg8+bNx7pGSVKj8zOGqjrQfH0YuAbYNqvJAeD0GcubmnWz+xmvqpGq\nGtm4cWNX5UrSCa/TYEjyxCQnH5kHdgB3z2p2LfCG5u6kFwE/rqqHuqxLkjS/roeSngZck+TIvv66\nqr6c5PcBqupK4DpgJ7Af+Bnw5o5rkiQtoNNgqKr7gefNsf7KGfMFvL3LOiRJSzcIt6tKkgaIwSBJ\najEYJEktBoMkqcVgkCS1GAySpBaDQZLUYjBIkloMBklSi8EgSWoxGCRJLQaDJKnFYJAktRgMkqQW\ng0GS1GIwSJJaDAZJUkvXn/l8epKvJLk3yT1J3jlHm7EkP05yZzO9r8uaJEkL6/oznw8Bf1hVdyQ5\nGdiX5KaqundWu/9dVa/ouBZJ0hJ0esZQVQ9V1R3N/E+B+4DTutynJGllVu0aQ5ItwK8Ct82xeTTJ\nXUmuT3LWatUkSXq8roeSAEjy88Ae4F1V9ZNZm+8AnllV/5JkJ/C3wJlz9LEL2AWwefPmjiuWpBNX\n52cMSZ5ALxQ+XVWfn729qn5SVf/SzF8HPCHJKXO0G6+qkaoa2bhxY9dlS9IJq+u7kgJ8Arivqv50\nnjZPb9qRZFtT0z91WZckaX5dDyW9GHg98K0kdzbr3gtsBqiqK4HXAG9Lcgj4v8CFVVUd1yVJmken\nwVBVXwOySJuPAh/tsg5J0tL55LMkqcVgkCS1GAySpBaDQZLUYjBIkloMBklSi8EgSWoxGCRJLQaD\nJKnFYJBOEJOTk1x++eVMTk72uxQNuFX5s9uS+mtycpLt27czPT3N8PAwe/fuZXR0tN9laUB5xnAc\nWCvvBNdKnYNuucdxcnKSSy+9lEcffZTDhw/z6KOPcumll/pz0Pyqas1NL3jBC0o9t9xyS5100kk1\nNDRUJ510Ut1yyy39LmlOa6XOQbfc43ik/bp16wqoJAXUunXr/DmcgICpWsL/sZ4xrHETExNMT09z\n+PBhpqenmZiY6HdJc1ordQ665R7HI+0fe+wx1q1bx7Of/WzWrVvHY4895s9B8zIY1rixsTGGh4cZ\nGhpieHiYsbGxfpc0p7VS56Bb7nGc2X7Dhg28+93vZsOGDf4ctKDUGvxMnJGRkZqamup3GQNjcnKS\niYkJxsbGBvqC4lqpc9At9zjObu/P4cSVZF9VjSzazmCQpBPDUoOh86GkJOcl+U6S/UneM8f2DUk+\n02y/LcmWrmuSJM2v02BIMgT8JfByYCvwu0m2zmr2FuCfq+o5wBXAB7qsSZK0sK7PGLYB+6vq/qqa\nBq4Gzp/V5nzgk83854DtSRb8nOij5X30J7bx8XHOPfdcxsfHV6Xv8fFxtm7dyllnncXrXve61vYj\n7bds2cLQ0BBPetKTHvfaLmpdqN8j25IseXrhC194zPZ/PDhuvr+l3NN6tBPwGuDjM5ZfD3x0Vpu7\ngU0zlr8HnLJQv0fzHIP30Z/Ydu/eXcC/Trt37+6079nrZk4XXXTRvNvmeu2xqnWhfheqd7Fp27Zt\nK97/8WAtfH8cb88xJNmVZCrJ1MGDB5f9+qO5j365ZxiLvVtYSn+e1XRjz549Cy4f674X6v/6669f\nsK+ual2o35Xs44477ljx/o8Hx9X3t5T0ONoJGAVumLF8MXDxrDY3AKPN/HrgEZq7peabVuOMYbnt\nF3u3sJT+PKvpjmcMnjF0bS18fyzxjKHrYFgP3A+cAQwDdwFnzWrzduDKZv5C4LOL9Xu0fxLjlltu\nqcsuu2xJ/+FedtllNTQ0VEANDQ3VZZddtmD7HTt2tH4pduzYsez+lrtPLc/u3btrx44dnfyDnavv\n3bt313Of+9zaunVrXXTRRa3tR9o/85nPrHXr1tXJJ5/8uNd2UetC/R7Z1kUoLGX/x4NB//4GIhh6\ndbAT+Dt61w4uadb9V+CVzfzPAX8D7AduB561WJ+r8beSPGOQdLxZajD4gNsClvuE6Pj4OHv27OGC\nCy5g165dR9WfT6VK6opPPkuSWgbmyWdJ0tpiMEiSWgwGSVKLwSBJajEYJEktBoMkqcVgkCS1GAyS\npBaDQZLUYjBIkloMBklSi8EgSWoxGCRJLQaDJKnFYJAktRgMkqSW9V11nORDwG8C0/Q+1vPNVfWj\nOdp9H/gpcBg4tJQPkZAkdafLM4abgF+pqn9H7zOfL16g7Uur6mxDQZL6r7NgqKobq+pQs3grsKmr\nfUmSjp3Vusbwe8D182wr4MYk+5LsWqV6JEnzWNE1hiQ3A0+fY9MlVfWFps0lwCHg0/N085KqOpDk\nqcBNSb5dVV+dY1+7gF0AmzdvXknZkqQFrCgYquqchbYneRPwCmB7VdU8fRxovj6c5BpgG/C4YKiq\ncWAcYGRkZM6+JEkr19lQUpLzgD8CXllVP5unzROTnHxkHtgB3N1VTZKkxXV5jeGjwMn0hofuTHIl\nQJJnJLmuafM04GtJ7gJuB75UVV/usCZJ0iI6e46hqp4zz/oHgZ3N/P3A87qqQZK0fD75LElqMRgk\nSS0GgySpxWCQJLUYDJKkFoNBktRiMEiSWgwGSVKLwSBJajEYJEktBoMkqcVgkCS1GAySpBaDQZLU\nYjBIkloMBklSi8EgSWoxGCRJLZ0FQ5JLkxxoPu/5ziQ752l3XpLvJNmf5D1d1SNJWprOPvO5cUVV\nfXi+jUmGgL8EfgN4APh6kmur6t6O65IkzaPfQ0nbgP1VdX9VTQNXA+f3uSZJOqF1HQzvSPLNJFcl\necoc208DfjBj+YFm3eMk2ZVkKsnUwYMHu6hVksQKgyHJzUnunmM6H/gY8GzgbOAh4CMr2VdVjVfV\nSFWNbNy4cSVdSZIWsKJrDFV1zlLaJfkr4ItzbDoAnD5jeVOzTpLUJ13elXTqjMVXAXfP0ezrwJlJ\nzkgyDFwIXNtVTZKkxXV5V9IHk5wNFPB94K0ASZ4BfLyqdlbVoSTvAG4AhoCrquqeDmuSJC2is2Co\nqtfPs/5BYOeM5euA67qqQ5K0PP2+XVWSNGAMBklSi8EgSWoxGDRwJicnufzyy5mcnOx3KdIJqeu/\nlSQty+TkJNu3b2d6eprh4WH27t3L6Ohov8uSTiieMWigTExMMD09zeHDh5menmZiYqLfJUknHINB\nA2VsbIzh4WGGhoYYHh5mbGys3yVJJxyHkjRQRkdH2bt3LxMTE4yNjTmMJPWBwaCBMzo6aiBIfeRQ\nkiSpxWCQJLUYDJKkFoNBktRiMEiSWgwGSVKLwSBJajEYJEktnT3gluQzwC83i08GflRVZ8/R7vvA\nT4HDwKGqGumqJknS4rr8aM/fOTKf5CPAjxdo/tKqeqSrWiRJS9f5n8RIEuC1wMu63pckaeVW4xrD\nrwM/rKrvzrO9gBuT7Euya75OkuxKMpVk6uDBg50UKkla4RlDkpuBp8+x6ZKq+kIz/7vA/1igm5dU\n1YEkTwVuSvLtqvrq7EZVNQ6MA4yMjNRK6pYkzW9FwVBV5yy0Pcl64NXACxbo40Dz9eEk1wDbgMcF\ngyRpdXQ9lHQO8O2qemCujUmemOTkI/PADuDujmuSJC2g62C4kFnDSEmekeS6ZvFpwNeS3AXcDnyp\nqr7ccU2SpAV0eldSVb1pjnUPAjub+fuB53VZgyRpeXzyWZLUYjBIkloMBklSi8EgSWoxGCRJLQaD\nJKnFYJAktRgMkqQWg0GS1GIwSJJaDAZJUovBIElqMRgkSS0GgySpxWCQJLUYDJKkFoNBktSy4mBI\n8ttJ7knyWJKRWdsuTrI/yXeSnDvP689IclvT7jNJhldakyTp6B2LM4a7gVcDX525MslWep/5fBZw\nHvDfkwzN8foPAFdU1XOAfwbecgxqkiQdpRUHQ1XdV1XfmWPT+cDVVfVoVf09sB/YNrNBkgAvAz7X\nrPok8FsrrUmSdPS6vMZwGvCDGcsPNOtm+kXgR1V1aIE2kqRVtH4pjZLcDDx9jk2XVNUXjm1J89aw\nC9gFsHnz5tXYpSSdkJYUDFV1zlH0fQA4fcbypmbdTP8EPDnJ+uasYa42R2oYB8YBRkZG6ijqkSQt\nQZdDSdcCFybZkOQM4Ezg9pkNqqqArwCvaVa9EViVMxBJ0tyOxe2qr0ryADAKfCnJDQBVdQ/wWeBe\n4MvA26vqcPOa65I8o+nij4E/SLKf3jWHT6y0JknS0UvvTfvaMjIyUlNTU/0uQ5LWlCT7qmpksXY+\n+SxJajEYJEktBoMkqcVgkCS1GAySpBaDQZLUYjBIkloMBklSi8EgSWoxGCRJLQaDJKnFYJAktRgM\nkqQWg0GS1GIwSJJaDAZJUovBIElqWVEwJPntJPckeSzJyIz1v5FkX5JvNV9fNs/rL01yIMmdzbRz\nJfVIklZu/QpffzfwamD3rPWPAL9ZVQ8m+RXgBuC0efq4oqo+vMI6JEnHyIqCoaruA0gye/03Zize\nA5yUZENVPbqS/UmSurca1xguAO5YIBTekeSbSa5K8pRVqEeStIBFgyHJzUnunmM6fwmvPQv4APDW\neZp8DHg2cDbwEPCRBfralWQqydTBgwcX27Uk6SgtOpRUVeccTcdJNgHXAG+oqu/N0/cPZ7T/K+CL\nC9QxDowDjIyM1NHUJElaXCdDSUmeDHwJeE9V/Z8F2p06Y/FV9C5mrymTk5NcfvnlTE5O9rsUSTom\nVnTxOcmrgP8GbAS+lOTOqjoXeAfwHOB9Sd7XNN9RVQ8n+ThwZVVNAR9McjZQwPeZf8hpIE1OTrJ9\n+3amp6cZHh5m7969jI6O9rssSVqRld6VdA294aLZ698PvH+e1/zHGfOvX8n++21iYoLp6WkOHz7M\n9PQ0ExMTBoOkNc8nn1dgbGyM4eFhhoaGGB4eZmxsrN8lSdKKrfQBtxPa6Ogoe/fuZWJigrGxMc8W\nJB0XDIYVGh0dNRAkHVccSpIktRgMkqQWg0GS1GIwSJJaDAZJUovBIElqSdXa+3t0SQ4C/9DvOhZx\nCr0PLFpL1mLNYN2raS3WDNZ9xDOrauNijdZkMKwFSaaqamTxloNjLdYM1r2a1mLNYN3L5VCSJKnF\nYJAktRgM3RnvdwFHYS3WDNa9mtZizWDdy+I1BklSi2cMkqQWg+EYS3J2kluT3JlkKsm2Zn2S/EWS\n/Um+meT5/a51piT/Ocm3k9yT5IMz1l/c1PydJOf2s8b5JPnDJJXklGZ5YI91kg81x/mbSa5pPgb3\nyLaBPtZJzmtq25/kPf2uZy5JTk/ylST3Nr/L72zW/0KSm5J8t/n6lH7XOpckQ0m+keSLzfIZSW5r\njvlnkgyvSiFV5XQMJ+BG4OXN/E5gYsb89UCAFwG39bvWGTW/FLgZ2NAsP7X5uhW4C9gAnAF8Dxjq\nd72zaj8duIHecy2nrIFjvQNY38x/APjAWjjWwFBT07OA4abWrf2ua446TwWe38yfDPxdc2w/SO8z\n6AHec+S4D9oE/AHw18AXm+XPAhc281cCb1uNOjxjOPYKeFIz/2+AB5v584FPVc+twJOTnNqPAufw\nNuBPqupRgKp6uFl/PnB1VT1aVX8P7Ae29anG+VwB/BG9437EwB7rqrqxqg41i7cCm5r5QT/W24D9\nVXV/VU0DV9OreaBU1UNVdUcz/1PgPuA0erV+smn2SeC3+lPh/JJsAv4D8PFmOcDLgM81TVatboPh\n2HsX8KEkPwA+DFzcrD8N+MGMdg806wbBLwG/3pyy/q8kv9asH+SaSXI+cKCq7pq1aaDrnuH36J3Z\nwODXPOj1PU6SLcCvArcBT6uqh5pN/wg8rU9lLeTP6L3JeaxZ/kXgRzPeSKzaMfcT3I5CkpuBp8+x\n6RJgO/BfqmpPktcCnwDOWc365rJIzeuBX6A37PJrwGeTPGsVy5vXInW/l97QzEBZqOaq+kLT5hLg\nEPDp1aztRJHk54E9wLuq6ie9N989VVVJBup2zCSvAB6uqn1Jxvpdj8FwFKpq3v/ok3wKeGez+Dc0\np4XAAXrj4UdsatatikVqfhvw+eoNZN6e5DF6f6OlrzXD/HUn+bf0xuLvav7RbwLuaC72D+yxBkjy\nJuAVwPbmmMMAHOtFDHp9/yrJE+iFwqer6vPN6h8mObWqHmqGFR+ev4e+eDHwyiQ7gZ+jNxz95/SG\nQdc3Zw2rdswdSjr2HgT+fTP/MuC7zfy1wBuaO2ZeBPx4xqltv/0tvQvQJPklehcXH6FX84VJNiQ5\nAzgTuL1vVc5QVd+qqqdW1Zaq2kLvNPv5VfWPDPCxTnIeveGCV1bVz2ZsGthj3fg6cGZzl8wwcCG9\nmgdKMy7/CeC+qvrTGZuuBd7YzL8R+MJq17aQqrq4qjY1v8sXAv+zqi4CvgK8pmm2anV7xnDs/Sfg\nz5OsB/4fsKtZfx29u2X2Az8D3tyf8uZ0FXBVkruBaeCNzTvZe5J8FriX3rDH26vqcB/rXKpBPtYf\npXfn0U3Nmc6tVfX7VTXQx7qqDiV5B707wIaAq6rqnj6XNZcXA68HvpXkzmbde4E/oTdE+hZ6d7C9\ntk/1LdcfA1cneT/wDXqh1zmffJYktTiUJElqMRgkSS0GgySpxWCQJLUYDJKkFoNBktRiMEiSWgwG\nSVLL/wfJEL3qGEv6mgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3240fbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# full_hess[60:80, 60:80]\n",
    "plt.plot(full_hess.flatten(), np.asarray(sparse_hess.todense()).flatten(), 'k.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
