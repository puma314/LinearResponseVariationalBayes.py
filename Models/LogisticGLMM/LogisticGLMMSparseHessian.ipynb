{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tau_prior_alpha', 'beta_prior_mean', 'y_group', 'mu_prior_mean', 'tau_prior_beta', 'N', 'beta_prior_info', 'mu_prior_info', 'x', 'K', 'NG', 'y'])\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "analysis_name = 'simulated_data_small'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "\n",
    "json_file = open(json_filename, 'r')\n",
    "json_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "stan_dat = json_dat['stan_dat']\n",
    "#vp_base = json_dat['vp_base']\n",
    "\n",
    "print(stan_dat.keys())\n",
    "K = stan_dat['K'][0]\n",
    "NObs = stan_dat['N'][0]\n",
    "NG = stan_dat['NG'][0]\n",
    "#N = NObs / NG\n",
    "y_g_vec = np.array(stan_dat['y_group'])\n",
    "y_vec = np.array(stan_dat['y'])\n",
    "x_mat = np.array(stan_dat['x'])\n",
    "\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "# Define a class to contain prior parameters.\n",
    "prior_par = logit_glmm.get_default_prior_params(K)\n",
    "prior_par['beta_prior_mean'].set(np.array(stan_dat['beta_prior_mean']))\n",
    "\n",
    "prior_par['beta_prior_info'].set(np.array(stan_dat['beta_prior_info']))\n",
    "\n",
    "prior_par['mu_prior_mean'].set(stan_dat['mu_prior_mean'][0])\n",
    "prior_par['mu_prior_info'].set(stan_dat['mu_prior_info'][0])\n",
    "\n",
    "prior_par['tau_prior_alpha'].set(stan_dat['tau_prior_alpha'][0])\n",
    "prior_par['tau_prior_beta'].set(stan_dat['tau_prior_beta'][0])\n",
    "\n",
    "# An index set to make sure jacobians match the order expected by R.\n",
    "prior_par_indices = copy.deepcopy(prior_par)\n",
    "prior_par_indices.set_name('Prior Indices')\n",
    "prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.0007837692042812705\n",
      "\tGrad time: 0.00658525709877722\n",
      "\tHessian vector product time: 0.013983451697276906\n",
      "\tPrior hess time:  0.05971574783325195\n"
     ]
    }
   ],
   "source": [
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector)\n",
    "moment_jac = get_moment_jacobian(init_par_vec)\n",
    "\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "def get_e_log_prior(prior_vec, free_par):\n",
    "    model.glmm_par.set_free(free_par)\n",
    "    model.prior_par.set_vector(prior_vec)\n",
    "    return model.get_e_log_prior()\n",
    "\n",
    "get_prior_model_grad = autograd.grad(get_e_log_prior, argnum=0)\n",
    "get_prior_hess = autograd.jacobian(get_prior_model_grad, argnum=1)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class Foo(object):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "class Bar(Foo):\n",
    "    def __init__(self, y):\n",
    "        super().__init__(y)\n",
    "        self.y = y\n",
    "        \n",
    "bar = Bar(3)\n",
    "print(bar.x)\n",
    "print(bar.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmm_par.set_free(np.random.random(glmm_par.free_size()))\n",
    "glmm_indices = copy.deepcopy(glmm_par)\n",
    "glmm_indices.set_vector(np.arange(0, glmm_indices.vector_size()))\n",
    "\n",
    "# Since we never use the free version of the observation parameters, we don't need to\n",
    "# set the minimum allowable values.\n",
    "def get_group_parameters(K):\n",
    "    group_par = vb.ModelParamsDict('Single group GLMM parameters')\n",
    "    group_par.push_param(vb.UVNParam('mu'))\n",
    "    group_par.push_param(vb.GammaParam('tau'))\n",
    "    group_par.push_param(vb.UVNParamVector('beta', K))\n",
    "    group_par.push_param(vb.UVNParamVector('u', 1))\n",
    "    return group_par\n",
    "\n",
    "# Since we never use the free version of the global parameters, we don't need to\n",
    "# set the minimum allowable values.\n",
    "def get_global_parameters(K):\n",
    "    global_par = vb.ModelParamsDict('Global GLMM parameters')\n",
    "    global_par.push_param(vb.UVNParam('mu'))\n",
    "    global_par.push_param(vb.GammaParam('tau'))\n",
    "    global_par.push_param(vb.UVNParamVector('beta', K))\n",
    "    return global_par\n",
    "\n",
    "\n",
    "group_par = get_group_parameters(K)\n",
    "global_par = get_global_parameters(K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "\n",
    "def get_global_entropy_args(info_mu, info_beta, tau_shape, tau_rate):\n",
    "    return \\\n",
    "        ef.univariate_normal_entropy(info_mu) + \\\n",
    "        ef.multivariate_normal_entropy(info_beta) + \\\n",
    "        ef.gamma_entropy(tau_shape, tau_rate)\n",
    "\n",
    "def get_local_entropy_args(info_u):\n",
    "    return ef.univariate_normal_entropy(info_u)\n",
    "\n",
    "def get_group_rows(group, y_g_vec):\n",
    "    return y_g_vec == group\n",
    "\n",
    "def get_group_data_log_lik(e_beta, var_beta, e_u_group, var_u_group,\n",
    "                           group_rows, y_g_vec, x_mat, y_vec, gh_x, gh_w):\n",
    "    # Log likelihood from data.\n",
    "    x_mat_group = x_mat[group_rows, :]\n",
    "    z_mean = e_u_group + np.matmul(x_mat_group, e_beta)\n",
    "    z_sd = np.sqrt(\n",
    "        var_u_group + np.einsum('nk,k,nk->n', x_mat_group, var_beta, x_mat_group))\n",
    "\n",
    "    return \\\n",
    "        np.sum(y_vec[group_rows] * z_mean) - \\\n",
    "        logit_glmm.get_e_logistic_term_guass_hermite(\n",
    "            z_mean, z_sd, gh_x, gh_w, aggregate_all=True)\n",
    "\n",
    "\n",
    "def get_group_re_log_lik(e_mu, var_mu, e_tau, e_log_tau, e_u_group, var_u_group):\n",
    "    return -0.5 * e_tau * (\n",
    "        ((e_mu - e_u_group) ** 2) + var_mu + var_u_group) + 0.5 * e_log_tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gettin' that ol' Hessian:\n",
      "Full Hessian time:  2.516045570373535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def set_group_parameters(glmm_par, group_par, group):\n",
    "    group_par['beta'].set_vector(glmm_par['beta'].get_vector())\n",
    "    group_par['mu'].set_vector(glmm_par['mu'].get_vector())\n",
    "    group_par['tau'].set_vector(glmm_par['tau'].get_vector())\n",
    "\n",
    "    group_par['u'].mean.set(glmm_par['u'].mean.get()[group])\n",
    "    group_par['u'].info.set(glmm_par['u'].info.get()[group])\n",
    "\n",
    "    \n",
    "def set_global_parameters(glmm_par, group_par, group):\n",
    "    global_par['beta'].set_vector(glmm_par['beta'].get_vector())\n",
    "    global_par['mu'].set_vector(glmm_par['mu'].get_vector())\n",
    "    global_par['tau'].set_vector(glmm_par['tau'].get_vector())\n",
    "\n",
    "\n",
    "class SparseModelObjective(logit_glmm.LogisticGLMM):\n",
    "    def __init__(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points):\n",
    "        super().__init__(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points)\n",
    "\n",
    "        self.glmm_indices = copy.deepcopy(self.glmm_par)\n",
    "        self.glmm_indices.set_vector(np.arange(0, self.glmm_indices.vector_size()))\n",
    "\n",
    "        # Parameters for a single observation.\n",
    "        K = glmm_par['beta'].size()\n",
    "        self.group_par = get_group_parameters(K)\n",
    "        self.group_indices = get_group_parameters(K)\n",
    "        self.group_indices.set_vector(np.arange(0, self.group_indices.vector_size()))\n",
    "        \n",
    "        self.group_rows = [ get_group_rows(g, self.y_g_vec) \\\n",
    "                            for g in range(np.max(self.y_g_vec) + 1)]\n",
    "\n",
    "    # Set the group parameters from the global parameters and\n",
    "    # return a vector of the indices.\n",
    "    def set_group_parameters(self, group):\n",
    "        set_group_parameters(self.glmm_par, self.group_par, group)\n",
    "        set_group_parameters(self.glmm_indices, self.group_indices, group)  \n",
    "        return self.group_indices.get_vector()\n",
    "    \n",
    "    # Entropy functions:\n",
    "    def get_global_entropy(self):\n",
    "        info_mu = self.glmm_par['mu'].info.get()\n",
    "        info_beta = self.glmm_par['beta'].info.get()\n",
    "        tau_shape = self.glmm_par['tau'].shape.get()\n",
    "        tau_rate = self.glmm_par['tau'].rate.get()\n",
    "        return get_global_entropy_args(info_mu, info_beta, tau_shape, tau_rate)\n",
    "        \n",
    "    def get_full_local_entropy(self, glmm_vec):\n",
    "        self.glmm_par.set_vector(glmm_vec)\n",
    "        return get_local_entropy_args(self.glmm_par['u'].info.get())\n",
    "\n",
    "    def get_local_entropy(self, local_vec):\n",
    "        self.group_par.set_vector(local_vec)\n",
    "        return get_local_entropy_args(self.group_par['u'].info.get())\n",
    "\n",
    "    # Likelihood functions:\n",
    "    def get_group_data_log_lik(self, group):\n",
    "        return get_group_data_log_lik(\n",
    "            e_beta=self.group_par['beta'].e(),\n",
    "            var_beta=self.group_par['beta'].var(),\n",
    "            e_u_group=self.group_par['u'].e(),\n",
    "            var_u_group=self.group_par['u'].var(),\n",
    "            group_rows=self.group_rows[group],\n",
    "            y_g_vec=self.y_g_vec, x_mat=self.x_mat, y_vec=self.y_vec,\n",
    "            gh_x=self.gh_x, gh_w=self.gh_w)\n",
    "    \n",
    "    def get_group_data_log_lik_from_vec(self, group_par_vec, group):\n",
    "        self.group_par.set_vector(group_par_vec)\n",
    "        return self.get_group_data_log_lik(group)\n",
    "    \n",
    "    def get_data_log_lik(self):\n",
    "        return np.sum(self.get_data_log_lik_terms())\n",
    "    \n",
    "    def get_data_log_lik_from_vec(self, glmm_par_vec):\n",
    "        self.glmm_par.set_vector(glmm_par_vec)\n",
    "        return self.get_data_log_lik()\n",
    "        \n",
    "        # Way slower:\n",
    "#         e_beta = self.glmm_par['beta'].e()\n",
    "#         cov_beta = self.glmm_par['beta'].cov()\n",
    "#         e_u = self.glmm_par['u'].e()\n",
    "#         var_u = self.glmm_par['u'].var()\n",
    "\n",
    "#         log_lik = 0.0\n",
    "#         for group in range(np.max(self.y_g_vec) + 1):\n",
    "#             log_lik += get_group_data_log_lik(\n",
    "#                 e_beta=e_beta,\n",
    "#                 cov_beta=cov_beta,\n",
    "#                 e_u_group=e_u[group],\n",
    "#                 var_u_group=var_u[group],\n",
    "#                 group_rows=self.group_rows[group],\n",
    "#                 y_g_vec=self.y_g_vec, x_mat=self.x_mat, y_vec=self.y_vec,\n",
    "#                 gh_x=self.gh_x, gh_w=self.gh_w)\n",
    "            \n",
    "#         return log_lik\n",
    "\n",
    "\n",
    "\n",
    "sparse_model = SparseModelObjective(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 4)\n",
    "\n",
    "group = 3\n",
    "\n",
    "get_local_hess = autograd.hessian(sparse_model.get_group_data_log_lik_from_vec)\n",
    "get_full_hess = autograd.hessian(sparse_model.get_data_log_lik_from_vec)\n",
    "\n",
    "sparse_model.set_group_parameters(group)\n",
    "\n",
    "print('Gettin\\' that ol\\' Hessian:')\n",
    "full_hess_time = time.time()\n",
    "full_hess = get_full_hess(sparse_model.glmm_par.get_vector())\n",
    "full_hess_time = time.time() - full_hess_time\n",
    "\n",
    "print('Full Hessian time: ', full_hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 of 100\n",
      "Group 20 of 100\n",
      "Group 40 of 100\n",
      "Group 60 of 100\n",
      "Group 80 of 100\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_e_logistic_term_guass_hermite(\n",
    "    z_mean, z_sd, gh_x, gh_w, aggregate_all=True):\n",
    "\n",
    "    return np.sum(z_mean + z_sd)\n",
    "    assert z_mean.shape == z_sd.shape\n",
    "    draws_axis = z_sd.ndim\n",
    "    z_vals = \\\n",
    "        np.sqrt(2) * np.expand_dims(z_sd, axis=draws_axis) * gh_x + \\\n",
    "        np.expand_dims(z_mean, axis=draws_axis)\n",
    "\n",
    "    # By dividing by the number of standard draws after summing,\n",
    "    # we add the sample means for all the observations.\n",
    "    # Note that\n",
    "    # log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "    logit_term = gh_w * np.log1p(np.exp(z_vals)) / np.sqrt(np.pi)\n",
    "    if aggregate_all:\n",
    "        return np.sum(logit_term)\n",
    "    else:\n",
    "        return np.sum(logit_term, axis=draws_axis)\n",
    "\n",
    "\n",
    "# import progressbar # progressbar breaks ipython\n",
    "import cProfile, pstats\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "\n",
    "set_parameters_fun = sparse_model.set_group_parameters\n",
    "local_hessian_fun = get_local_hess\n",
    "group_range = range(NG)\n",
    "#group_range = range(20)\n",
    "\n",
    "\n",
    "sparse_hess_time = time.time()\n",
    "pr.enable()\n",
    "\n",
    "hess_vals = [] # These will be the entries of dkl / dz dweight^T\n",
    "hess_rows = [] # These will be the z indices\n",
    "hess_cols = [] # These will be the data indices\n",
    "\n",
    "group_hess_dim = sparse_model.group_par.vector_size()\n",
    "full_hess_dim = sparse_model.glmm_par.vector_size()\n",
    "\n",
    "#bar = progressbar.ProgressBar(redirect_stdout=True, max_value=NG)\n",
    "for group in group_range:\n",
    "    if group % 20 == 0:\n",
    "        print('Group {} of {}'.format(group, NG))\n",
    "    #bar.update(group)\n",
    "    full_indices = set_parameters_fun(group)  \n",
    "    group_par_vec = sparse_model.group_par.get_vector()\n",
    "    row_hess_val = local_hessian_fun(group_par_vec, group)\n",
    "    \n",
    "    # Just to confirm that local_hessian_fun is taking all the time.\n",
    "    #row_hess_val = np.zeros((group_hess_dim, group_hess_dim))\n",
    "    \n",
    "    for row in range(group_hess_dim):\n",
    "        for col in range(group_hess_dim):\n",
    "            if row_hess_val[row, col] != 0:\n",
    "                hess_vals.append(row_hess_val[row, col])\n",
    "                hess_rows.append(int(full_indices[row]))\n",
    "                hess_cols.append(int(full_indices[col]))\n",
    "\n",
    "print('Done.')\n",
    "sparse_hess = csr_matrix((hess_vals, (hess_rows, hess_cols)),\n",
    "                         (full_hess_dim, full_hess_dim))\n",
    "pr.disable()\n",
    "\n",
    "sparse_hess_time = time.time() - sparse_hess_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Hessian time:  5.847397089004517\n",
      "Sparse Hessian time per group:  0.05847397089004516\n"
     ]
    }
   ],
   "source": [
    "print('Sparse Hessian time: ', sparse_hess_time)\n",
    "print('Sparse Hessian time per group: ', sparse_hess_time  / float(NG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "\n",
    "s = io.StringIO()\n",
    "sortby = 'cumulative'\n",
    "ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full Hessian time: ', full_hess_time)\n",
    "print('Sparse Hessian time: ', sparse_hess_time)\n",
    "\n",
    "print('Max difference (should be zero):', np.max(np.abs(full_hess - sparse_hess.todense())))\n",
    "print('Stdev (so you know it\\'s not all zeros):', np.std(full_hess[:]))\n",
    "# full_hess[60:80, 60:80]\n",
    "#plt.plot(full_hess[:], sparse_hess.todense()[:], 'k.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
