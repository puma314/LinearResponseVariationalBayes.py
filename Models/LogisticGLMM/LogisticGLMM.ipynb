{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import \\\n",
    "    Objective, pack_csr_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['y_group', 'N', 'NG', 'x', 'mu_prior_info', 'tau_prior_beta', 'K', 'beta_prior_mean', 'beta_prior_info', 'mu_prior_mean', 'y', 'tau_prior_alpha'])\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                            'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    y_g_vec, y_vec, x_mat, glmm_par, prior_par = logit_glmm.load_json_data(json_filename)\n",
    "    \n",
    "    K = x_mat.shape[1]\n",
    "    NG = np.max(y_g_vec) + 1\n",
    "\n",
    "else:\n",
    "    # Generate data\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "if False:\n",
    "    # Slightly smarter inits would probably improve fit time, but as of now it doesn't\n",
    "    # seem worth explaining in the paper.\n",
    "    import pandas as pd\n",
    "    #print(glmm_par)\n",
    "\n",
    "    x_t_x = np.matmul(x_mat.transpose(), x_mat)\n",
    "    x_t_y = np.matmul(x_mat.transpose(), y_vec)\n",
    "    beta_init = np.linalg.solve(x_t_x, x_t_y)\n",
    "    #print(beta_init)\n",
    "    #plt.plot(sp.special.expit(np.matmul(x_mat, beta_init)), y_vec, 'k.')\n",
    "\n",
    "    df = pd.DataFrame({ 'y_g': y_g_vec, 'y': y_vec}).groupby('y_g')\n",
    "    #print(df.sum())\n",
    "    u_init = np.array(df.sum()) / np.array(df.count()['y'])\n",
    "    #plt.figure()\n",
    "    print(np.min(y_g_vec))\n",
    "    #plt.plot(u_init[y_g_vec], y_vec, 'k.')\n",
    "\n",
    "glmm_par['mu']['mean'].set(0.0)\n",
    "glmm_par['mu']['info'].set(1.0)\n",
    "\n",
    "glmm_par['tau']['shape'].set(2.0)\n",
    "glmm_par['tau']['rate'].set(2.0)\n",
    "\n",
    "glmm_par['beta']['mean'].set(np.full(K, 0.0))\n",
    "#glmm_par['beta'].info.set(np.eye(K))\n",
    "glmm_par['beta']['info'].set(np.ones(K))\n",
    "\n",
    "glmm_par['u']['mean'].set(np.full(NG, 0.0))\n",
    "glmm_par['u']['info'].set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "moment_jac = moment_wrapper.get_moment_jacobian(init_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.0005080893984995783\n",
      "\tGrad time: 0.004943348499364219\n",
      "\tHessian vector product time: 0.013280399699578994\n",
      "\tPrior hess time:  0.05856823921203613\n"
     ]
    }
   ],
   "source": [
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=4)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "model.objective.fun_free(free_par_vec)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: model.objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: model.objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: model.objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "model.get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n",
    "\n",
    "sparse_model = logit_glmm.SparseModelObjective(\n",
    "    model.glmm_par, model.prior_par, model.x_mat, model.y_vec, model.y_g_vec,\n",
    "    model.num_gh_points, num_groups=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region.\n",
      "Iter  0  value:  1034.44059918\n",
      "Iter  5  value:  235.257298461\n",
      "Iter  10  value:  72.6398068113\n",
      "Iter  15  value:  69.409569197\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 69.407873\n",
      "         Iterations: 19\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 20\n",
      "         Hessian evaluations: 0\n",
      "VB time:  2.2258026599884033\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region.')\n",
    "num_gh_points = 4\n",
    "vb_time = time.time()\n",
    "vb_opt = model.tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "print('VB time: ', vb_time)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glmm_par.set_free(opt_x)\n",
    "if simulate_data:\n",
    "    print('Fit beta: ', glmm_par['beta'].e())\n",
    "    print('True beta: ', true_beta)\n",
    "    \n",
    "    print('Fit mu: ', glmm_par['mu'].e())\n",
    "    print('True mu: ', true_mu)\n",
    "    \n",
    "    print('Fit tau: ', glmm_par['tau'].e())\n",
    "    print('True tau: ', true_tau)\n",
    "    \n",
    "    plt.plot(true_u, true_u, 'r.')\n",
    "    plt.plot(true_u, glmm_par['u'].e(), 'k.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB time:  2.2258026599884033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f7a3e69aa58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a3e804908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a841d98d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('VB time: ', vb_time)\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "\n",
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "\n",
    "z_mean = e_u + np.matmul(model.x_mat, e_beta)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 0], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # In case you want to save without calculating the Hessian, instantiate them here\n",
    "if False:\n",
    "    hess_time = 0.\n",
    "    log_prior_hess = np.array([0.])\n",
    "    elbo_hess = np.array([0.])\n",
    "    moment_jac = np.array([0.])\n",
    "    lrvb_cov = np.array([0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Calculating global hessian:\n",
      "Calculating local hessian:\n",
      "Group 0 of 99.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 8.811845\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization\n",
    "# sparse_model = logit_glmm.SparseModelObjective(\n",
    "#     glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points, num_groups=1)\n",
    "\n",
    "model.glmm_par.set_free(opt_x)\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian...\\n')\n",
    "sparse_vector_hess = \\\n",
    "    sparse_model.get_sparse_vector_hessian(print_every_n=100)\n",
    "elbo_hess = sparse_model.get_free_hessian(sparse_vector_hess)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = model.get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "moment_jac = moment_wrapper.get_moment_jacobian(opt_x)\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving systems...\n",
      "\n",
      "Done\n",
      "\n",
      "Inverse time: 0.008187294006347656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: CholmodTypeConversionWarning: converting matrix of class csr_matrix to CSC format\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print('Solving systems...\\n')\n",
    "inverse_time = time.time()\n",
    "from scikits.sparse.cholmod import cholesky\n",
    "elbo_hess_chol = cholesky(elbo_hess)\n",
    "elbo_inv_moment_jac = -1 * elbo_hess_chol.solve_A(moment_jac.T)\n",
    "lrvb_cov = np.matmul(moment_jac, elbo_inv_moment_jac)\n",
    "vb_prior_sens = np.matmul(log_prior_hess, elbo_inv_moment_jac).T\n",
    "\n",
    "inverse_time = time.time() - inverse_time\n",
    "print('Done\\n')\n",
    "\n",
    "print('Inverse time:', inverse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Solving systems...\\n')\n",
    "#lrvb_cov = -1 * np.matmul(moment_jac, np.linalg.solve(elbo_hess, moment_jac.T))\n",
    "# elbo_inv_moment_jac = -1 * sp.sparse.linalg.spsolve(elbo_hess, moment_jac.T)\n",
    "#print('Done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: 5.64263313801e-16\n",
      "Old time:  0.008536577224731445\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    old_inv_time = time.time()\n",
    "    elbo_inv_moment_jac_solve = -1 * sp.sparse.linalg.spsolve(elbo_hess, moment_jac.T)\n",
    "    old_inv_time = time.time() - old_inv_time\n",
    "\n",
    "    print('Difference:', np.linalg.norm(elbo_inv_moment_jac_solve - elbo_inv_moment_jac))\n",
    "    print('Old time: ', old_inv_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  20\n",
      "CG time:  0.3514587879180908\n",
      "Number of iterations:  23\n",
      "0.0584545098444\n"
     ]
    }
   ],
   "source": [
    "# Time using conjugate gradient to get a single row of the moment sensitivity.\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class OptimumHVP(object):\n",
    "    def __init__(self, glmm_par, opt_x, moment_jac):\n",
    "        self.verbose = False\n",
    "        self.print_every = 10\n",
    "        self.reset_iter()\n",
    "        self.opt_x = opt_x\n",
    "        self.moment_jac = moment_jac\n",
    "        self.lo = LinearOperator(\n",
    "            (glmm_par.free_size(), glmm_par.free_size()), self.hvp)\n",
    "        \n",
    "    def reset_iter(self):\n",
    "        self.iter = 0\n",
    "    \n",
    "    def hvp(self, vec):\n",
    "        self.iter += 1\n",
    "        if self.verbose and self.iter % self.print_every == 0:\n",
    "            print('Iter ', self.iter)\n",
    "        return model.objective.fun_free_hvp(self.opt_x, vec)\n",
    "    \n",
    "    def get_moment_sensitivity_row(self, moment_row):\n",
    "        self.reset_iter()\n",
    "        moment_jac_vec = moment_jac[moment_row, :].flatten()\n",
    "        cg_res, info = sp.sparse.linalg.cg(self.lo, moment_jac_vec)\n",
    "        return cg_res, info\n",
    "\n",
    "moment_row = 0\n",
    "optimum_hvp = OptimumHVP(glmm_par, opt_x, moment_jac)\n",
    "optimum_hvp.verbose = True\n",
    "optimum_hvp.print_every = 20\n",
    "cg_row_time = time.time()\n",
    "cg_res, info = optimum_hvp.get_moment_sensitivity_row(0)\n",
    "cg_row_time = time.time() - cg_row_time\n",
    "\n",
    "print('CG time: ', cg_row_time)\n",
    "num_cg_iterations = optimum_hvp.iter\n",
    "print('Number of iterations: ', optimum_hvp.iter)\n",
    "\n",
    "print(np.max(np.abs(cg_res - elbo_inv_moment_jac[:, moment_row].flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/simulated_data_small_python_vb_results.pkl\n",
      "\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    \n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "    pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "    # Unlike with JSON, numpy arrays can be pickled.\n",
    "    # Note that it does not seem that you can pickle a sparse Cholesky decomposition.\n",
    "    pickle_result_dict = {  'glmm_par_dictval': glmm_par_opt.dictval(),\n",
    "                            'glmm_par_vector': glmm_par_opt.get_vector(),\n",
    "                            'glmm_par_free': glmm_par_opt.get_free(),\n",
    "                            'run_name': run_name,\n",
    "                            'vb_time': vb_time,\n",
    "                            'hess_time': hess_time,\n",
    "                            'inverse_time': inverse_time,\n",
    "                            'cg_row_time': cg_row_time,\n",
    "                            'num_cg_iterations': num_cg_iterations,\n",
    "                            'num_gh_points': num_gh_points, \n",
    "                            'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                            'moment_jac': np.squeeze(moment_jac),\n",
    "                            'elbo_inv_moment_jac': elbo_inv_moment_jac,\n",
    "                            'elbo_hess_packed': pack_csr_matrix(elbo_hess),\n",
    "                            'sparse_vector_hess_packed': pack_csr_matrix(sparse_vector_hess),\n",
    "                            'vb_prior_sens': np.squeeze(vb_prior_sens),\n",
    "                            'log_prior_hess': np.squeeze(log_prior_hess) }\n",
    "\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(pickle_result_dict, pickle_output)\n",
    "    pickle_output.close()\n",
    "    \n",
    "    print(pickle_output_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
