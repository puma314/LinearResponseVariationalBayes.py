{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tau_prior_alpha', 'N', 'K', 'y', 'y_group', 'mu_prior_mean', 'x', 'beta_prior_mean', 'beta_prior_info', 'tau_prior_beta', 'NG', 'mu_prior_info'])\n",
      "0.213409806931\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "    analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                            'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    y_g_vec, y_vec, x_mat, glmm_par, prior_par = load_json_data(json_filename)\n",
    "    \n",
    "    K = x_mat.shape[1]\n",
    "    NG = np.max(y_g_vec) + 1\n",
    "\n",
    "else:\n",
    "    # Generate data\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "if False:\n",
    "    # Slightly smarter inits would probably improve fit time, but as of now it doesn't\n",
    "    # seem worth explaining in the paper.\n",
    "    import pandas as pd\n",
    "    #print(glmm_par)\n",
    "\n",
    "    x_t_x = np.matmul(x_mat.transpose(), x_mat)\n",
    "    x_t_y = np.matmul(x_mat.transpose(), y_vec)\n",
    "    beta_init = np.linalg.solve(x_t_x, x_t_y)\n",
    "    #print(beta_init)\n",
    "    #plt.plot(sp.special.expit(np.matmul(x_mat, beta_init)), y_vec, 'k.')\n",
    "\n",
    "    df = pd.DataFrame({ 'y_g': y_g_vec, 'y': y_vec}).groupby('y_g')\n",
    "    #print(df.sum())\n",
    "    u_init = np.array(df.sum()) / np.array(df.count()['y'])\n",
    "    #plt.figure()\n",
    "    print(np.min(y_g_vec))\n",
    "    #plt.plot(u_init[y_g_vec], y_vec, 'k.')\n",
    "\n",
    "glmm_par['mu'].mean.set(0.0)\n",
    "glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "glmm_par['tau'].shape.set(2.0)\n",
    "glmm_par['tau'].rate.set(2.0)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.full(K, 0.0))\n",
    "#glmm_par['beta'].info.set(np.eye(K))\n",
    "glmm_par['beta'].info.set(np.ones(K))\n",
    "\n",
    "glmm_par['u'].mean.set(np.full(NG, 0.0))\n",
    "glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector)\n",
    "moment_jac = get_moment_jacobian(init_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.015894326998386533\n",
      "\tGrad time: 0.04990489460178651\n",
      "\tHessian vector product time: 0.10604314259835519\n",
      "\tPrior hess time:  0.07500195503234863\n"
     ]
    }
   ],
   "source": [
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "def get_e_log_prior(prior_vec, free_par):\n",
    "    model.glmm_par.set_free(free_par)\n",
    "    model.prior_par.set_vector(prior_vec)\n",
    "    return model.get_e_log_prior()\n",
    "\n",
    "get_prior_model_grad = autograd.grad(get_e_log_prior, argnum=0)\n",
    "get_prior_hess = autograd.jacobian(get_prior_model_grad, argnum=1)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "def tr_optimize(trust_init, num_gh_points, gtol=1e-6, maxiter=500):\n",
    "    model.set_gh_points(num_gh_points)\n",
    "    objective.logger.initialize()\n",
    "    objective.logger.print_every = 5\n",
    "    vb_opt = optimize.minimize(\n",
    "        lambda par: objective.fun_free(par, verbose=True),\n",
    "        x0=trust_init,\n",
    "        method='trust-ncg',\n",
    "        jac=objective.fun_free_grad,\n",
    "        hessp=objective.fun_free_hvp,\n",
    "        tol=1e-6, options={'maxiter': maxiter, 'disp': True, 'gtol': gtol })\n",
    "    return vb_opt.x\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region.\n",
      "Iter  0  value:  162354.434209\n",
      "\tx_diff:  inf\n",
      "Iter  5  value:  38998.7177003\n",
      "\tx_diff:  0.0448425369929\n",
      "Iter  10  value:  30431.1788754\n",
      "\tx_diff:  1.31959311782\n",
      "Iter  15  value:  26782.1378198\n",
      "\tx_diff:  0.484492101679\n",
      "Iter  20  value:  24120.4158785\n",
      "\tx_diff:  1.14842597767\n",
      "Iter  25  value:  23887.7607754\n",
      "\tx_diff:  0.584701818804\n",
      "Iter  30  value:  23879.5113995\n",
      "\tx_diff:  1.54801730042e-05\n",
      "Iter  35  value:  23846.4811303\n",
      "\tx_diff:  2.55090424602e-05\n",
      "Iter  40  value:  23825.6518432\n",
      "\tx_diff:  1.86358156195e-05\n",
      "Iter  45  value:  23825.6016448\n",
      "\tx_diff:  0.0130086484227\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23825.601642\n",
      "         Iterations: 47\n",
      "         Function evaluations: 48\n",
      "         Gradient evaluations: 48\n",
      "         Hessian evaluations: 0\n",
      "VB time:  52.541800022125244\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region.')\n",
    "num_gh_points = 4\n",
    "vb_time = time.time()\n",
    "opt_x = tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "print('VB time: ', vb_time)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glmm_par.set_free(opt_x)\n",
    "if simulate_data:\n",
    "    print('Fit beta: ', glmm_par['beta'].e())\n",
    "    print('True beta: ', true_beta)\n",
    "    \n",
    "    print('Fit mu: ', glmm_par['mu'].e())\n",
    "    print('True mu: ', true_mu)\n",
    "    \n",
    "    print('Fit tau: ', glmm_par['tau'].e())\n",
    "    print('True tau: ', true_tau)\n",
    "    \n",
    "    plt.plot(true_u, true_u, 'r.')\n",
    "    plt.plot(true_u, glmm_par['u'].e(), 'k.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB time:  52.541800022125244\n",
      "[ 1.44700085  0.03296895  0.11030994 -0.17308099  0.27302143]\n",
      "GLMM Parameters:\n",
      "\tmu:\n",
      "mu_mean: [ 2.04149248]\n",
      "mu_info: [ 4117.03635185]\n",
      "\ttau:\n",
      "tau_shape: [ 2503.00016505]\n",
      "tau_rate: [ 3039.81555361]\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 1.44700085  0.03296895  0.11030994 -0.17308099  0.27302143]\n",
      "beta_info:\n",
      "[ 33806.28900287  63229.10973601  72441.81617374  52237.74531174\n",
      "  54524.85152504]\n",
      "\tu:\n",
      "u_mean:\n",
      "[ 3.21159129  3.3788278   3.78659004 ...,  1.84961682  1.57920182\n",
      "  0.6498244 ]\n",
      "u_info:\n",
      "[ 5.21362512  1.67310881  5.3002852  ...,  0.93910507  2.83407442\n",
      "  1.86566524]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f8888563cc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1/8tQZLUrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8888707080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMfQlqSGGviQ15P8BxYwFyMWlFHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88cc3b68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('VB time: ', vb_time)\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "#glmm_par_opt.set_free(init_par_vec)\n",
    "print(glmm_par_opt['beta'].e())\n",
    "print(glmm_par_opt)\n",
    "\n",
    "#plt.plot(glmm_par_opt['u'].e(), glmm_par_opt['u'].var(), 'k.')\n",
    "\n",
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "\n",
    "z_mean = e_u + np.matmul(model.x_mat, e_beta)\n",
    "#plt.plot(sp.special.expit(z_mean), model.y_vec, 'k.')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 0], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case you want to save without calculating the Hessian, instantiate them here\n",
    "hess_time = 0.\n",
    "log_prior_hess = np.array([0.])\n",
    "elbo_hess = np.array([0.])\n",
    "moment_jac = np.array([0.])\n",
    "lrvb_cov = np.array([0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  20\n",
      "Iter  40\n",
      "Iter  60\n",
      "Iter  80\n",
      "CG time:  9.660226345062256\n",
      "Number of iteratiors:  80\n",
      "8.59395067444e-07\n"
     ]
    }
   ],
   "source": [
    "# Time using conjugate gradient to get a single row of the moment sensitivity.\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class OptimumHVP(object):\n",
    "    def __init__(self, glmm_par, opt_x, moment_jac):\n",
    "        self.verbose = False\n",
    "        self.print_every = 10\n",
    "        self.reset_iter()\n",
    "        self.opt_x = opt_x\n",
    "        self.moment_jac = moment_jac\n",
    "        self.lo = LinearOperator(\n",
    "            (glmm_par.free_size(), glmm_par.free_size()), self.hvp)\n",
    "        \n",
    "    def reset_iter(self):\n",
    "        self.iter = 0\n",
    "    \n",
    "    def hvp(self, vec):\n",
    "        self.iter += 1\n",
    "        if self.verbose and self.iter % self.print_every == 0:\n",
    "            print('Iter ', self.iter)\n",
    "        return objective.fun_free_hvp(self.opt_x, vec)\n",
    "    \n",
    "    def get_moment_sensitivity_row(self, moment_row):\n",
    "        self.reset_iter()\n",
    "        moment_jac_vec = moment_jac[moment_row, :].flatten()\n",
    "        cg_res, info = sp.sparse.linalg.cg(self.lo, moment_jac_vec)\n",
    "        return cg_res, info\n",
    "\n",
    "moment_row = 0\n",
    "optimum_hvp = OptimumHVP(glmm_par, opt_x, moment_jac)\n",
    "optimum_hvp.verbose = True\n",
    "optimum_hvp.print_every = 20\n",
    "cg_row_time = time.time()\n",
    "cg_res, info = optimum_hvp.get_moment_sensitivity_row(0)\n",
    "cg_row_time = time.time() - cg_row_time\n",
    "\n",
    "print('CG time: ', cg_row_time)\n",
    "print('Number of iteratiors: ', optimum_hvp.iter)\n",
    "\n",
    "print(np.max(np.abs(cg_res - elbo_inv_moment_jac[:, moment_row].flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moment row  0  of  8\n",
      "Row time:  8.754542589187622\n",
      "Moment row  1  of  8\n",
      "Row time:  8.683900594711304\n",
      "Moment row  2  of  8\n",
      "Row time:  7.853826999664307\n",
      "Moment row  3  of  8\n",
      "Row time:  7.428946018218994\n",
      "Moment row  4  of  8\n",
      "Row time:  8.110037088394165\n",
      "Moment row  5  of  8\n",
      "Row time:  6.734155178070068\n",
      "Moment row  6  of  8\n",
      "Row time:  8.454768896102905\n",
      "Moment row  7  of  8\n",
      "Row time:  8.522122144699097\n",
      "Done.  Time:  64.54982733726501\n"
     ]
    }
   ],
   "source": [
    "moment_indices = logit_glmm.MomentWrapper(glmm_par)\n",
    "moment_indices.moment_par.set_vector(np.arange(moment_indices.moment_par.vector_size()))\n",
    "\n",
    "global_indices = np.hstack(\n",
    "    [ moment_indices.moment_par['e_beta'].get(),\n",
    "      moment_indices.moment_par['e_mu'].get(),\n",
    "      moment_indices.moment_par['e_tau'].get(),\n",
    "      moment_indices.moment_par['e_log_tau'].get() ])\n",
    "\n",
    "optimum_hvp.verbose = False\n",
    "cg_time = time.time()\n",
    "global_elbo_inv_moment_jac = np.full((len(global_indices), glmm_par.free_size()), float('nan'))\n",
    "for moment_row in global_indices:\n",
    "    print('Moment row ', moment_row, ' of ', len(global_indices))\n",
    "    cg_row_time = time.time()\n",
    "    cg_res, info = optimum_hvp.get_moment_sensitivity_row(moment_row)\n",
    "    cg_row_time = time.time() - cg_row_time\n",
    "    print('Row time: ', cg_row_time)\n",
    "    global_elbo_inv_moment_jac[moment_row, :] = cg_res\n",
    "\n",
    "cg_time = time.time() - cg_time\n",
    "\n",
    "print('Done.  Time: ', cg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5008, 10014)\n",
      "9.68675250044e-06\n",
      "\n",
      " i:  1\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  2\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  3\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  4\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  5\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  6\n",
      "Orthogonal:  1.16447090871  Along:  0.0\n",
      "\n",
      " i:  7\n",
      "Orthogonal:  0.000141270655703  Along:  1.41435483303\n",
      "\n",
      " i:  8\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  9\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  10\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  11\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  12\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  13\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  14\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  15\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  16\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  17\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  18\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  19\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  20\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  21\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  22\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  23\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  24\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  25\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  26\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  27\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  28\n",
      "Orthogonal:  1.0  Along:  0.0\n",
      "\n",
      " i:  29\n",
      "Orthogonal:  1.0  Along:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(moment_jac.shape)\n",
    "\n",
    "foo = elbo_inv_moment_jac[:, global_indices].T\n",
    "print(np.max(np.abs(global_elbo_inv_moment_jac - foo)))\n",
    "\n",
    "# Get the components of column vector vec orthogonal to and along the rows of matrix x.\n",
    "def projection_components(x, vec):\n",
    "    xtx = np.matmul(x, x.T)\n",
    "    vec_along = np.matmul(x.T, np.linalg.solve(xtx, np.matmul(x, vec)))\n",
    "    return vec - vec_along, vec_along\n",
    "    \n",
    "\n",
    "for i in range(1, 30):\n",
    "    vec_orth, vec_along = projection_components(moment_jac[0:i, :], moment_jac[i, :])    \n",
    "    print('i: ', i, ' Orthogonal: ', np.linalg.norm(vec_orth), ' Along: ', np.linalg.norm(vec_along))\n",
    "\n",
    "# plt.plot(global_elbo_inv_moment_jac.flatten(), foo.flatten(), 'k.')\n",
    "# plt.plot(foo.flatten(), foo.flatten(), 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Calculating global hessian:\n",
      "Group 0 of 0\n",
      "Done.\n",
      "Calculating local hessian:\n",
      "Group 0 of 4999\n",
      "Group 50 of 4999\n",
      "Group 100 of 4999\n",
      "Group 150 of 4999\n",
      "Group 200 of 4999\n",
      "Group 250 of 4999\n",
      "Group 300 of 4999\n",
      "Group 350 of 4999\n",
      "Group 400 of 4999\n",
      "Group 450 of 4999\n",
      "Group 500 of 4999\n",
      "Group 550 of 4999\n",
      "Group 600 of 4999\n",
      "Group 650 of 4999\n",
      "Group 700 of 4999\n",
      "Group 750 of 4999\n",
      "Group 800 of 4999\n",
      "Group 850 of 4999\n",
      "Group 900 of 4999\n",
      "Group 950 of 4999\n",
      "Group 1000 of 4999\n",
      "Group 1050 of 4999\n",
      "Group 1100 of 4999\n",
      "Group 1150 of 4999\n",
      "Group 1200 of 4999\n",
      "Group 1250 of 4999\n",
      "Group 1300 of 4999\n",
      "Group 1350 of 4999\n",
      "Group 1400 of 4999\n",
      "Group 1450 of 4999\n",
      "Group 1500 of 4999\n",
      "Group 1550 of 4999\n",
      "Group 1600 of 4999\n",
      "Group 1650 of 4999\n",
      "Group 1700 of 4999\n",
      "Group 1750 of 4999\n",
      "Group 1800 of 4999\n",
      "Group 1850 of 4999\n",
      "Group 1900 of 4999\n",
      "Group 1950 of 4999\n",
      "Group 2000 of 4999\n",
      "Group 2050 of 4999\n",
      "Group 2100 of 4999\n",
      "Group 2150 of 4999\n",
      "Group 2200 of 4999\n",
      "Group 2250 of 4999\n",
      "Group 2300 of 4999\n",
      "Group 2350 of 4999\n",
      "Group 2400 of 4999\n",
      "Group 2450 of 4999\n",
      "Group 2500 of 4999\n",
      "Group 2550 of 4999\n",
      "Group 2600 of 4999\n",
      "Group 2650 of 4999\n",
      "Group 2700 of 4999\n",
      "Group 2750 of 4999\n",
      "Group 2800 of 4999\n",
      "Group 2850 of 4999\n",
      "Group 2900 of 4999\n",
      "Group 2950 of 4999\n",
      "Group 3000 of 4999\n",
      "Group 3050 of 4999\n",
      "Group 3100 of 4999\n",
      "Group 3150 of 4999\n",
      "Group 3200 of 4999\n",
      "Group 3250 of 4999\n",
      "Group 3300 of 4999\n",
      "Group 3350 of 4999\n",
      "Group 3400 of 4999\n",
      "Group 3450 of 4999\n",
      "Group 3500 of 4999\n",
      "Group 3550 of 4999\n",
      "Group 3600 of 4999\n",
      "Group 3650 of 4999\n",
      "Group 3700 of 4999\n",
      "Group 3750 of 4999\n",
      "Group 3800 of 4999\n",
      "Group 3850 of 4999\n",
      "Group 3900 of 4999\n",
      "Group 3950 of 4999\n",
      "Group 4000 of 4999\n",
      "Group 4050 of 4999\n",
      "Group 4100 of 4999\n",
      "Group 4150 of 4999\n",
      "Group 4200 of 4999\n",
      "Group 4250 of 4999\n",
      "Group 4300 of 4999\n",
      "Group 4350 of 4999\n",
      "Group 4400 of 4999\n",
      "Group 4450 of 4999\n",
      "Group 4500 of 4999\n",
      "Group 4550 of 4999\n",
      "Group 4600 of 4999\n",
      "Group 4650 of 4999\n",
      "Group 4700 of 4999\n",
      "Group 4750 of 4999\n",
      "Group 4800 of 4999\n",
      "Group 4850 of 4999\n",
      "Group 4900 of 4999\n",
      "Group 4950 of 4999\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 423.743577\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization\n",
    "sparse_model = logit_glmm.SparseModelObjective(\n",
    "    glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points)\n",
    "sparse_model.glmm_par.set_free(opt_x)\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian...\\n')\n",
    "#kl_hess = objective.fun_free_hessian(opt_x)\n",
    "sparse_vector_hess = \\\n",
    "    sparse_model.get_sparse_vector_hessian(print_every_n=50)\n",
    "elbo_hess = sparse_model.get_free_hessian(sparse_vector_hess)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "moment_jac = get_moment_jacobian(opt_x)\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving systems...\n",
      "\n",
      "Done\n",
      "\n",
      "Inverse time: 178.71107459068298\n"
     ]
    }
   ],
   "source": [
    "print('Solving systems...\\n')\n",
    "inverse_time = time.time()\n",
    "#lrvb_cov = -1 * np.matmul(moment_jac, np.linalg.solve(elbo_hess, moment_jac.T))\n",
    "elbo_inv_moment_jac = -1 * sp.sparse.linalg.spsolve(elbo_hess, moment_jac.T)\n",
    "lrvb_cov = np.matmul(moment_jac, elbo_inv_moment_jac)\n",
    "vb_prior_sens = np.matmul(log_prior_hess, elbo_inv_moment_jac).T\n",
    "inverse_time = time.time() - inverse_time\n",
    "print('Done\\n')\n",
    "\n",
    "print('Inverse time:', inverse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/criteo_subsampled_python_vb_results.pkl\n",
      "\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    \n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "    pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "    # TODO: The sparse matrices are not being saved in a usable form.\n",
    "    # Unlike with JSON, numpy arrays can be pickled.\n",
    "    pickle_result_dict = {  'glmm_par_dictval': glmm_par_opt.dictval(),\n",
    "                            'glmm_par_vector': glmm_par_opt.get_vector(),\n",
    "                            'glmm_par_free': glmm_par_opt.get_free(),\n",
    "                            'run_name': run_name,\n",
    "                            'vb_time': vb_time,\n",
    "                            'hess_time': hess_time,\n",
    "                            'inverse_time': inverse_time,\n",
    "                            'num_gh_points': num_gh_points, \n",
    "                            'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                            'moment_jac': np.squeeze(moment_jac),\n",
    "                            'elbo_hess': np.squeeze(elbo_hess),\n",
    "                            'vb_prior_sens': np.squeeze(vb_prior_sens),\n",
    "                            'log_prior_hess': np.squeeze(log_prior_hess) }\n",
    "\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(pickle_result_dict, pickle_output)\n",
    "    pickle_output.close()\n",
    "    \n",
    "    print(pickle_output_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
