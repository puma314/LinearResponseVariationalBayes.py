{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import \\\n",
    "    Objective, pack_csr_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'beta_prior_info', 'mu_prior_mean', 'beta_prior_mean', 'K', 'tau_prior_beta', 'y_group', 'y', 'NG', 'mu_prior_info', 'tau_prior_alpha', 'N'])\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                            'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    y_g_vec, y_vec, x_mat, glmm_par, prior_par = logit_glmm.load_json_data(json_filename)\n",
    "    \n",
    "    K = x_mat.shape[1]\n",
    "    NG = np.max(y_g_vec) + 1\n",
    "\n",
    "else:\n",
    "    # Generate data\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "if False:\n",
    "    # Slightly smarter inits would probably improve fit time, but as of now it doesn't\n",
    "    # seem worth explaining in the paper.\n",
    "    import pandas as pd\n",
    "    #print(glmm_par)\n",
    "\n",
    "    x_t_x = np.matmul(x_mat.transpose(), x_mat)\n",
    "    x_t_y = np.matmul(x_mat.transpose(), y_vec)\n",
    "    beta_init = np.linalg.solve(x_t_x, x_t_y)\n",
    "    #print(beta_init)\n",
    "    #plt.plot(sp.special.expit(np.matmul(x_mat, beta_init)), y_vec, 'k.')\n",
    "\n",
    "    df = pd.DataFrame({ 'y_g': y_g_vec, 'y': y_vec}).groupby('y_g')\n",
    "    #print(df.sum())\n",
    "    u_init = np.array(df.sum()) / np.array(df.count()['y'])\n",
    "    #plt.figure()\n",
    "    print(np.min(y_g_vec))\n",
    "    #plt.plot(u_init[y_g_vec], y_vec, 'k.')\n",
    "\n",
    "glmm_par['mu']['mean'].set(0.0)\n",
    "glmm_par['mu']['info'].set(1.0)\n",
    "\n",
    "glmm_par['tau']['shape'].set(2.0)\n",
    "glmm_par['tau']['rate'].set(2.0)\n",
    "\n",
    "glmm_par['beta']['mean'].set(np.full(K, 0.0))\n",
    "#glmm_par['beta'].info.set(np.eye(K))\n",
    "glmm_par['beta']['info'].set(np.ones(K))\n",
    "\n",
    "glmm_par['u']['mean'].set(np.full(NG, 0.0))\n",
    "glmm_par['u']['info'].set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "moment_jac = moment_wrapper.get_moment_jacobian(init_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.0011359903000993654\n",
      "\tGrad time: 0.00696026039950084\n",
      "\tHessian vector product time: 0.011446397099643946\n",
      "\tPrior hess time:  0.06974911689758301\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'obj_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-202608c9bf1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m sparse_model = logit_glmm.SparseModelObjective(\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglmm_par\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_par\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_g_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     model.num_gh_points, num_groups=1)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/LogisticGLMM_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points, num_groups)\u001b[0m\n\u001b[1;32m    353\u001b[0m             np.array(y_g_vec), num_gh_points)\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglmm_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_index_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglmm_par\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# Parameters for a single observation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obj_lib' is not defined"
     ]
    }
   ],
   "source": [
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=4)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "model.objective.fun_free(free_par_vec)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: model.objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: model.objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: model.objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "model.get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n",
    "\n",
    "sparse_model = logit_glmm.SparseModelObjective(\n",
    "    model.glmm_par, model.prior_par, model.x_mat, model.y_vec, model.y_g_vec,\n",
    "    model.num_gh_points, num_groups=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region.')\n",
    "num_gh_points = 4\n",
    "vb_time = time.time()\n",
    "vb_opt = model.tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "print('VB time: ', vb_time)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glmm_par.set_free(opt_x)\n",
    "if simulate_data:\n",
    "    print('Fit beta: ', glmm_par['beta'].e())\n",
    "    print('True beta: ', true_beta)\n",
    "    \n",
    "    print('Fit mu: ', glmm_par['mu'].e())\n",
    "    print('True mu: ', true_mu)\n",
    "    \n",
    "    print('Fit tau: ', glmm_par['tau'].e())\n",
    "    print('True tau: ', true_tau)\n",
    "    \n",
    "    plt.plot(true_u, true_u, 'r.')\n",
    "    plt.plot(true_u, glmm_par['u'].e(), 'k.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VB time: ', vb_time)\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "\n",
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "\n",
    "z_mean = e_u + np.matmul(model.x_mat, e_beta)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 0], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # In case you want to save without calculating the Hessian, instantiate them here\n",
    "if False:\n",
    "    hess_time = 0.\n",
    "    log_prior_hess = np.array([0.])\n",
    "    elbo_hess = np.array([0.])\n",
    "    moment_jac = np.array([0.])\n",
    "    lrvb_cov = np.array([0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the Hessians at the number of draws used for optimization\n",
    "# sparse_model = logit_glmm.SparseModelObjective(\n",
    "#     glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points, num_groups=1)\n",
    "\n",
    "model.glmm_par.set_free(opt_x)\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian...\\n')\n",
    "sparse_vector_hess = \\\n",
    "    sparse_model.get_sparse_vector_hessian(print_every_n=50)\n",
    "elbo_hess = sparse_model.get_free_hessian(sparse_vector_hess)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = model.get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "moment_jac = moment_wrapper.get_moment_jacobian(opt_x)\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Solving systems...\\n')\n",
    "inverse_time = time.time()\n",
    "#lrvb_cov = -1 * np.matmul(moment_jac, np.linalg.solve(elbo_hess, moment_jac.T))\n",
    "elbo_inv_moment_jac = -1 * sp.sparse.linalg.spsolve(elbo_hess, moment_jac.T)\n",
    "lrvb_cov = np.matmul(moment_jac, elbo_inv_moment_jac)\n",
    "vb_prior_sens = np.matmul(log_prior_hess, elbo_inv_moment_jac).T\n",
    "inverse_time = time.time() - inverse_time\n",
    "print('Done\\n')\n",
    "\n",
    "print('Inverse time:', inverse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time using conjugate gradient to get a single row of the moment sensitivity.\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class OptimumHVP(object):\n",
    "    def __init__(self, glmm_par, opt_x, moment_jac):\n",
    "        self.verbose = False\n",
    "        self.print_every = 10\n",
    "        self.reset_iter()\n",
    "        self.opt_x = opt_x\n",
    "        self.moment_jac = moment_jac\n",
    "        self.lo = LinearOperator(\n",
    "            (glmm_par.free_size(), glmm_par.free_size()), self.hvp)\n",
    "        \n",
    "    def reset_iter(self):\n",
    "        self.iter = 0\n",
    "    \n",
    "    def hvp(self, vec):\n",
    "        self.iter += 1\n",
    "        if self.verbose and self.iter % self.print_every == 0:\n",
    "            print('Iter ', self.iter)\n",
    "        return model.objective.fun_free_hvp(self.opt_x, vec)\n",
    "    \n",
    "    def get_moment_sensitivity_row(self, moment_row):\n",
    "        self.reset_iter()\n",
    "        moment_jac_vec = moment_jac[moment_row, :].flatten()\n",
    "        cg_res, info = sp.sparse.linalg.cg(self.lo, moment_jac_vec)\n",
    "        return cg_res, info\n",
    "\n",
    "moment_row = 0\n",
    "optimum_hvp = OptimumHVP(glmm_par, opt_x, moment_jac)\n",
    "optimum_hvp.verbose = True\n",
    "optimum_hvp.print_every = 20\n",
    "cg_row_time = time.time()\n",
    "cg_res, info = optimum_hvp.get_moment_sensitivity_row(0)\n",
    "cg_row_time = time.time() - cg_row_time\n",
    "\n",
    "print('CG time: ', cg_row_time)\n",
    "num_cg_iterations = optimum_hvp.iter\n",
    "print('Number of iterations: ', optimum_hvp.iter)\n",
    "\n",
    "print(np.max(np.abs(cg_res - elbo_inv_moment_jac[:, moment_row].flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    \n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "    pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "    # Unlike with JSON, numpy arrays can be pickled.\n",
    "    pickle_result_dict = {  'glmm_par_dictval': glmm_par_opt.dictval(),\n",
    "                            'glmm_par_vector': glmm_par_opt.get_vector(),\n",
    "                            'glmm_par_free': glmm_par_opt.get_free(),\n",
    "                            'run_name': run_name,\n",
    "                            'vb_time': vb_time,\n",
    "                            'hess_time': hess_time,\n",
    "                            'inverse_time': inverse_time,\n",
    "                            'cg_row_time': cg_row_time,\n",
    "                            'num_cg_iterations': num_cg_iterations,\n",
    "                            'num_gh_points': num_gh_points, \n",
    "                            'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                            'moment_jac': np.squeeze(moment_jac),\n",
    "                            'elbo_inv_moment_jac': elbo_inv_moment_jac,\n",
    "                            'elbo_hess_packed': pack_csr_matrix(elbo_hess),\n",
    "                            'sparse_vector_hess_packed': pack_csr_matrix(sparse_vector_hess),\n",
    "                            'vb_prior_sens': np.squeeze(vb_prior_sens),\n",
    "                            'log_prior_hess': np.squeeze(log_prior_hess) }\n",
    "\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(pickle_result_dict, pickle_output)\n",
    "    pickle_output.close()\n",
    "    \n",
    "    print(pickle_output_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
