{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NG', 'mu_prior_info', 'K', 'N', 'mu_prior_mean', 'x', 'beta_prior_info', 'tau_prior_alpha', 'y', 'y_group', 'tau_prior_beta', 'beta_prior_mean'])\n",
      "0.171046565237\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "    analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                            'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    json_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    stan_dat = json_dat['stan_dat']\n",
    "    #vp_base = json_dat['vp_base']\n",
    "\n",
    "    print(stan_dat.keys())\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    #N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    prior_par['beta_prior_mean'].set(np.array(stan_dat['beta_prior_mean']))\n",
    "\n",
    "    prior_par['beta_prior_info'].set(np.array(stan_dat['beta_prior_info']))\n",
    "\n",
    "    prior_par['mu_prior_mean'].set(stan_dat['mu_prior_mean'][0])\n",
    "    prior_par['mu_prior_info'].set(stan_dat['mu_prior_info'][0])\n",
    "    \n",
    "    prior_par['tau_prior_alpha'].set(stan_dat['tau_prior_alpha'][0])\n",
    "    prior_par['tau_prior_beta'].set(stan_dat['tau_prior_beta'][0])\n",
    "    \n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(\n",
    "        K=K, NG=NG, \n",
    "        mu_info_min=0.001, tau_alpha_min=0.001,\n",
    "        tau_beta_min=0.001, beta_diag_min=0.001,\n",
    "        u_info_min=0.001)\n",
    "\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "glmm_init = False\n",
    "if glmm_init and not simulate_data:\n",
    "    # Initialize with GLMM.\n",
    "    # If you use this, don't forget to add the computation time to your final VB time!\n",
    "    glmm_time = 0.\n",
    "\n",
    "    glmm_fit = json_dat['glmm_fit']\n",
    "    glmm_par['mu'].mean.set(glmm_fit['mu_mean'][0])\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    tau_mean = 1.0 / glmm_fit['mu_sd'][0] ** 2\n",
    "    tau_var = 1.0\n",
    "    glmm_par['tau'].shape.set((tau_mean ** 2) / tau_var)\n",
    "    glmm_par['tau'].rate.set(tau_var / tau_mean)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.array(glmm_fit['beta_mean']))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.array(glmm_fit['u_map']))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "    free_par_vec = glmm_par.get_free()\n",
    "else:\n",
    "    glmm_time = 0.\n",
    "    glmm_par['mu'].mean.set(0.0)\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    glmm_par['tau'].shape.set(2.0)\n",
    "    glmm_par['tau'].rate.set(2.0)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.full(K, 0.0))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.full(NG, 0.0))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "# Fix this:\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector)\n",
    "moment_jac = get_moment_jacobian(init_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.003254019899759442\n",
      "\tGrad time: 0.018754950596485288\n",
      "\tHessian vector product time: 0.04336678509716876\n",
      "\tPrior hess time:  0.09372329711914062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "def get_e_log_prior(prior_vec, free_par):\n",
    "    model.glmm_par.set_free(free_par)\n",
    "    model.prior_par.set_vector(prior_vec)\n",
    "    return model.get_e_log_prior()\n",
    "\n",
    "get_prior_model_grad = autograd.grad(get_e_log_prior, argnum=0)\n",
    "get_prior_hess = autograd.jacobian(get_prior_model_grad, argnum=1)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "def tr_optimize(trust_init, num_gh_points, gtol=1e-6, maxiter=500):\n",
    "    model.set_gh_points(num_gh_points)\n",
    "    objective.logger.initialize()\n",
    "    objective.logger.print_every = 5\n",
    "    vb_opt = optimize.minimize(\n",
    "        lambda par: objective.fun_free(par, verbose=True),\n",
    "        x0=trust_init,\n",
    "        method='trust-ncg',\n",
    "        jac=objective.fun_free_grad,\n",
    "        hessp=objective.fun_free_hvp,\n",
    "        tol=1e-6, options={'maxiter': maxiter, 'disp': True, 'gtol': gtol })\n",
    "    return vb_opt.x\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#print(glmm_par)\n",
    "\n",
    "x_t_x = np.matmul(x_mat.transpose(), x_mat)\n",
    "x_t_y = np.matmul(x_mat.transpose(), y_vec)\n",
    "beta_init = np.linalg.solve(x_t_x, x_t_y)\n",
    "#print(beta_init)\n",
    "#plt.plot(sp.special.expit(np.matmul(x_mat, beta_init)), y_vec, 'k.')\n",
    "\n",
    "df = pd.DataFrame({ 'y_g': y_g_vec, 'y': y_vec}).groupby('y_g')\n",
    "#print(df.sum())\n",
    "u_init = np.array(df.sum()) / np.array(df.count()['y'])\n",
    "#plt.figure()\n",
    "print(np.min(y_g_vec))\n",
    "#plt.plot(u_init[y_g_vec], y_vec, 'k.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region with few draws.\n",
      "Iter  0  value:  34731.9617662\n",
      "\tx_diff:  inf\n",
      "Iter  5  value:  7447.49823263\n",
      "\tx_diff:  0.0292152418032\n",
      "Iter  10  value:  5517.55412207\n",
      "\tx_diff:  1.48212046172\n",
      "Iter  15  value:  4794.25535164\n",
      "\tx_diff:  0.00327951178233\n",
      "Iter  20  value:  4715.84335281\n",
      "\tx_diff:  0.186072172997\n",
      "Iter  25  value:  4712.85532834\n",
      "\tx_diff:  0.148427844035\n",
      "Iter  30  value:  4712.26571461\n",
      "\tx_diff:  0.052511231943\n",
      "Iter  35  value:  4710.7115346\n",
      "\tx_diff:  0.0561010989539\n",
      "Iter  40  value:  4710.12338497\n",
      "\tx_diff:  9.54741486756e-05\n",
      "Iter  45  value:  4710.64740727\n",
      "\tx_diff:  18.3593521171\n",
      "Iter  50  value:  4709.35060522\n",
      "\tx_diff:  8.68557380108\n",
      "Iter  55  value:  4708.78240523\n",
      "\tx_diff:  0.125722912195\n",
      "Iter  60  value:  4708.63893622\n",
      "\tx_diff:  17.5567228816\n",
      "Iter  65  value:  4708.38918379\n",
      "\tx_diff:  0.0823893656085\n",
      "Iter  70  value:  4708.12076494\n",
      "\tx_diff:  0.151214825398\n",
      "Iter  75  value:  4707.99558589\n",
      "\tx_diff:  0.0507859378292\n",
      "Iter  80  value:  4707.84655182\n",
      "\tx_diff:  5.03116679663\n",
      "Iter  85  value:  4707.78864737\n",
      "\tx_diff:  0.0120855979317\n",
      "Iter  90  value:  4707.76778004\n",
      "\tx_diff:  0.00139420578412\n",
      "Iter  95  value:  4707.76668707\n",
      "\tx_diff:  2.39561476079e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 4707.766687\n",
      "         Iterations: 95\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 92\n",
      "         Hessian evaluations: 0\n",
      "VB time:  170.14013528823853\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region with few draws.')\n",
    "num_gh_points = 4\n",
    "vb_time = time.time()\n",
    "opt_x = tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=200)\n",
    "vb_time_opt_1 = time.time() - vb_time\n",
    "#print('vb_time_opt_1: ', vb_time_opt_1)\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "# print('Running Newton Trust Region with more draws')\n",
    "# num_gh_points = 20\n",
    "# # vb_time = time.time()\n",
    "# opt_x = tr_optimize(opt_x, num_gh_points, gtol=1e-6, maxiter=100)\n",
    "# vb_time = time.time() - vb_time\n",
    "\n",
    "print('VB time: ', vb_time)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glmm_par.set_free(opt_x)\n",
    "if simulate_data:\n",
    "    print('Fit beta: ', glmm_par['beta'].e())\n",
    "    print('True beta: ', true_beta)\n",
    "    \n",
    "    print('Fit mu: ', glmm_par['mu'].e())\n",
    "    print('True mu: ', true_mu)\n",
    "    \n",
    "    print('Fit tau: ', glmm_par['tau'].e())\n",
    "    print('True tau: ', true_tau)\n",
    "    \n",
    "    plt.plot(true_u, true_u, 'r.')\n",
    "    plt.plot(true_u, glmm_par['u'].e(), 'k.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.14010000228882\n",
      "3.528594970703125e-05\n"
     ]
    }
   ],
   "source": [
    "print(vb_time_opt_1)\n",
    "print(vb_time - vb_time_opt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB time:  170.14013528823853\n",
      "[ 1.2348191  -0.16889091  0.13661964 -0.12919619  0.14628128]\n",
      "GLMM Parameters:\n",
      "\tmu:\n",
      "mu_mean: [ 0.57417067]\n",
      "mu_info: [ 59.70367101]\n",
      "\ttau:\n",
      "tau_shape: [ 52.99999999]\n",
      "tau_rate: [ 88.78663254]\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 1.2348191  -0.16889091  0.13661964 -0.12919619  0.14628128]\n",
      "beta_info:\n",
      "[[  5821.22287588   7441.49884427   8215.92786329   6818.302574\n",
      "    7150.45879805]\n",
      " [  7441.49884427  10625.62799187  10961.86805618   8838.82612345\n",
      "    9340.73804654]\n",
      " [  8215.92786329  10961.86805618  12418.43777193   9559.14862539\n",
      "   10203.02966826]\n",
      " [  6818.302574     8838.82612345   9559.14862539   9626.51679796\n",
      "    8173.1594143 ]\n",
      " [  7150.45879805   9340.73804654  10203.02966826   8173.1594143\n",
      "    9147.2886467 ]]\n",
      "\tu:\n",
      "u_mean:\n",
      "[-1.73375944 -0.67082099  0.20001149  1.49828711  2.58709269  1.25125989\n",
      "  0.33298407 -1.79348605 -1.51612165  1.64790981  1.06840909  0.13756032\n",
      "  2.58571922  0.79160002  2.04971571  1.08314311  0.84975832  1.23647945\n",
      "  1.3850553  -0.35460523  0.45045497  0.4320226  -0.01126006  1.6041814\n",
      "  3.33243408  1.72440912  0.07324527  0.07550393  1.24989765 -0.65157725\n",
      " -0.81718683 -0.2169668   1.62685701  1.51536134 -0.27158218 -0.87608995\n",
      "  2.93555339 -0.23648932 -0.45486834  0.65328644  0.92451765 -0.24909313\n",
      "  0.84763321 -1.2349605  -0.08902599 -0.92814584  1.5013698  -0.74335341\n",
      "  0.46913755  2.30356476  2.21554737  0.00632316  1.34521216 -0.70505683\n",
      " -2.43527121 -1.87733699 -0.61776653 -0.41719234  1.16072633 -1.50389564\n",
      " -0.8091024   1.62344285  0.22435309  1.84916842  2.07101467  1.53423832\n",
      " -0.74558416  0.24187709 -0.08261581 -0.08204419  1.76870834  2.09599318\n",
      "  0.80757147 -1.31232469  0.14636921  0.48593051 -0.66671069  1.40191572\n",
      "  1.58617384  2.35615608  0.5140276   0.38715584  0.28741075 -1.57870186\n",
      "  1.21309151  0.44399581 -0.02172671  0.2288822   1.91203597  2.71666865\n",
      "  1.85380031  1.82783544  0.60219537 -0.70209089  3.19665169  0.36374476\n",
      "  1.5684251   0.03332151  1.18325256  2.15586668]\n",
      "u_info:\n",
      "[  2.93082938   8.9713863    9.7858811   12.31351622  24.01695133\n",
      "  29.07737126   3.3032975    3.95311563   3.77273534  16.28033855\n",
      "  16.77875688   2.60857471   6.44964835  24.43331469  27.45182693\n",
      "  12.48620091   2.05125188   2.4203939   47.62626685   2.01044953\n",
      "   4.12582494  26.78261215  21.88408645  12.30192006  29.25971311\n",
      "   8.31472476  16.39706601  11.93000345  36.05729482   3.16344848\n",
      "  10.05618281   5.6465226   59.6045063   17.11975888   4.74429539\n",
      "   7.21063342  37.05515539   9.47952754   2.08406462  12.21644036\n",
      "  11.15746988   1.94891159  34.07925846   1.62785777  19.47465109\n",
      "   6.26770557  48.65102658   3.22291871  14.69817849  22.43272401\n",
      "  19.75839078   6.39764569   1.62350988   2.24818054   2.37170698\n",
      "   4.00255399   1.24106913   2.97126562  32.48929224   1.79448061\n",
      "   5.214436    25.9935902    1.61948899  21.8440119   52.27951566\n",
      "  43.99778578   9.04981091  22.69531403   4.60512307  17.67693996\n",
      "  51.62102722   9.60243798   8.80215017   5.59337141   6.30812175\n",
      "   6.74833667   8.94940084  22.56379029   2.10275708  27.88840877\n",
      "   2.19497112  15.71299291  16.02315572   1.84043157  19.24687719\n",
      "   2.34704414   8.33133892   3.43006916   6.35678233   7.96096348\n",
      "  51.9533633   24.47163433  29.2027396    6.08659433  15.83414498\n",
      "  11.41353839  34.01170471  19.31866128  13.8928313   20.16333896]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7feca2b61710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feca2ca1748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngu2tQZCMTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fecc9f588d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('VB time: ', vb_time)\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "#glmm_par_opt.set_free(init_par_vec)\n",
    "print(glmm_par_opt['beta'].e())\n",
    "print(glmm_par_opt)\n",
    "\n",
    "#plt.plot(glmm_par_opt['u'].e(), glmm_par_opt['u'].var(), 'k.')\n",
    "\n",
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "\n",
    "z_mean = e_u + np.matmul(model.x_mat, e_beta)\n",
    "#plt.plot(sp.special.expit(z_mean), model.y_vec, 'k.')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 0], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 6.015921\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization.\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian...\\n')\n",
    "kl_hess = objective.fun_free_hessian(opt_x)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_jac = get_moment_jacobian(opt_x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/criteo_subsampled_python_vb_results.json\n",
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/criteo_subsampled_python_vb_results.pkl\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'run_name': run_name,\n",
    "                    'vb_time': vb_time, 'hess_time': hess_time, 'num_gh_points': num_gh_points, \n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "    print(json_output_filename)\n",
    "\n",
    "    \n",
    "    \n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "    pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "    # TODO: save everything needed to reconstruct glmm_par, since the parameters cannot be pickled\n",
    "    # due to having function pointers.\n",
    "    # Unlike with JSON, numpy arrays can be pickled.\n",
    "    pickle_result_dict = {  'glmm_par_dictval': glmm_par_opt.dictval(),\n",
    "                            'glmm_par_vector': glmm_par_opt.get_vector(),\n",
    "                            'glmm_par_free': glmm_par_opt.get_free(),\n",
    "                            'run_name': run_name,\n",
    "                            'vb_time': vb_time,\n",
    "                            'hess_time': hess_time,\n",
    "                            'num_gh_points': num_gh_points, \n",
    "                            'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                            'moment_jac': np.squeeze(moment_jac),\n",
    "                            'elbo_hess': np.squeeze(elbo_hess),\n",
    "                            'log_prior_hess': np.squeeze(log_prior_hess) }\n",
    "\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(pickle_result_dict, pickle_output)\n",
    "    pickle_output.close()\n",
    "    \n",
    "    print(pickle_output_filename)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
