{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['K', 'tau_prior_beta', 'beta_prior_mean', 'NG', 'y_group', 'mu_prior_mean', 'N', 'mu_prior_info', 'tau_prior_alpha', 'beta_prior_info', 'x', 'y'])\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "    #analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                            'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    json_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    stan_dat = json_dat['stan_dat']\n",
    "    #vp_base = json_dat['vp_base']\n",
    "\n",
    "    print(stan_dat.keys())\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    #N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    prior_par['beta_prior_mean'].set(np.array(stan_dat['beta_prior_mean']))\n",
    "\n",
    "    prior_par['beta_prior_info'].set(np.array(stan_dat['beta_prior_info']))\n",
    "\n",
    "    prior_par['mu_prior_mean'].set(stan_dat['mu_prior_mean'][0])\n",
    "    prior_par['mu_prior_info'].set(stan_dat['mu_prior_info'][0])\n",
    "    \n",
    "    prior_par['tau_prior_alpha'].set(stan_dat['tau_prior_alpha'][0])\n",
    "    prior_par['tau_prior_beta'].set(stan_dat['tau_prior_beta'][0])\n",
    "    \n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(\n",
    "        K=K, NG=NG, \n",
    "        mu_info_min=0.001, tau_alpha_min=0.001,\n",
    "        tau_beta_min=0.001, beta_diag_min=0.001,\n",
    "        u_info_min=0.001)\n",
    "\n",
    "\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "glmm_init = False\n",
    "if glmm_init and not simulate_data:\n",
    "    # Initialize with GLMM.\n",
    "    # If you use this, don't forget to add the computation time to your final VB time!\n",
    "    glmm_time = 0.\n",
    "\n",
    "    glmm_fit = json_dat['glmm_fit']\n",
    "    glmm_par['mu'].mean.set(glmm_fit['mu_mean'][0])\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    tau_mean = 1.0 / glmm_fit['mu_sd'][0] ** 2\n",
    "    tau_var = 1.0\n",
    "    glmm_par['tau'].shape.set((tau_mean ** 2) / tau_var)\n",
    "    glmm_par['tau'].rate.set(tau_var / tau_mean)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.array(glmm_fit['beta_mean']))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.array(glmm_fit['u_map']))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "    free_par_vec = glmm_par.get_free()\n",
    "else:\n",
    "    glmm_time = 0.\n",
    "    glmm_par['mu'].mean.set(0.0)\n",
    "    glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "    glmm_par['tau'].shape.set(2.0)\n",
    "    glmm_par['tau'].rate.set(2.0)\n",
    "\n",
    "    glmm_par['beta'].mean.set(np.full(K, 0.0))\n",
    "    glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "    glmm_par['u'].mean.set(np.full(NG, 0.0))\n",
    "    glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector)\n",
    "moment_jac = get_moment_jacobian(init_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.001187564095016569\n",
      "\tGrad time: 0.006480430800002069\n",
      "\tHessian vector product time: 0.014736441796412692\n",
      "\tPrior hess time:  0.06890082359313965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "# # PriorHess evaluates the second order derivative d2 EPrior / dpar dprior_par\n",
    "def get_e_log_prior(prior_vec, free_par):\n",
    "    model.glmm_par.set_free(free_par)\n",
    "    model.prior_par.set_vector(prior_vec)\n",
    "    return model.get_e_log_prior()\n",
    "\n",
    "get_prior_model_grad = autograd.grad(get_e_log_prior, argnum=0)\n",
    "get_prior_hess = autograd.jacobian(get_prior_model_grad, argnum=1)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: objective.fun_free_hvp(free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "def tr_optimize(trust_init, num_gh_points, gtol=1e-6, maxiter=500):\n",
    "    model.set_gh_points(num_gh_points)\n",
    "    objective.logger.initialize()\n",
    "    objective.logger.print_every = 5\n",
    "    vb_opt = optimize.minimize(\n",
    "        lambda par: objective.fun_free(par, verbose=True),\n",
    "        x0=trust_init,\n",
    "        method='trust-ncg',\n",
    "        jac=objective.fun_free_grad,\n",
    "        hessp=objective.fun_free_hvp,\n",
    "        tol=1e-6, options={'maxiter': maxiter, 'disp': True, 'gtol': gtol })\n",
    "    return vb_opt.x\n",
    "\n",
    "def get_moment_vec(vb_opt_x):\n",
    "    glmm_par_opt.set_free(vb_opt_x)\n",
    "    set_moments(glmm_par_opt, moment_par)\n",
    "    return moment_par.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#print(glmm_par)\n",
    "\n",
    "x_t_x = np.matmul(x_mat.transpose(), x_mat)\n",
    "x_t_y = np.matmul(x_mat.transpose(), y_vec)\n",
    "beta_init = np.linalg.solve(x_t_x, x_t_y)\n",
    "#print(beta_init)\n",
    "#plt.plot(sp.special.expit(np.matmul(x_mat, beta_init)), y_vec, 'k.')\n",
    "\n",
    "df = pd.DataFrame({ 'y_g': y_g_vec, 'y': y_vec}).groupby('y_g')\n",
    "#print(df.sum())\n",
    "u_init = np.array(df.sum()) / np.array(df.count()['y'])\n",
    "#plt.figure()\n",
    "print(np.min(y_g_vec))\n",
    "#plt.plot(u_init[y_g_vec], y_vec, 'k.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region with few draws.\n",
      "Iter  0  value:  1034.44059918\n",
      "\tx_diff:  inf\n",
      "Iter  5  value:  222.349417308\n",
      "\tx_diff:  1.42822867231\n",
      "Iter  10  value:  76.7117519695\n",
      "\tx_diff:  0.916654154504\n",
      "Iter  15  value:  69.3355009275\n",
      "\tx_diff:  0.159558673608\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 69.330981\n",
      "         Iterations: 19\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 20\n",
      "         Hessian evaluations: 0\n",
      "VB time:  3.5663294792175293\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region with few draws.')\n",
    "num_gh_points = 4\n",
    "vb_time = time.time()\n",
    "opt_x = tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "vb_time_opt_1 = time.time() - vb_time\n",
    "#print('vb_time_opt_1: ', vb_time_opt_1)\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "# print('Running Newton Trust Region with more draws')\n",
    "# num_gh_points = 20\n",
    "# # vb_time = time.time()\n",
    "# opt_x = tr_optimize(opt_x, num_gh_points, gtol=1e-6, maxiter=100)\n",
    "# vb_time = time.time() - vb_time\n",
    "\n",
    "print('VB time: ', vb_time)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "glmm_par.set_free(opt_x)\n",
    "if simulate_data:\n",
    "    print('Fit beta: ', glmm_par['beta'].e())\n",
    "    print('True beta: ', true_beta)\n",
    "    \n",
    "    print('Fit mu: ', glmm_par['mu'].e())\n",
    "    print('True mu: ', true_mu)\n",
    "    \n",
    "    print('Fit tau: ', glmm_par['tau'].e())\n",
    "    print('True tau: ', true_tau)\n",
    "    \n",
    "    plt.plot(true_u, true_u, 'r.')\n",
    "    plt.plot(true_u, glmm_par['u'].e(), 'k.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.566304922103882\n",
      "2.4557113647460938e-05\n"
     ]
    }
   ],
   "source": [
    "print(vb_time_opt_1)\n",
    "print(vb_time - vb_time_opt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB time:  3.5663294792175293\n",
      "[ 0.72659812  1.89783076  3.31028161  4.19112418  5.2443219 ]\n",
      "GLMM Parameters:\n",
      "\tmu:\n",
      "mu_mean: [-3.58689269]\n",
      "mu_info: [ 101.79848479]\n",
      "\ttau:\n",
      "tau_shape: [ 52.99999978]\n",
      "tau_rate: [ 52.06875819]\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 0.72659812  1.89783076  3.31028161  4.19112418  5.2443219 ]\n",
      "beta_info:\n",
      "[[ 19.90139139   1.537584     1.79316044   1.1716148    1.44494035]\n",
      " [  1.537584    19.93884551  -0.60244701   1.59036098  -1.15202817]\n",
      " [  1.79316044  -0.60244701  14.07471897  -0.53789248  -2.55185057]\n",
      " [  1.1716148    1.59036098  -0.53789248  15.79077914  -3.45016328]\n",
      " [  1.44494035  -1.15202817  -2.55185057  -3.45016328  13.44048995]]\n",
      "\tu:\n",
      "u_mean:\n",
      "[-3.07347311 -3.57603209 -3.77950233 -4.44325575 -3.51764448 -3.88686897\n",
      " -3.69932252 -3.76567835 -2.73880961 -3.47690654 -2.7855888  -3.27113769\n",
      " -3.71875716 -3.79701444 -3.59067252 -3.06494631 -3.30427204 -4.17309857\n",
      " -3.80269617 -3.0318877  -2.58949618 -3.65957655 -3.65687996 -4.557617\n",
      " -3.24092232 -4.29173848 -3.64939983 -3.59042534 -3.26547184 -2.95149865\n",
      " -3.55924642 -3.22150952 -3.51662309 -3.91293868 -3.18999938 -5.26936888\n",
      " -3.75641486 -3.80129731 -3.99644747 -3.37691368 -3.71261178 -3.49979855\n",
      " -2.90661459 -4.46106501 -4.19852837 -4.08712484 -3.04837942 -3.73073457\n",
      " -3.18314014 -3.52485452 -3.37844444 -4.01785149 -3.26401197 -3.72593705\n",
      " -3.47404717 -2.71697705 -3.19494186 -4.04122059 -4.71912475 -3.18202238\n",
      " -3.45058713 -3.57171988 -3.59563886 -3.32284126 -3.55482871 -2.33546373\n",
      " -3.88661572 -3.8431336  -2.44868017 -3.67833561 -3.80210575 -4.03586476\n",
      " -3.46710514 -5.00256896 -3.94056508 -2.92433261 -3.86005195 -3.11233637\n",
      " -3.77678241 -4.16503214 -3.19013085 -4.28821718 -3.92603254 -3.21504569\n",
      " -3.69451899 -3.18543553 -3.58685699 -2.53995339 -3.90909578 -4.35968363\n",
      " -3.58540788 -4.09314918 -3.01384931 -3.16966386 -3.82105631 -3.66944105\n",
      " -3.63394111 -3.81683102 -3.54054702 -3.09227914]\n",
      "u_info:\n",
      "[ 1.35611917  1.20191024  1.89846289  1.29253722  1.60715977  1.27875136\n",
      "  1.12977566  1.17837465  1.35793672  1.34245278  1.41313355  1.32249391\n",
      "  1.41825946  1.5688267   1.04246587  1.65808003  1.28589789  1.23830225\n",
      "  1.26589966  1.26733241  1.64999888  1.12376846  1.90124948  1.26151499\n",
      "  1.5058815   1.34056728  1.61465394  1.31880798  1.2518474   1.52704986\n",
      "  1.55865165  1.40498267  1.54681919  1.25506444  1.33554364  1.66965372\n",
      "  1.19566793  1.20896452  1.22711429  1.33841164  1.17197699  1.3088197\n",
      "  1.51134491  1.43142609  1.57618665  1.39166878  1.96531141  1.68309381\n",
      "  1.44924507  1.16971442  1.46263554  1.57526742  1.85358932  1.45786661\n",
      "  1.50434064  1.67598188  1.41357706  1.73915073  1.31319795  1.35869796\n",
      "  1.58803274  1.23599701  1.02844574  1.60534681  1.47278172  1.38890217\n",
      "  1.3645802   1.51188241  1.81835619  1.21658506  1.71078074  1.69776172\n",
      "  1.45284909  1.5216251   1.49436667  1.54721997  1.61704845  1.80239891\n",
      "  1.19672792  1.37726341  1.29853555  1.26719715  1.46664974  1.35598478\n",
      "  1.48550901  1.31559767  1.41547003  1.53101952  1.24907573  1.22403085\n",
      "  1.52623257  1.32880083  1.50171231  1.26829775  1.41176491  1.54674257\n",
      "  1.52454116  1.6287362   1.60294082  1.58553608]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f4f544e6cf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f32efbc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuI4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f77cdc8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('VB time: ', vb_time)\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(opt_x)\n",
    "#glmm_par_opt.set_free(init_par_vec)\n",
    "print(glmm_par_opt['beta'].e())\n",
    "print(glmm_par_opt)\n",
    "\n",
    "#plt.plot(glmm_par_opt['u'].e(), glmm_par_opt['u'].var(), 'k.')\n",
    "\n",
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "\n",
    "z_mean = e_u + np.matmul(model.x_mat, e_beta)\n",
    "#plt.plot(sp.special.expit(z_mean), model.y_vec, 'k.')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z_mean[model.y_vec == 0], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.title('y == 0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 1.930953\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization.\n",
    "\n",
    "hess_time = time.time()\n",
    "print('KL Hessian...\\n')\n",
    "kl_hess = objective.fun_free_hessian(opt_x)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print('hess_time: %f' % hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_jac = get_moment_jacobian(opt_x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/simulated_data_small_python_vb_results.json\n",
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/simulated_data_small_python_vb_results.pkl\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a JSON file for use in R.\n",
    "    \n",
    "    run_name = 'production'\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'run_name': run_name,\n",
    "                    'vb_time': vb_time, 'hess_time': hess_time, 'num_gh_points': num_gh_points, \n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "    print(json_output_filename)\n",
    "\n",
    "    \n",
    "    \n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "    pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "    # TODO: save everything needed to reconstruct glmm_par, since the parameters cannot be pickled\n",
    "    # due to having function pointers.\n",
    "    # Unlike with JSON, numpy arrays can be pickled.\n",
    "    pickle_result_dict = {  'glmm_par_dictval': glmm_par_opt.dictval(),\n",
    "                            'glmm_par_vector': glmm_par_opt.get_vector(),\n",
    "                            'glmm_par_free': glmm_par_opt.get_free(),\n",
    "                            'run_name': run_name,\n",
    "                            'vb_time': vb_time,\n",
    "                            'hess_time': hess_time,\n",
    "                            'num_gh_points': num_gh_points, \n",
    "                            'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                            'moment_jac': np.squeeze(moment_jac),\n",
    "                            'elbo_hess': np.squeeze(elbo_hess),\n",
    "                            'log_prior_hess': np.squeeze(log_prior_hess) }\n",
    "\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(pickle_result_dict, pickle_output)\n",
    "    pickle_output.close()\n",
    "    \n",
    "    print(pickle_output_filename)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
