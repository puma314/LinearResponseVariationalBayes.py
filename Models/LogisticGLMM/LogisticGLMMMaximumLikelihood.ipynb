{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, unpack_csr_matrix, get_sparse_hessian\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "analysis_name = 'simulated_data_small'\n",
    "#analysis_name = 'criteo_subsampled'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n",
    "\n",
    "\n",
    "pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "\n",
    "pkl_file = open(pickle_output_filename, 'rb')\n",
    "vb_results = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mu_prior_mean', 'tau_prior_beta', 'K', 'N', 'x', 'beta_prior_mean', 'mu_prior_info', 'y', 'NG', 'tau_prior_alpha', 'beta_prior_info', 'y_group'])\n"
     ]
    }
   ],
   "source": [
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "y_g_vec, y_vec, x_mat, glmm_par, prior_par = logit_glmm.load_json_data(json_filename)\n",
    "\n",
    "K = x_mat.shape[1]\n",
    "NG = np.max(y_g_vec) + 1\n",
    "\n",
    "# Define moment parameters\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['beta_mean', 'beta_sd', 'glmm_time', 'mu_mean', 'tau_mean', 'u_cond_sd', 'beta_par', 'u_map', 'mu_sd'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the glmer results\n",
    "glmer_json_filename = os.path.join(data_dir, '%s_glmer_results.json' % analysis_name)\n",
    "json_file = open(glmer_json_filename, 'r')\n",
    "glmer_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "print(glmer_dat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_mle_parameters(K, NG):\n",
    "    mle_par = vb.ModelParamsDict('GLMER Parameters')\n",
    "    mle_par.push_param(vb.VectorParam('mu'))\n",
    "    mle_par.push_param(vb.VectorParam('tau'))\n",
    "    mle_par.push_param(vb.VectorParam('beta', K))\n",
    "    mle_par.push_param(vb.VectorParam('u', NG))\n",
    "\n",
    "    return mle_par\n",
    "\n",
    "def get_data_log_lik_terms(mle_par, x_mat, y_vec, y_g_vec):\n",
    "    beta = mle_par['beta'].get()\n",
    "\n",
    "    # atleast_1d is necessary for indexing by y_g_vec to work right.\n",
    "    e_u = np.atleast_1d(mle_par['u'].get())\n",
    "\n",
    "    # Log likelihood from data.\n",
    "    z = e_u[y_g_vec] + np.squeeze(np.matmul(x_mat, beta))\n",
    "\n",
    "    return y_vec * z - np.log1p(np.exp(z))\n",
    "\n",
    "def get_re_log_lik(mle_par):\n",
    "    mu = mle_par['mu'].get()\n",
    "    tau = mle_par['tau'].get()\n",
    "    u = mle_par['u'].get()\n",
    "\n",
    "    return -0.5 * tau * np.sum(\n",
    "        ((mu - u) ** 2)) +  0.5 * np.log(tau) * glmm_par['u'].size()\n",
    "\n",
    "def get_log_prior(mle_par, prior_par):\n",
    "    beta = mle_par['beta'].get()\n",
    "    mu = mle_par['mu'].get()\n",
    "    tau = mle_par['tau'].get()\n",
    "\n",
    "    K = len(beta)\n",
    "    log_p_beta = ef.mvn_prior(\n",
    "        prior_mean = prior_par['beta_prior_mean'].get(),\n",
    "        prior_info = prior_par['beta_prior_info'].get(),\n",
    "        e_obs = beta,\n",
    "        cov_obs = np.zeros((K, K)))\n",
    "\n",
    "    log_p_mu = ef.uvn_prior(\n",
    "        prior_mean = prior_par['mu_prior_mean'].get(),\n",
    "        prior_info = prior_par['mu_prior_info'].get(),\n",
    "        e_obs = mu,\n",
    "        var_obs = 0.0)\n",
    "\n",
    "    log_p_tau = ef.gamma_prior(\n",
    "        prior_shape = prior_par['tau_prior_alpha'].get(),\n",
    "        prior_rate = prior_par['tau_prior_beta'].get(),\n",
    "        e_obs = tau,\n",
    "        e_log_obs = np.log(tau))\n",
    "\n",
    "    return log_p_beta + log_p_mu + log_p_tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticGLMMMaximumLikelihood(object):\n",
    "    def __init__(self, mle_par, prior_par, x_mat, y_vec, y_g_vec):\n",
    "\n",
    "        self.mle_par = copy.deepcopy(mle_par)\n",
    "        self.prior_par = copy.deepcopy(prior_par)\n",
    "        self.x_mat = np.array(x_mat)\n",
    "        self.y_vec = np.array(y_vec)\n",
    "        self.y_g_vec = np.array(y_g_vec)\n",
    "\n",
    "        assert np.min(y_g_vec) == 0\n",
    "        assert np.max(y_g_vec) == self.mle_par['u'].size() - 1\n",
    "\n",
    "\n",
    "    def get_log_lik(self):\n",
    "        data_log_lik = np.sum(get_data_log_lik_terms(\n",
    "            mle_par = self.mle_par,\n",
    "            x_mat = self.x_mat,\n",
    "            y_vec = self.y_vec,\n",
    "            y_g_vec = self.y_g_vec))\n",
    "        re_log_lik = get_re_log_lik(self.mle_par)\n",
    "        log_prior = get_log_prior(self.mle_par, self.prior_par)\n",
    "        return np.squeeze(data_log_lik + re_log_lik + log_prior)\n",
    "    \n",
    "    def get_log_loss(self):\n",
    "        return -1 * self.get_log_lik()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-174.46702524191048\n",
      "174.467025242\n"
     ]
    }
   ],
   "source": [
    "mle_par = get_mle_parameters(K=K, NG=NG)\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "glmm_par.set_free(vb_results['glmm_par_free'])\n",
    "\n",
    "set_from_glmer = True\n",
    "if set_from_glmer:\n",
    "    mle_par['beta'].set(np.array(glmer_dat['beta_mean']))\n",
    "    mle_par['mu'].set(np.array(glmer_dat['mu_mean']))\n",
    "    mle_par['tau'].set(np.array(glmer_dat['tau_mean']))\n",
    "    mle_par['u'].set(np.array(glmer_dat['u_map']))\n",
    "else:\n",
    "    # Set from VB\n",
    "    mle_par['beta'].set(glmm_par['beta'].e())\n",
    "    mle_par['mu'].set(glmm_par['mu'].e())\n",
    "    mle_par['tau'].set(glmm_par['tau'].e())\n",
    "    mle_par['u'].set(glmm_par['u'].e())\n",
    "\n",
    "model = LogisticGLMMMaximumLikelihood(mle_par, prior_par, x_mat, y_vec, y_g_vec)\n",
    "print(model.get_log_lik())\n",
    "\n",
    "objective = Objective(fun=model.get_log_loss, par=model.mle_par['u'])\n",
    "print(objective.fun_free(model.mle_par['u'].get_free()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  1418.11311409\n",
      "\tx_diff:  inf\n",
      "Iter  1  value:  1355.83340249\n",
      "\tx_diff:  0.177328106601\n",
      "Iter  2  value:  1236.05208963\n",
      "\tx_diff:  0.354477044041\n",
      "Iter  3  value:  1015.64467796\n",
      "\tx_diff:  0.70724232857\n",
      "Iter  4  value:  651.245659754\n",
      "\tx_diff:  1.40030049949\n",
      "Iter  5  value:  220.164710037\n",
      "\tx_diff:  2.67844571696\n",
      "Iter  6  value:  139.077697203\n",
      "\tx_diff:  1.56086077267\n",
      "Iter  7  value:  137.790996119\n",
      "\tx_diff:  0.387151010828\n",
      "Iter  8  value:  137.739016592\n",
      "\tx_diff:  0.109280391847\n",
      "Iter  9  value:  137.735564943\n",
      "\tx_diff:  0.0311048636224\n",
      "Iter  10  value:  137.735265342\n",
      "\tx_diff:  0.0121174715304\n",
      "Iter  11  value:  137.735265223\n",
      "\tx_diff:  0.000152520140333\n",
      "Iter  12  value:  137.735265223\n",
      "\tx_diff:  1.41684987298e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 137.735265\n",
      "         Iterations: 12\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#u_free_init = model.mle_par['u'].get_free()\n",
    "u_free_init = np.random.random(model.mle_par['u'].free_size())\n",
    "objective.logger.initialize()\n",
    "objective.logger.print_every = 1\n",
    "mle_opt = optimize.minimize(\n",
    "    lambda par: objective.fun_free(par, verbose=True),\n",
    "    x0=u_free_init,\n",
    "    method='trust-ncg',\n",
    "    jac=objective.fun_free_grad,\n",
    "    hessp=objective.fun_free_hvp,\n",
    "    tol=1e-6, options={'maxiter': 200, 'disp': True, 'gtol': 1e-6 })\n",
    "u_free_opt = mle_opt.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b8a1e4a90>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nllAOAGZmCfX/AY66a9o7m5MRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b8a20e668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.mle_par['u'].set_free(z_free_opt)\n",
    "u_mle = model.mle_par['u'].get()\n",
    "\n",
    "glmm_par.set_free(vb_results['glmm_par_free'])\n",
    "u_vb = glmm_par['u'].e()\n",
    "\n",
    "plt.plot(u_vb, u_mle, 'k.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
