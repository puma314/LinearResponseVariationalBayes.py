{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "import VariationalBayes.SparseObjectives as obj_lib\n",
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import autograd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scikits.sparse.cholmod import cholesky\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_simulated_data = False\n",
    "if use_simulated_data:\n",
    "    # Used 2, 5, 10, 20, 40, 60, 100\n",
    "    num_obs_per_group = 100\n",
    "    analysis_name = 'simulated_data_for_refit_{}'.format(num_obs_per_group)\n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_refit_jackknife_results.pkl' % analysis_name)\n",
    "else:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    analysis_name = 'criteo_subsampled'\n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "\n",
    "pkl_file = open(pickle_output_filename, 'rb')\n",
    "\n",
    "vb_data = pickle.load(pkl_file)\n",
    "model = logit_glmm.load_model_from_pickle(vb_data)\n",
    "timer = obj_lib.Timer()\n",
    "kl_hess = obj_lib.unpack_csr_matrix(vb_data['kl_hess_packed'])\n",
    "moment_jac = vb_data['moment_jac']\n",
    "moment_wrapper = logit_glmm.MomentWrapper(model.glmm_par)\n",
    "opt_glmm_free_par = vb_data['glmm_par_free']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_with_weights(\n",
    "    model, weights, init_par, preconditioner, gtol=1e-8, print_every=1, verbose=True):\n",
    "\n",
    "    model.use_weights = True\n",
    "    model.weights = copy.deepcopy(weights)\n",
    "    preconditioned_init_par = sp.sparse.linalg.spsolve(preconditioner, init_par)\n",
    "    return model.tr_optimize_cond(\n",
    "        preconditioned_init_par,\n",
    "        preconditioner=preconditioner,\n",
    "        num_gh_points=model.num_gh_points,\n",
    "        gtol=gtol,\n",
    "        print_every=print_every,\n",
    "        verbose=verbose)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-condition with the KL Hessian from the original analysis.\n",
    "preconditioner = sp.sparse.diags([1 / np.sqrt(kl_hess.diagonal())], [0])\n",
    "preconditioner = sp.sparse.csr_matrix(preconditioner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61895.0\n",
      "Iter  0  value:  23825.6016424\n",
      "Iter  1  value:  23825.6016424\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: 23825.601642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "base_weights = np.full(model.x_mat.shape[0], 1.0)\n",
    "print(np.sum(base_weights))\n",
    "base_opt = optimize_with_weights(\n",
    "    model=model,\n",
    "    preconditioner=preconditioner,\n",
    "    weights=base_weights,\n",
    "    init_par=opt_glmm_free_par,\n",
    "    gtol=1e-8)\n",
    "base_free_par = model.objective.uncondition_x(base_opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moment_jac_time: 7.704058885574341 seconds\n"
     ]
    }
   ],
   "source": [
    "timer.tic()\n",
    "moment_jac = moment_wrapper.get_moment_jacobian(base_free_par)\n",
    "timer.toc('moment_jac_time')\n",
    "moment_jac_sp = sp.sparse.csr_matrix(moment_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 of 4999\n",
      "Group 200 of 4999\n",
      "Group 400 of 4999\n",
      "Group 600 of 4999\n",
      "Group 800 of 4999\n",
      "Group 1000 of 4999\n",
      "Group 1200 of 4999\n",
      "Group 1400 of 4999\n",
      "Group 1600 of 4999\n",
      "Group 1800 of 4999\n",
      "Group 2000 of 4999\n",
      "Group 2200 of 4999\n",
      "Group 2400 of 4999\n",
      "Group 2600 of 4999\n",
      "Group 2800 of 4999\n",
      "Group 3000 of 4999\n",
      "Group 3200 of 4999\n",
      "Group 3400 of 4999\n",
      "Group 3600 of 4999\n",
      "Group 3800 of 4999\n",
      "Group 4000 of 4999\n",
      "Group 4200 of 4999\n",
      "Group 4400 of 4999\n",
      "Group 4600 of 4999\n",
      "Group 4800 of 4999\n",
      "weight_jac_time: 61.729551792144775 seconds\n",
      "Jacobian time:  61.729551792144775\n"
     ]
    }
   ],
   "source": [
    "# Get a sparse Jacobian.\n",
    "timer.tic()\n",
    "weight_jacobian = model.get_sparse_weight_free_jacobian(base_free_par, print_every_n=200)\n",
    "timer.toc('weight_jac_time')\n",
    "print('Jacobian time: ', timer.time_dict['weight_jac_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 of 4999.\n",
      "Group 200 of 4999.\n",
      "Group 400 of 4999.\n",
      "Group 600 of 4999.\n",
      "Group 800 of 4999.\n",
      "Group 1000 of 4999.\n",
      "Group 1200 of 4999.\n",
      "Group 1400 of 4999.\n",
      "Group 1600 of 4999.\n",
      "Group 1800 of 4999.\n",
      "Group 2000 of 4999.\n",
      "Group 2200 of 4999.\n",
      "Group 2400 of 4999.\n",
      "Group 2600 of 4999.\n",
      "Group 2800 of 4999.\n",
      "Group 3000 of 4999.\n",
      "Group 3200 of 4999.\n",
      "Group 3400 of 4999.\n",
      "Group 3600 of 4999.\n",
      "Group 3800 of 4999.\n",
      "Group 4000 of 4999.\n",
      "Group 4200 of 4999.\n",
      "Group 4400 of 4999.\n",
      "Group 4600 of 4999.\n",
      "Group 4800 of 4999.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess_time: 70.28769063949585 seconds\n",
      "Hessian time:  70.28769063949585\n"
     ]
    }
   ],
   "source": [
    "# Get a sparse Hessian.\n",
    "timer.tic()\n",
    "kl_hess = model.get_sparse_free_hessian(base_free_par, print_every_n=200)\n",
    "timer.toc('hess_time')\n",
    "print('Hessian time: ', timer.time_dict['hess_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky...\n",
      "choesky_time: 0.01992940902709961 seconds\n",
      "Solving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: CholmodTypeConversionWarning: converting matrix of class csr_matrix to CSC format\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverse_time: 11.018663167953491 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Invert to get parameter sensitivity.\n",
    "print('Cholesky...')\n",
    "timer.tic()\n",
    "kl_hess_chol = cholesky(kl_hess)\n",
    "timer.toc('choesky_time')\n",
    "\n",
    "print('Solving...')\n",
    "timer.tic()\n",
    "param_boot_mat = -1 * kl_hess_chol.solve_A(weight_jacobian.T)\n",
    "timer.toc('inverse_time')\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply\n",
      "weight_jac_mult: 0.004601478576660156 seconds\n",
      "Solving with weights...\n",
      "weight_inverse_time: 0.0019378662109375 seconds\n"
     ]
    }
   ],
   "source": [
    "num_obs = model.x_mat.shape[0]\n",
    "boot_draw = np.random.multinomial(num_obs, [1. / num_obs] * num_obs, size=1)\n",
    "boot_draw = np.asarray(np.squeeze(boot_draw))\n",
    "boot_diff_sp = sp.sparse.csc_matrix(boot_draw - 1.0).T\n",
    "\n",
    "print('Multiply')\n",
    "timer.tic()\n",
    "weight_mat = weight_jacobian.T.dot(boot_diff_sp)\n",
    "timer.toc('weight_jac_mult')\n",
    "\n",
    "print('Solving with weights...')\n",
    "timer.tic()\n",
    "kl_weight_mat = -1 * kl_hess_chol.solve_A(weight_mat)\n",
    "timer.toc('weight_inverse_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sparse: 0.0023086071014404297 seconds\n",
      "single lr bootstrap dot: 0.7441492080688477 seconds\n",
      "single lr bootstrap: 0.6968855857849121 seconds\n",
      "fast bootstrap: 0.002902984619140625 seconds\n",
      "(10014, 1)\n",
      "(10014, 1)\n",
      "1.16983318757e-12\n"
     ]
    }
   ],
   "source": [
    "num_obs = model.x_mat.shape[0]\n",
    "boot_draw = np.random.multinomial(num_obs, [1. / num_obs] * num_obs, size=1)\n",
    "boot_draw = np.asarray(np.squeeze(boot_draw))\n",
    "\n",
    "timer.tic()\n",
    "boot_diff_sp = sp.sparse.csc_matrix(boot_draw - 1.0).T\n",
    "timer.toc('Make sparse')\n",
    "\n",
    "timer.tic()\n",
    "lr_param_diff = param_boot_mat.dot(boot_diff_sp) \n",
    "timer.toc('single lr bootstrap dot')\n",
    "\n",
    "timer.tic()\n",
    "lr_param_diff = param_boot_mat * boot_diff_sp\n",
    "timer.toc('single lr bootstrap')\n",
    "\n",
    "timer.tic()\n",
    "lr_param_diff_fast = -1 * kl_hess_chol.solve_A(weight_jacobian.T.dot(boot_diff_sp))\n",
    "timer.toc('fast bootstrap')\n",
    "\n",
    "print(sp.sparse.linalg.norm(lr_param_diff_fast - lr_param_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10014, 61895)\n",
      "619816530\n",
      "619816530\n"
     ]
    }
   ],
   "source": [
    "print(param_boot_mat.shape)\n",
    "print(np.prod(param_boot_mat.shape))\n",
    "print(param_boot_mat.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_bootstrap(model, param_boot_mat, base_free_par):\n",
    "    num_obs = model.x_mat.shape[0]\n",
    "    boot_draw = np.random.multinomial(num_obs, [1. / num_obs] * num_obs, size=1)\n",
    "    boot_draw = np.asarray(np.squeeze(boot_draw))\n",
    "    boot_diff_sp = sp.sparse.csc_matrix(boot_draw - 1.0).T\n",
    "    #lr_param_diff = param_boot_mat * boot_diff_sp\n",
    "    # The following line is way faster:\n",
    "    lr_param_diff = -1 * kl_hess_chol.solve_A(weight_jacobian.T.dot(boot_diff_sp))\n",
    "    glmm_par_lr_boot = base_free_par + np.squeeze(lr_param_diff.toarray())\n",
    "    return glmm_par_lr_boot, boot_draw\n",
    "\n",
    "def bootstrap_and_refit(model, preconditioner, param_boot_mat, base_free_par):\n",
    "    glmm_par_lr_boot, boot_draw = lr_bootstrap(model, param_boot_mat, base_free_par)\n",
    "    glmm_par_opt_boot = optimize_with_weights(\n",
    "        model=model,\n",
    "        preconditioner=preconditioner,\n",
    "        init_par=glmm_par_lr_boot,\n",
    "        weights=boot_draw,\n",
    "        gtol=1e-8,\n",
    "        verbose=False)\n",
    "    boot_free_par = model.objective.uncondition_x(glmm_par_opt_boot.x)\n",
    "    return boot_free_par, glmm_par_opt_boot, glmm_par_lr_boot, boot_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10014,)\n",
      "lr_bootstrap_single_run_time: 0.015452384948730469 seconds\n",
      "full_bootstrap_single_run_time: 33.63530898094177 seconds\n"
     ]
    }
   ],
   "source": [
    "timer.tic()\n",
    "lr_bootstrap(model, param_boot_mat, base_free_par)\n",
    "timer.toc('lr_bootstrap_single_run_time')\n",
    "\n",
    "timer.tic()\n",
    "bootstrap_and_refit(model, preconditioner, param_boot_mat, base_free_par)\n",
    "timer.toc('full_bootstrap_single_run_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boot_samples = 50\n",
    "lr_boot_free_par_list = []\n",
    "boot_free_par_list = []\n",
    "boot_draw_list = []\n",
    "timer.tic()\n",
    "for boot in range(num_boot_samples):\n",
    "    if boot % 5 == 0:\n",
    "        print('Bootstrap {} of {}'.format(boot + 1, num_boot_samples))\n",
    "    boot_free_par, glmm_par_opt_boot, glmm_par_lr_boot, boot_draw = \\\n",
    "        bootstrap_and_refit(model, preconditioner, param_boot_mat, base_free_par)\n",
    "    boot_free_par_list.append(boot_free_par)\n",
    "    lr_boot_free_par_list.append(glmm_par_lr_boot)\n",
    "    boot_draw_list.append(boot_draw)\n",
    "timer.toc('bootstrap_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap 0 of 499\n",
      "Bootstrap 50 of 499\n",
      "Bootstrap 100 of 499\n",
      "Bootstrap 150 of 499\n",
      "Bootstrap 200 of 499\n",
      "Bootstrap 250 of 499\n",
      "Bootstrap 300 of 499\n",
      "Bootstrap 350 of 499\n",
      "Bootstrap 400 of 499\n",
      "Bootstrap 450 of 499\n",
      "lr_bootstrap_time: 5.725649833679199 seconds\n"
     ]
    }
   ],
   "source": [
    "lr_boot_free_par_list_long = []\n",
    "num_long_boot_samples = 2000\n",
    "timer.tic()\n",
    "for boot in range(num_long_boot_samples):\n",
    "    if boot % 500 == 0:\n",
    "        print('Bootstrap {} of {}'.format(boot, num_long_boot_samples - 1))\n",
    "    glmm_par_lr_boot, boot_draw = lr_bootstrap(model, param_boot_mat, base_free_par)\n",
    "    lr_boot_free_par_list_long.append(glmm_par_lr_boot)\n",
    "timer.toc('lr_bootstrap_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The actual change in the moment vectors.\n",
    "boot = 2\n",
    "boot_free_par = boot_free_par_list[boot]\n",
    "lr_boot_free_par = lr_boot_free_par_list[boot]\n",
    "\n",
    "moment_vec = moment_wrapper.get_moment_vector_from_free(base_free_par)\n",
    "moment_vec_boot = moment_wrapper.get_moment_vector_from_free(boot_free_par)\n",
    "true_moment_diff = moment_vec_boot - moment_vec\n",
    "print('True param difference: {}'.format(np.linalg.norm(base_free_par - boot_free_par)))\n",
    "print('True moment norm difference: {}'.format(np.linalg.norm(true_moment_diff)))\n",
    "\n",
    "# Use the linear approximation for the parameters, not the moments.\n",
    "moment_pred_from_params = \\\n",
    "    moment_wrapper.get_moment_vector_from_free(lr_boot_free_par)\n",
    "moment_pred_from_params_diff = moment_pred_from_params - moment_vec\n",
    "\n",
    "# The difference based on a linear approximation to the moments.\n",
    "moment_pred_from_moments_diff = moment_jac_sp * (lr_boot_free_par - base_free_par)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linearizing the moments')\n",
    "plt.plot(true_moment_diff, moment_pred_from_moments_diff, 'r+', markersize=10)\n",
    "plt.plot(true_moment_diff, true_moment_diff, 'k.')\n",
    "#plt.axis([-10, 10, -10, 10])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linearizing the parameters')\n",
    "plt.plot(true_moment_diff, moment_pred_from_params_diff, 'bx', markersize=10)\n",
    "plt.plot(true_moment_diff, true_moment_diff, 'k.')\n",
    "#plt.axis([-10, 10, -10, 10])\n",
    "\n",
    "# It doesn't make a difference whether you linearize the moments or parameters.\n",
    "plt.figure()\n",
    "plt.title('Moments vs parameters')\n",
    "plt.plot(moment_pred_from_params_diff, moment_pred_from_moments_diff, 'r+', markersize=10)\n",
    "plt.plot(moment_pred_from_params_diff, moment_pred_from_params_diff, 'k.')\n",
    "#plt.axis([-10, 10, -10, 10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the moments in a list form.\n",
    "\n",
    "lr_boot_moment_vec_list = \\\n",
    "    [ model.moment_wrapper.get_moment_vector_from_free(par) \\\n",
    "      for par in lr_boot_free_par_list ]\n",
    "lr_boot_moment_vec_list_long = \\\n",
    "    [ model.moment_wrapper.get_moment_vector_from_free(par) \\\n",
    "      for par in lr_boot_free_par_list_long ]\n",
    "boot_moment_vec_list = \\\n",
    "    [ model.moment_wrapper.get_moment_vector_from_free(par) \\\n",
    "      for par in boot_free_par_list ]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the result to a pickle file for use in R.\n",
    "\n",
    "run_name = 'jackknife'\n",
    "\n",
    "pickle_result_filename = os.path.join(data_dir, '%s_python_vb_jackknife_results.pkl' % analysis_name)\n",
    "pickle_output = open(pickle_result_filename, 'wb')\n",
    "\n",
    "pickle_result_dict = {  'boot_free_par_list': boot_free_par_list,\n",
    "                        'lr_boot_free_par_list': lr_boot_free_par_list,\n",
    "                        'lr_boot_free_par_list_long': lr_boot_free_par_list_long,\n",
    "                        'lr_boot_moment_vec_list': lr_boot_moment_vec_list,\n",
    "                        'lr_boot_moment_vec_list_long': lr_boot_moment_vec_list_long,\n",
    "                        'boot_moment_vec_list': boot_moment_vec_list,\n",
    "                        'boot_draw_list': boot_draw_list,\n",
    "                        'run_name': run_name,\n",
    "                        'timer': timer,\n",
    "                        'base_free_par': base_free_par,\n",
    "                        'boot_free_par': boot_free_par,\n",
    "                        'weight_jacobian': obj_lib.pack_csr_matrix(sp.sparse.csr_matrix(weight_jacobian)),\n",
    "                        'param_boot_mat': obj_lib.pack_csr_matrix(sp.sparse.csr_matrix(param_boot_mat)) }\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(pickle_result_dict, pickle_output)\n",
    "pickle_output.close()\n",
    "\n",
    "print(pickle_result_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
