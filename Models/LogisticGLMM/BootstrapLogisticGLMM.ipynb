{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "import VariationalBayes.SparseObjectives as vb_sparse\n",
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "analysis_name = 'simulated_data_small'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "pkl_file = open(pickle_output_filename, 'rb')\n",
    "vb_data = pickle.load(pkl_file)\n",
    "\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "\n",
    "json_file = open(json_filename, 'r')\n",
    "json_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "stan_dat = json_dat['stan_dat']\n",
    "\n",
    "K = stan_dat['K'][0]\n",
    "NObs = stan_dat['N'][0]\n",
    "NG = stan_dat['NG'][0]\n",
    "y_g_vec = np.array(stan_dat['y_group'])\n",
    "y_vec = np.array(stan_dat['y'])\n",
    "x_mat = np.array(stan_dat['x'])\n",
    "\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "# Define a class to contain prior parameters.\n",
    "prior_par = logit_glmm.get_default_prior_params(K)\n",
    "prior_par['beta_prior_mean'].set(np.array(stan_dat['beta_prior_mean']))\n",
    "\n",
    "prior_par['beta_prior_info'].set(np.array(stan_dat['beta_prior_info']))\n",
    "\n",
    "prior_par['mu_prior_mean'].set(stan_dat['mu_prior_mean'][0])\n",
    "prior_par['mu_prior_info'].set(stan_dat['mu_prior_info'][0])\n",
    "\n",
    "prior_par['tau_prior_alpha'].set(stan_dat['tau_prior_alpha'][0])\n",
    "prior_par['tau_prior_beta'].set(stan_dat['tau_prior_beta'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticGLMMLogPosterior(object):\n",
    "    def __init__(\n",
    "        self, glmm_par_draw, prior_par, x_mat, y_vec, y_g_vec):\n",
    "\n",
    "        self.glmm_par_draw = copy.deepcopy(glmm_par_draw)\n",
    "        self.prior_par = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        self.K = x_mat.shape[1]\n",
    "\n",
    "        assert np.min(y_g_vec) == 0\n",
    "        assert np.max(y_g_vec) == self.glmm_par_draw['u'].size() - 1\n",
    "\n",
    "    def get_log_prior(self):\n",
    "        beta = self.glmm_par_draw['beta'].get()\n",
    "        mu = self.glmm_par_draw['mu'].get()\n",
    "        tau = self.glmm_par_draw['tau'].get()\n",
    "        log_tau = np.log(tau)\n",
    "        \n",
    "        cov_beta = np.zeros((self.K, self.K))\n",
    "        beta_prior_info = self.prior_par['beta_prior_info'].get()\n",
    "        beta_prior_mean = self.prior_par['beta_prior_mean'].get()\n",
    "        log_p_beta = ef.mvn_prior(\n",
    "            beta_prior_mean, beta_prior_info, beta, cov_beta)\n",
    "\n",
    "        log_p_mu = ef.uvn_prior(\n",
    "            self.prior_par['mu_prior_mean'].get(),\n",
    "            self.prior_par['mu_prior_info'].get(), mu, 0.0)\n",
    "\n",
    "        tau_prior_shape = self.prior_par['tau_prior_alpha'].get()\n",
    "        tau_prior_rate = self.prior_par['tau_prior_beta'].get()\n",
    "        log_p_tau = ef.gamma_prior(\n",
    "            tau_prior_shape, tau_prior_rate, tau, log_tau)\n",
    "\n",
    "        return log_p_beta + log_p_mu + log_p_tau\n",
    "\n",
    "    def get_log_lik(self):\n",
    "        beta = self.glmm_par_draw['beta'].get()\n",
    "        u = self.glmm_par_draw['u'].get()\n",
    "        mu = self.glmm_par_draw['mu'].get()\n",
    "        tau = self.glmm_par_draw['tau'].get()\n",
    "        log_tau = np.log(tau)\n",
    "\n",
    "        log_lik = 0.\n",
    "\n",
    "        # Log likelihood from data.\n",
    "        z = u[self.y_g_vec] + np.matmul(self.x_mat, beta)\n",
    "        log_lik += np.sum(self.y_vec * z - np.log1p(np.exp(z)))\n",
    "\n",
    "        # Log likelihood from random effect terms.\n",
    "        log_lik += -0.5 * tau * np.sum((mu - u) ** 2) + 0.5 * log_tau * len(u)\n",
    "\n",
    "        return log_lik\n",
    "\n",
    "    def get_log_posterior(self):\n",
    "        return np.squeeze(\n",
    "            self.get_log_lik() + \\\n",
    "            self.get_log_prior())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-696.14718055994535"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = logit_glmm.LogisticGLMM(\n",
    "    glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=vb_data['num_gh_points'])\n",
    "\n",
    "glmm_par_draw = vb.ModelParamsDict('GLMM Parameter Draw')\n",
    "glmm_par_draw.push_param(vb.ScalarParam('mu', val=0.0))\n",
    "glmm_par_draw.push_param(vb.ScalarParam('tau', val=1.0))\n",
    "glmm_par_draw.push_param(vb.VectorParam('beta', K, val=np.full(K, 0.)))\n",
    "glmm_par_draw.push_param(vb.VectorParam('u', NG))\n",
    "\n",
    "log_model = LogisticGLMMLogPosterior(glmm_par_draw, prior_par, x_mat, y_vec, y_g_vec)\n",
    "log_model.get_log_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticGLMMBootstrap(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.weights = np.full(model.x_mat.shape[0], 1.0)\n",
    "        \n",
    "    def wrap_data_log_lik_terms(self, free_par):\n",
    "        self.model.glmm_par.set_free(free_par)\n",
    "        return self.model.get_data_log_lik_terms()\n",
    "    \n",
    "glmm_bootstrap_object = LogisticGLMMBootstrap(model)\n",
    "\n",
    "get_weight_jacobian = autograd.jacobian(glmm_bootstrap_object.wrap_data_log_lik_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmm_par_free = vb_data['glmm_par_free']\n",
    "elbo_hess = vb_sparse.unpack_csr_matrix(vb_data['elbo_hess_packed'])\n",
    "\n",
    "moment_wrapper = logit_glmm.MomentWrapper(glmm_par)\n",
    "get_moment_jacobian = autograd.jacobian(moment_wrapper.get_moment_vector_from_free)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_model_weight_grad(free_par_vec, weights, num_gh_points=4):\n",
    "    model.use_weights = True\n",
    "    model.set_gh_points(num_gh_points)\n",
    "    model.weights = copy.deepcopy(weights)\n",
    "    return objective.fun_free_grad(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d73344dda913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNObs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvb_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglmm_par_free\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglmm_par_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvb_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/LogisticGLMM_lib.py\u001b[0m in \u001b[0;36mtr_optimize\u001b[0;34m(self, trust_init, num_gh_points, print_every, gtol, maxiter)\u001b[0m\n\u001b[1;32m    258\u001b[0m     def tr_optimize(self, trust_init, num_gh_points,\n\u001b[1;32m    259\u001b[0m                     print_every=5, gtol=1e-6, maxiter=500):\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_gh_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_gh_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/LogisticGLMM_lib.py\u001b[0m in \u001b[0;36mset_gh_points\u001b[0;34m(self, num_gh_points)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_gh_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gh_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gh_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_gh_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgh_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgh_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolynomial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhermite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhermgauss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_gh_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_e_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/polynomial/hermite.py\u001b[0m in \u001b[0;36mhermgauss\u001b[0;34m(deg)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \"\"\"\n\u001b[0;32m-> 1752\u001b[0;31m     \u001b[0mideg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mideg\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdeg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mideg\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"deg must be a non-negative integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "base_weights = np.full(NObs, 1.0)\n",
    "print(np.sum(base_weights))\n",
    "glmm_par_opt = tr_optimize(glmm_par_free, base_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kl_hess = objective.fun_free_hessian(glmm_par_opt)\n",
    "moment_jac = get_moment_jacobian(glmm_par_opt)\n",
    "weight_jacobian = get_weight_jacobian(glmm_par_opt)\n",
    "param_boot_mat = -1 * np.linalg.solve(elbo_hess, np.transpose(weight_jacobian))\n",
    "moment_boot_mat = np.matmul(moment_jac, param_boot_mat)\n",
    "print(moment_boot_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluated at a linear combination of the bootstrap draw and base weights.\n",
    "# Note that at the full bootstrap draw, the response is quite nonlinear.\n",
    "boot_draw = np.random.multinomial(NObs, [1. / NObs] * NObs, size=1) - 1.0\n",
    "boot_draw = 1.0 * boot_draw + base_weights\n",
    "print(np.sum(boot_draw))\n",
    "\n",
    "lr_param_diff = np.matmul(param_boot_mat, np.squeeze(boot_draw) - 1.0)\n",
    "model_weight_grad = get_model_weight_grad(glmm_par_opt + lr_param_diff, boot_draw)\n",
    "boot_newton_step = -1 * np.linalg.solve(elbo_hess, model_weight_grad)\n",
    "print(np.max(np.abs(boot_newton_step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_par_opt_boot = tr_optimize(glmm_par_opt + lr_param_diff, boot_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_vec = moment_wrapper.get_moment_vector(glmm_par_opt)\n",
    "moment_vec_boot = moment_wrapper.get_moment_vector(glmm_par_opt_boot)\n",
    "moment_vec_boot_step = moment_wrapper.get_moment_vector(\n",
    "    glmm_par_opt + lr_param_diff + boot_newton_step)\n",
    "#moment_vec_boot_step = moment_wrapper.get_moment_vector(glmm_par_opt - param_diff)\n",
    "\n",
    "true_moment_diff = moment_vec_boot - moment_vec\n",
    "boot_step_moment_diff = moment_vec_boot - moment_vec_boot_step\n",
    "lr_moment_diff = np.matmul(moment_boot_mat, np.squeeze(boot_draw) - 1.0)\n",
    "\n",
    "#plt.plot(moment_vec, moment_vec_boot, 'k.')\n",
    "plt.plot(true_moment_diff, lr_moment_diff, 'r+', markersize=20)\n",
    "plt.plot(true_moment_diff, boot_step_moment_diff, 'bx', markersize=10)\n",
    "plt.plot(true_moment_diff, true_moment_diff, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moment_indices = copy.deepcopy(moment_wrapper.moment_par)\n",
    "moment_indices.set_vector(np.arange(0, moment_indices.vector_size()))\n",
    "print(moment_indices)\n",
    "u_ind = moment_indices['e_u'].get()\n",
    "beta_ind = moment_indices['e_beta'].get()\n",
    "non_u_ind = list(set(moment_indices.get_vector()) - set(u_ind))\n",
    "print(non_u_ind)\n",
    "\n",
    "#true_moment_diff[u_ind]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(true_moment_diff[u_ind], lr_moment_diff[u_ind], 'r+', markersize=20)\n",
    "plt.plot(true_moment_diff[u_ind], true_moment_diff[u_ind], 'k.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(true_moment_diff[non_u_ind], lr_moment_diff[non_u_ind], 'r+', markersize=20)\n",
    "plt.plot(true_moment_diff[non_u_ind], true_moment_diff[non_u_ind], 'k.')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(true_moment_diff[beta_ind], lr_moment_diff[beta_ind], 'r+', markersize=20)\n",
    "plt.plot(true_moment_diff[beta_ind], true_moment_diff[beta_ind], 'k.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
