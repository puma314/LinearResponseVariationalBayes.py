{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "import VariationalBayes.SparseObjectives as obj_lib\n",
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import autograd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scikits.sparse.cholmod import cholesky\n",
    "\n",
    "\n",
    "analysis_name = 'simulated_data_small'\n",
    "#analysis_name = 'criteo_subsampled'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "pkl_file = open(pickle_output_filename, 'rb')\n",
    "vb_data = pickle.load(pkl_file)\n",
    "model = logit_glmm.load_model_from_pickle(vb_data)\n",
    "timer = vb_sparse.Timer()\n",
    "kl_hess = obj_lib.unpack_csr_matrix(vb_data['kl_hess_packed'])\n",
    "moment_jac = vb_data['moment_jac']\n",
    "moment_wrapper = logit_glmm.MomentWrapper(model.glmm_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_with_weights(\n",
    "    model, weights, init_par, preconditioner, gtol=1e-8, print_every=1, verbose=True):\n",
    "\n",
    "    model.use_weights = True\n",
    "    model.weights = copy.deepcopy(weights)\n",
    "    preconditioned_init_par = sp.sparse.linalg.spsolve(preconditioner, init_par)\n",
    "    return model.tr_optimize_cond(\n",
    "        preconditioned_init_par,\n",
    "        preconditioner=preconditioner,\n",
    "        num_gh_points=model.num_gh_points,\n",
    "        gtol=gtol,\n",
    "        print_every=print_every,\n",
    "        verbose=verbose)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-condition with the KL Hessian from the original analysis.\n",
    "preconditioner = sp.sparse.diags([1 / np.sqrt(kl_hess.diagonal())], [0])\n",
    "preconditioner = sp.sparse.csr_matrix(preconditioner)\n",
    "# cond_init = sp.sparse.linalg.spsolve(preconditioner, glmm_par_free)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n",
      "Iter  0  value:  69.4078730719\n",
      "Iter  1  value:  69.4078730719\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: 69.407873\n",
      "         Iterations: 0\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "base_weights = np.full(model.x_mat.shape[0], 1.0)\n",
    "print(np.sum(base_weights))\n",
    "base_opt = optimize_with_weights(\n",
    "    model=model,\n",
    "    preconditioner=preconditioner,\n",
    "    weights=base_weights,\n",
    "    init_par=glmm_par_free,\n",
    "    gtol=1e-8)\n",
    "base_free_par = model.objective.uncondition_x(base_opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moment_jac_time: 0.12421250343322754 seconds\n"
     ]
    }
   ],
   "source": [
    "timer.tic()\n",
    "moment_jac = moment_wrapper.get_moment_jacobian(base_free_par)\n",
    "timer.toc('moment_jac_time')\n",
    "moment_jac_sp = sp.sparse.csr_matrix(moment_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 of 99\n",
      "weight_jac_time: 1.4826602935791016 seconds\n",
      "Jacobian time:  1.4826602935791016\n"
     ]
    }
   ],
   "source": [
    "# Get a sparse Jacobian.\n",
    "timer.tic()\n",
    "weight_jacobian = model.get_sparse_weight_free_jacobian(base_free_par, print_every_n=200)\n",
    "timer.toc('weight_jac_time')\n",
    "print('Jacobian time: ', timer.time_dict['weight_jac_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 of 99.\n",
      "hess_time: 2.3268980979919434 seconds\n",
      "Hessian time:  2.3268980979919434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "# Get a sparse Hessian.\n",
    "timer.tic()\n",
    "kl_hess = model.get_sparse_free_hessian(base_free_par, print_every_n=200)\n",
    "timer.toc('hess_time')\n",
    "print('Hessian time: ', timer.time_dict['hess_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky...\n",
      "Solving...\n",
      "Done.\n",
      "inverse_time: 0.011031866073608398 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: CholmodTypeConversionWarning: converting matrix of class csr_matrix to CSC format\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Invert to get parameter sensitivity.\n",
    "timer.tic()\n",
    "print('Cholesky...')\n",
    "kl_hess_chol = cholesky(kl_hess)\n",
    "print('Solving...')\n",
    "param_boot_mat = -1 * kl_hess_chol.solve_A(weight_jacobian.T)\n",
    "print('Done.')\n",
    "timer.toc('inverse_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_and_refit(model, preconditioner, param_boot_mat, base_free_par):\n",
    "    num_obs = model.x_mat.shape[0]\n",
    "    boot_draw = np.random.multinomial(num_obs, [1. / num_obs] * num_obs, size=1)\n",
    "    boot_draw = np.asarray(np.squeeze(boot_draw))\n",
    "    lr_param_diff = param_boot_mat * (boot_draw - 1.0)\n",
    "    glmm_par_lr_boot = base_free_par + lr_param_diff\n",
    "    glmm_par_opt_boot = optimize_with_weights(\n",
    "        model=model,\n",
    "        preconditioner=preconditioner,\n",
    "        init_par=glmm_par_lr_boot,\n",
    "        weights=boot_draw,\n",
    "        gtol=1e-8,\n",
    "        verbose=False)\n",
    "    boot_free_par = model.objective.uncondition_x(glmm_par_opt_boot.x)\n",
    "    return boot_free_par, glmm_par_opt_boot, glmm_par_lr_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap 1 of 50\n"
     ]
    }
   ],
   "source": [
    "num_boot_samples = 50\n",
    "lr_boot_free_par_list = []\n",
    "boot_free_par_list = []\n",
    "timer.tic()\n",
    "for boot in range(num_boot_samples):\n",
    "    if boot % 20 == 0:\n",
    "        print('Bootstrap {} of {}'.format(boot + 1, num_boot_samples))\n",
    "    boot_free_par, glmm_par_opt_boot, glmm_par_lr_boot = \\\n",
    "        bootstrap_and_refit(model, preconditioner, param_boot_mat, base_free_par)\n",
    "    boot_free_par_list.append(boot_free_par)\n",
    "    lr_boot_free_par_list.append(glmm_par_lr_boot)\n",
    "timer.toc('bootstrap_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluated at a linear combination of the bootstrap draw and base weights.\n",
    "use_jackknife = False\n",
    "if use_jackknife:\n",
    "    boot_draw = copy.deepcopy(base_weights)\n",
    "    boot_draw[np.random.randint(NObs)] = 0.\n",
    "else:\n",
    "    boot_draw = np.random.multinomial(NObs, [1. / NObs] * NObs, size=1) - 1.0\n",
    "    boot_draw = 1.0 * boot_draw + base_weights\n",
    "\n",
    "print('Total weight (there are {} observations): {}'.format(NObs, np.sum(boot_draw)))\n",
    "lr_boot_time = time.time()\n",
    "lr_param_diff = param_boot_mat * (np.squeeze(boot_draw) - 1.0)\n",
    "lr_boot_time = time.time() - lr_boot_time\n",
    "\n",
    "print('lr_boot_time: ', lr_boot_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preconditioner = sp.sparse.diags([1 / np.sqrt(kl_hess.diagonal())], [0])\n",
    "# cond_init = sp.sparse.linalg.spsolve(preconditioner, base_free_par + lr_param_diff)\n",
    "\n",
    "timer.tic()\n",
    "glmm_par_opt_boot = optimize_with_weights(\n",
    "    model=model,\n",
    "    preconditioner=preconditioner,\n",
    "    init_par=base_free_par + lr_param_diff,\n",
    "    weights=boot_draw, gtol=1e-8)\n",
    "boot_free_par = model.objective.uncondition_x(glmm_par_opt_boot.x)\n",
    "timer.toc('re_optimization_time')\n",
    "\n",
    "print('Re-optimization time: ', timer.time_dict['re_optimization_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual change in the moment vectors.\n",
    "moment_vec = moment_wrapper.get_moment_vector_from_free(base_free_par)\n",
    "moment_vec_boot = moment_wrapper.get_moment_vector_from_free(boot_free_par)\n",
    "true_moment_diff = moment_vec_boot - moment_vec\n",
    "print('True param difference: {}'.format(np.linalg.norm(base_free_par - boot_free_par)))\n",
    "print('True moment norm difference: {}'.format(np.linalg.norm(true_moment_diff)))\n",
    "\n",
    "# Use the linear approximation for the parameters, not the moments.\n",
    "moment_pred_from_params = \\\n",
    "    moment_wrapper.get_moment_vector_from_free(base_free_par + lr_param_diff)\n",
    "moment_pred_from_params_diff = moment_pred_from_params - moment_vec\n",
    "\n",
    "# The difference based on a linear approximation to the moments.\n",
    "# lr_moment_diff = \\\n",
    "#     moment_jac_sp * (param_boot_mat * (np.squeeze(boot_draw) - 1.0))\n",
    "moment_pred_from_moments_diff = moment_jac_sp * lr_param_diff\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linearizing the moments')\n",
    "plt.plot(true_moment_diff, moment_pred_from_moments_diff, 'r+', markersize=10)\n",
    "plt.plot(true_moment_diff, true_moment_diff, 'k.')\n",
    "#plt.axis([-10, 10, -10, 10])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linearizing the parameters')\n",
    "plt.plot(true_moment_diff, moment_pred_from_params_diff, 'bx', markersize=10)\n",
    "plt.plot(true_moment_diff, true_moment_diff, 'k.')\n",
    "#plt.axis([-10, 10, -10, 10])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Moments vs parameters')\n",
    "plt.plot(moment_pred_from_params_diff, moment_pred_from_moments_diff, 'r+', markersize=10)\n",
    "plt.plot(moment_pred_from_params_diff, moment_pred_from_params_diff, 'k.')\n",
    "#plt.axis([-10, 10, -10, 10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result to a pickle file for use in R.\n",
    "\n",
    "run_name = 'jackknife'\n",
    "\n",
    "pickle_result_filename = os.path.join(data_dir, '%s_python_vb_jackknife_results.pkl' % analysis_name)\n",
    "pickle_output = open(pickle_result_filename, 'wb')\n",
    "\n",
    "# Unlike with JSON, numpy arrays can be pickled.\n",
    "pickle_result_dict = {  'boot_free_par_list': boot_free_par_list,\n",
    "                        'lr_boot_free_par_list': lr_boot_free_par_list,\n",
    "                        'run_name': run_name,\n",
    "                        'beta_dim': K,\n",
    "                        'num_groups': NG,\n",
    "                        'num_gh_points': model.num_gh_points,\n",
    "                        'timer': timer,\n",
    "                        'base_free_par': base_free_par,\n",
    "                        'boot_free_par': boot_free_par,\n",
    "                        'boot_draw': boot_draw,\n",
    "                        'kl_hess': vb_sparse.pack_csr_matrix(kl_hess),\n",
    "                        'weight_jacobian': vb_sparse.pack_csr_matrix(sp.sparse.csr_matrix(weight_jacobian)),\n",
    "                        'param_boot_mat': vb_sparse.pack_csr_matrix(sp.sparse.csr_matrix(param_boot_mat)),\n",
    "                        'moment_jac': moment_jac }\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(pickle_result_dict, pickle_output)\n",
    "pickle_output.close()\n",
    "\n",
    "print(pickle_result_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
