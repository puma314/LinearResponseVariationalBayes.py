{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "import VariationalBayes.SparseObjectives as vb_sparse\n",
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "analysis_name = 'simulated_data_for_refit'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "class TrueParameters(object):\n",
    "    def __init__(self, num_obs_per_group, num_groups, true_beta, true_mu, true_tau):\n",
    "        self.num_obs_per_group = num_obs_per_group\n",
    "        self.num_groups = num_groups\n",
    "        self.true_beta = true_beta\n",
    "        self.true_mu = true_mu\n",
    "        self.true_tau = true_tau\n",
    "        self.beta_dim = len(self.true_beta)\n",
    "        \n",
    "    def generate_data(self):\n",
    "        x_mat, y_g_vec, y_vec, self.true_rho, self.true_u = \\\n",
    "            logit_glmm.simulate_data(\n",
    "                self.num_obs_per_group, self.num_groups,\n",
    "                self.true_beta, self.true_mu, self.true_tau)\n",
    "        return x_mat, y_g_vec, y_vec\n",
    "\n",
    "        \n",
    "true_beta = np.array(range(5))\n",
    "true_beta = true_beta - np.mean(true_beta)\n",
    "true_mu = 0.\n",
    "true_tau = 40.0\n",
    "\n",
    "true_params = TrueParameters(\n",
    "    num_obs_per_group = 10,\n",
    "    num_groups = 200,\n",
    "    true_beta = true_beta,\n",
    "    true_mu = 0.,\n",
    "    true_tau = 40.0)\n",
    "\n",
    "x_mat, y_g_vec, y_vec  = true_params.generate_data()\n",
    "prior_par = logit_glmm.get_default_prior_params(true_params.beta_dim)\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=true_params.beta_dim, NG=true_params.num_groups)\n",
    "logit_glmm.initialize_glmm_pars(glmm_par)\n",
    "init_par_vec = glmm_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  1640.67787586\n",
      "Iter  5  value:  1109.81769121\n",
      "Iter  10  value:  1077.39970041\n",
      "Iter  15  value:  1077.29938029\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1077.299380\n",
      "         Iterations: 16\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "# Get an initial fit and preconditioner.\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(\n",
    "    glmm_par=glmm_par, prior_par=prior_par, x_mat=x_mat,\n",
    "    y_vec=y_vec, y_g_vec=y_g_vec, num_gh_points=5)\n",
    "\n",
    "vb_time = time.time()\n",
    "vb_opt = model.tr_optimize(init_par_vec, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ind 0 of 413\n",
      "Ind 100 of 413\n",
      "Ind 200 of 413\n",
      "Ind 300 of 413\n",
      "Ind 400 of 413\n"
     ]
    }
   ],
   "source": [
    "class DiagonalModel(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.glmm_par = model.glmm_par\n",
    "        self.free_par = model.glmm_par.get_free()\n",
    "        self.get_single_par_hessian = autograd.hessian(self.get_single_par_kl)\n",
    "\n",
    "    def get_single_par_kl(self, single_free_par, ind):\n",
    "        free_par = np.concatenate(\n",
    "            [ self.free_par[:ind],\n",
    "              np.atleast_1d(single_free_par),\n",
    "              self.free_par[(ind + 1):]])\n",
    "        self.glmm_par.set_free(free_par)\n",
    "        return model.get_kl()\n",
    "    \n",
    "    def get_hessian_diag(self, free_par, print_every=100):\n",
    "        self.glmm_par.set_free(free_par)\n",
    "        self.free_par = model.glmm_par.get_free()\n",
    "        hess_diag = []\n",
    "        free_size = self.glmm_par.free_size()\n",
    "        for ind in range(free_size):\n",
    "            if ind % print_every == 0:\n",
    "                print('Ind {} of {}'.format(ind, free_size - 1))\n",
    "            hess_diag.append(self.get_single_par_hessian(self.free_par[ind], ind))\n",
    "        return hess_diag\n",
    "    \n",
    "diagonal_model = DiagonalModel(model)\n",
    "diagonal_model.get_single_par_kl(7.0, 3)\n",
    "diagonal_model.get_single_par_hessian(5.0, 1)\n",
    "hess_diag = diagonal_model.get_hessian_diag(init_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32587081167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:102: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "print(np.min(hess_diag))\n",
    "preconditioner = sp.sparse.diags([1 / np.sqrt(hess_diag)], [0])\n",
    "model.objective.preconditioner = preconditioner\n",
    "cond_init = sp.sparse.linalg.spsolve(preconditioner, opt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "refit_model = copy.deepcopy(model)\n",
    "def simulate_and_fit(model, cond_init, true_params):\n",
    "    model.x_mat, model.y_g_vec, model.y_vec = true_params.generate_data()\n",
    "\n",
    "    vb_time = time.time()\n",
    "    vb_opt = model.tr_optimize_cond(\n",
    "        cond_init,\n",
    "        preconditioner=preconditioner,\n",
    "        gtol=1e-6, maxiter=500, verbose=False)\n",
    "    return model.objective.uncondition_x(vb_opt.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simg 0 of 99\n",
      "Simg 10 of 99\n",
      "Simg 20 of 99\n",
      "Simg 30 of 99\n",
      "Simg 40 of 99\n",
      "Simg 50 of 99\n",
      "Simg 60 of 99\n",
      "Simg 70 of 99\n",
      "Simg 80 of 99\n",
      "Simg 90 of 99\n"
     ]
    }
   ],
   "source": [
    "opt_x_sims = []\n",
    "num_sims = 100\n",
    "for sim in range(num_sims):\n",
    "    if sim % 10 == 0:\n",
    "        print('Sim {} of {}'.format(sim, num_sims - 1))\n",
    "    opt_x_sims.append(simulate_and_fit(refit_model, cond_init, true_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/simulated_data_small_python_vb_results.pkl\n",
      "\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write the result to a JSON file for use in R.\n",
    "\n",
    "run_name = 'simulation'\n",
    "\n",
    "pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "# Unlike with JSON, numpy arrays can be pickled.\n",
    "# Note that it does not seem that you can pickle a sparse Cholesky decomposition.\n",
    "pickle_result_dict = {  'num_gh_points': model.num_gh_points,\n",
    "                        'true_params': true_params,\n",
    "                        'glmm_par_sims': opt_x_sims,\n",
    "                        'glmm_par_free': opt_x,\n",
    "                        'hess_diag': hess_diag,\n",
    "                        'x_mat': x_mat,\n",
    "                        'y_g_vec': y_g_vec,\n",
    "                        'y_vec': y_vec\n",
    "                     }\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(pickle_result_dict, pickle_output)\n",
    "pickle_output.close()\n",
    "\n",
    "print(pickle_output_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
