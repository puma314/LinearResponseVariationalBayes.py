{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "from VariationalBayes.NormalParams import MVNParam, UVNParam, UVNParamVector\n",
    "from VariationalBayes.GammaParams import GammaParam\n",
    "from VariationalBayes.ExponentialFamilies import \\\n",
    "    UnivariateNormalEntropy, MultivariateNormalEntropy, GammaEntropy, \\\n",
    "    MVNPrior, UVNPrior, GammaPrior\n",
    "\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as asp\n",
    "import scipy as sp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named trlib",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1a0d3eb38cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtrlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#import numpy as np\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named trlib"
     ]
    }
   ],
   "source": [
    "import trlib\n",
    "import scipy.sparse\n",
    "#import numpy as np\n",
    "H = scipy.sparse.diags(np.linspace(-1.0, 100.0, 1000),0)\n",
    "g = np.ones(1000)\n",
    "x, TR = trlib.trlib_solve(H, g, 1.0)\n",
    "np.linalg.norm(x)\n",
    "x, TR = trlib.trlib_solve(H, g, .5, reentry=True, TR=TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "prior_par = ModelParamsDict('Prior Parameters')\n",
    "\n",
    "#analysis_name = 'simulated_data_small'\n",
    "analysis_name = 'simulated_data_large'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "json_file = open(json_filename, 'r')\n",
    "json_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "stan_dat = json_dat['stan_dat']\n",
    "vp_base = json_dat['vp_base']\n",
    "\n",
    "print stan_dat.keys()\n",
    "K = stan_dat['K'][0]\n",
    "NObs = stan_dat['N'][0]\n",
    "NG = stan_dat['NG'][0]\n",
    "N = NObs / NG\n",
    "y_g_vec = np.array(stan_dat['y_group'])\n",
    "y_vec = np.array(stan_dat['y'])\n",
    "x_mat = np.array(stan_dat['x'])\n",
    "\n",
    "# Define a class to contain prior parameters.\n",
    "prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "beta_prior_info = np.linalg.inv(np.array(stan_dat['beta_prior_var']))\n",
    "prior_par.push_param(PosDefMatrixParam('beta_prior_info', K, val=beta_prior_info))\n",
    "\n",
    "prior_par.push_param(ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "prior_par.push_param(ScalarParam('mu_prior_info', val=1 / stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "prior_par.push_param(ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "prior_par.push_param(ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "# An index set to make sure jacobians match the order expected by R.\n",
    "prior_par_indices = copy.deepcopy(prior_par)\n",
    "prior_par_indices.set_name('Prior Indices')\n",
    "prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "glmm_par.push_param(ScalarParam('mu'))\n",
    "glmm_par.push_param(ScalarParam('tau', lb=1e-6))\n",
    "glmm_par.push_param(VectorParam('beta', K))\n",
    "glmm_par.push_param(UVNParamVector('u', NG, min_info=vp_base['u_info_min'][0]))\n",
    "\n",
    "# Initialize with ADVI.  Don't forget to add the ADVI computation time to your final VB time!\n",
    "advi_fit = json_dat['advi_results']\n",
    "glmm_par['mu'].set(advi_fit['mu_mean'][0])\n",
    "\n",
    "tau_mean = advi_fit['tau_mean'][0]\n",
    "glmm_par['tau'].set(tau_mean)\n",
    "\n",
    "glmm_par['beta'].set(np.array(advi_fit['beta_mean']))\n",
    "\n",
    "glmm_par['u'].mean.set(np.array(advi_fit['u_mean']))\n",
    "glmm_par['u'].info.set(1 / np.array(advi_fit['u_var']))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "\n",
    "moment_par = ModelParamsDict('Moment Parameters')\n",
    "moment_par.push_param(VectorParam('e_beta', K))\n",
    "moment_par.push_param(PosDefMatrixParam('e_beta_outer', K))\n",
    "moment_par.push_param(ScalarParam('e_mu'))\n",
    "moment_par.push_param(ScalarParam('e_mu2'))\n",
    "moment_par.push_param(ScalarParam('e_tau'))\n",
    "moment_par.push_param(ScalarParam('e_log_tau'))\n",
    "moment_par.push_param(VectorParam('e_u', NG))\n",
    "moment_par.push_param(VectorParam('e_u2', NG))\n",
    "\n",
    "def set_moments(glmm_par, moment_par):\n",
    "    e_beta = glmm_par['beta'].get()\n",
    "    moment_par['e_beta'].set(e_beta)\n",
    "    moment_par['e_beta_outer'].set(np.outer(e_beta, e_beta))\n",
    "    moment_par['e_mu'].set(glmm_par['mu'].get())\n",
    "    moment_par['e_mu2'].set(glmm_par['mu'].get() ** 2)\n",
    "    moment_par['e_tau'].set(glmm_par['tau'].get())\n",
    "    moment_par['e_log_tau'].set(np.log(glmm_par['tau'].get()))\n",
    "    moment_par['e_u'].set(glmm_par['u'].e())\n",
    "    moment_par['e_u2'].set((glmm_par['u'].e_outer()))\n",
    "    \n",
    "set_moments(glmm_par, moment_par)\n",
    "\n",
    "# Moment indices.\n",
    "moment_indices = copy.deepcopy(moment_par)\n",
    "moment_indices.set_vector(1 + np.array(range(moment_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_combined_parameters(combined_free_par_vec, glmm_par, prior_par):\n",
    "    assert glmm_par.free_size() + prior_par.vector_size() == len(combined_free_par_vec) \n",
    "    glmm_par.set_free(combined_free_par_vec[0:glmm_par.free_size()])\n",
    "    prior_par.set_vector(combined_free_par_vec[glmm_par.free_size():])\n",
    "\n",
    "    \n",
    "def encode_combined_parameters(glmm_par, prior_par):\n",
    "    combined_free_par_vec = np.full(glmm_par.free_size() + prior_par.vector_size(), float('nan'))\n",
    "    combined_free_par_vec[0:glmm_par.free_size()] = glmm_par.get_free()\n",
    "    combined_free_par_vec[glmm_par.free_size():] = prior_par.get_vector()\n",
    "    return combined_free_par_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ELogPrior(prior_par, glmm_par_elbo):\n",
    "    e_beta = glmm_par_elbo['beta'].get()\n",
    "    cov_beta = np.zeros((len(e_beta), len(e_beta)))\n",
    "    beta_prior_info = prior_par['beta_prior_info'].get()\n",
    "    beta_prior_mean = prior_par['beta_prior_mean'].get()\n",
    "    e_log_p_beta = MVNPrior(beta_prior_mean, beta_prior_info, e_beta, cov_beta)\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].get()\n",
    "    mu_prior_mean = prior_par['mu_prior_mean'].get()\n",
    "    mu_prior_info = prior_par['mu_prior_info'].get()\n",
    "    e_log_p_mu = UVNPrior(mu_prior_mean, mu_prior_info, e_mu, 0.)\n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].get()\n",
    "    e_log_tau = np.log(e_tau)\n",
    "    tau_prior_shape = prior_par['tau_prior_alpha'].get()\n",
    "    tau_prior_rate = prior_par['tau_prior_beta'].get()\n",
    "    e_log_p_tau = GammaPrior(tau_prior_shape, tau_prior_rate, e_tau, e_log_tau)\n",
    "    \n",
    "    return  e_log_p_beta + e_log_p_mu + e_log_p_tau\n",
    "           \n",
    "\n",
    "def DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta, e_mu, var_mu, e_u, var_u, std_draws):\n",
    "    z_mean = e_u + e_mu + np.matmul(x_mat, e_beta)\n",
    "    z_sd = np.sqrt(var_u + var_mu + np.einsum('nk,kj,nj->n', x_mat, cov_beta, x_mat))\n",
    "    z = np.einsum('i,j->ij', z_sd, std_draws) + np.expand_dims(z_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # p = exp(z) / (1 + exp(z))\n",
    "    # log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "    logit_term = -np.sum(np.log1p(np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * z_mean)\n",
    "    return y_term + logit_term\n",
    "\n",
    "\n",
    "def RandomEffectLogLikelihood(e_u, var_u, e_tau, e_log_tau):\n",
    "    return -0.5 * e_tau * np.sum((e_u ** 2) + var_u) + 0.5 * e_log_tau * len(e_u)\n",
    "\n",
    "    \n",
    "def Elbo(y_vec, x_mat, y_g_vec, glmm_par_elbo, std_draws, prior_par):\n",
    "    e_beta = glmm_par_elbo['beta'].get()\n",
    "    cov_beta = np.zeros((len(e_beta), len(e_beta)))\n",
    "    \n",
    "    e_u = glmm_par_elbo['u'].mean.get()\n",
    "    info_u = glmm_par_elbo['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].get()\n",
    "    var_mu = 0.\n",
    "    \n",
    "    e_tau = glmm_par_elbo['tau'].get()\n",
    "    e_log_tau = np.log(e_tau)\n",
    "        \n",
    "    ll = \\\n",
    "        DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta, e_mu, var_mu,\n",
    "                          e_u[y_g_vec], var_u[y_g_vec], std_draws) + \\\n",
    "        RandomEffectLogLikelihood(e_u, var_u, e_tau, e_log_tau)\n",
    "    if np.isnan(ll):\n",
    "        return -np.inf\n",
    "\n",
    "    e_log_prior = ELogPrior(prior_par, glmm_par_elbo)\n",
    "    if np.isnan(e_log_prior):\n",
    "        return -np.inf\n",
    "    \n",
    "    entropy = UnivariateNormalEntropy(info_u)\n",
    "\n",
    "    return ll[0] + e_log_prior[0] + entropy\n",
    "\n",
    "\n",
    "class KLWrapper(object):\n",
    "    def __init__(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = sp.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.y_g_vec,\n",
    "                   self.__glmm_par_ad, self.std_draws, self.__prior_par_ad)\n",
    "        if verbose: print kl\n",
    "            \n",
    "        # TODO: this is returning an array when it should be a scalar.\n",
    "        return kl\n",
    "    \n",
    "    def ExpectedLogPrior(self, combined_free_par_vec):\n",
    "        # Encode the glmm parameters first and the prior second.\n",
    "        decode_combined_parameters(combined_free_par_vec, self.__glmm_par_ad, self.__prior_par_ad)\n",
    "        e_log_prior = ELogPrior(self.__prior_par_ad, self.__glmm_par_ad)\n",
    "        return e_log_prior[0]\n",
    "        \n",
    "\n",
    "class MomentWrapper(object):\n",
    "    def __init__(self, glmm_par, moment_par):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__moment_par = copy.deepcopy(moment_par)\n",
    "\n",
    "    # Return a posterior moment of interest as a function of unconstrained parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par.get_vector()\n",
    "    \n",
    "    def GetMomentParameters(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par\n",
    "\n",
    "\n",
    "kl_wrapper = KLWrapper(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "\n",
    "moment_wrapper = MomentWrapper(glmm_par, moment_par)\n",
    "MomentJacobian = jacobian(moment_wrapper.GetMoments)\n",
    "\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par, prior_par)\n",
    "PriorHess = hessian(kl_wrapper.ExpectedLogPrior)\n",
    "kl_wrapper.ExpectedLogPrior(combined_free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "# print 'Moment jacobian time:'\n",
    "# print timeit.timeit(lambda: MomentJacobian(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# time_num = 1\n",
    "# print 'Prior Hessian time:'\n",
    "# print timeit.timeit(lambda: PriorHess(combined_free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# # so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class OptimizationPath(object):\n",
    "    def __init__(self):\n",
    "        self.x_history = []\n",
    "        pass\n",
    "    \n",
    "    def save(self, x):\n",
    "        self.x_history.append(x)\n",
    "\n",
    "bfgs_path = OptimizationPath()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "\n",
    "# Optimize.\n",
    "vb_time = time.time()\n",
    "# print 'Running BFGS'\n",
    "# vb_opt_bfgs = optimize.minimize(\n",
    "#     lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "#     method='bfgs', jac=KLGrad, tol=1e-2, callback=bfgs_path.save,\n",
    "#     options={'maxiter': 100, 'gtol': 1e-2, 'disp': True})\n",
    "\n",
    "trust_path = OptimizationPath()\n",
    "print 'Running Newton Trust Region'\n",
    "# trust_init = copy.deepcopy(vb_opt_bfgs.x)\n",
    "trust_init = copy.deepcopy(init_par_vec)\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    trust_init, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd,\n",
    "    tol=1e-6, callback=trust_path.save,\n",
    "    options={'maxiter': 100, 'disp': True, 'gtol': 1e-6, 'eta': 0.15 })\n",
    "\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(vb_opt.x)\n",
    "\n",
    "print 'Done.'\n",
    "\n",
    "print vb_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(trust_path.x_history)\n",
    "\n",
    "# for i in range(len(path.x_history) - 1):\n",
    "#     print np.sum(path.x_history[i + 1] - path.x_history[i])\n",
    "    \n",
    "# for i in range(len(trust_path.x_history)):\n",
    "#     glmm_par.set_free(trust_path.x_history[i])\n",
    "#     #print 'Iteration ' + str(i) + '\\n'\n",
    "#     #print str(np.diag(glmm_par['beta'].info.get())) + '\\n'\n",
    "#     #print str(np.diag(glmm_par['mu'].get())) + '\\n'\n",
    "#     #print str(glmm_par['beta'].get()[2]) + '\\n'\n",
    "\n",
    "vals = [ kl_wrapper.Eval(x) for x in trust_path.x_history ]\n",
    "\n",
    "# for i in range(len(trust_path.x_history)):\n",
    "    #grad = KLGrad(trust_path.x_history[i])\n",
    "    #print np.max(np.abs(grad))\n",
    "\n",
    "# print vals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hess = KLHess(vb_opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eig(hess)\n",
    "grad = KLGrad(vb_opt.x)\n",
    "step_direction = -np.linalg.solve(hess, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the conjugate gradient step direction\n",
    "\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "ObjHessVecProdLO = LinearOperator((vb_opt.x.size, vb_opt.x.size), lambda par: KLHessVecProd(vb_opt.x, par))\n",
    "cg_step_direction, info = sp.sparse.linalg.cg(ObjHessVecProdLO, -grad)\n",
    "assert info == 0\n",
    "print np.max(np.abs(cg_step_direction - step_direction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the random effect estimates.  This requires simulated data.\n",
    "from ggplot import *\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# plot_df = pd.DataFrame({ 'iter': np.arange(len(vals)), 'val': np.log10(np.abs(vals)) })\n",
    "# print ggplot(plot_df[30:], aes(x='iter', y='val')) + geom_point()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_eps = 2.\n",
    "eps_vals = np.arange(0., max_eps, max_eps / 10)\n",
    "kl_steps = [ kl_wrapper.Eval(vb_opt.x + eps * cg_step_direction) for eps in eps_vals ]\n",
    "plot_df = pd.DataFrame({ 'eps': eps_vals, 'val': kl_steps })\n",
    "print ggplot(plot_df, aes(x='eps', y='val')) + geom_point()\n",
    "\n",
    "print (kl_steps[0] - np.min(kl_steps)) / kl_steps[0]\n",
    "print kl_steps[0] - np.min(kl_steps)\n",
    "\n",
    "# glmm_par.set_free(step_direction / np.linalg.norm(step_direction))\n",
    "# min_vec = vecs[:, vals.argmin()]\n",
    "# glmm_par.set_free(min_vec)\n",
    "# print glmm_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_step = trust_path.x_history[len(trust_path.x_history) - 1] - trust_path.x_history[len(trust_path.x_history) - 2]\n",
    "\n",
    "print np.linalg.norm(cg_step_direction)\n",
    "print np.linalg.norm(step_direction)\n",
    "print np.linalg.norm(grad)\n",
    "print np.linalg.norm(last_step)\n",
    "\n",
    "plot_df = pd.DataFrame({ 'last_step': last_step, 'step_direction': step_direction })\n",
    "print ggplot(plot_df, aes(x='step_direction', y='last_step')) + geom_point()\n",
    "\n",
    "plot_df = pd.DataFrame({ 'cg_step_direction': cg_step_direction, 'step_direction': step_direction })\n",
    "print ggplot(plot_df, aes(x='step_direction', y='cg_step_direction')) + geom_point()\n",
    "\n",
    "print np.sum(np.abs(last_step) < 1e-6) / float(len(last_step))\n",
    "print np.sum(np.abs(step_direction) < 1e-6) / float(len(step_direction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Slow, but probably faster than using CG.\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par_opt, prior_par)\n",
    "\n",
    "hess_time = time.time()\n",
    "print 'KL Hessian.\\n'\n",
    "kl_hess = KLHess(vb_opt.x)\n",
    "print 'Log prior Hessian.\\n'\n",
    "log_prior_hess_full = PriorHess(combined_free_par_vec)\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print 'hess_time: %f' % hess_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glmm_inds = range(glmm_par_opt.free_size())\n",
    "prior_inds = range(glmm_par_opt.free_size(), len(combined_free_par_vec))\n",
    "log_prior_hess = log_prior_hess_full[np.ix_(prior_inds, glmm_inds)]\n",
    "\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_name = 'debug'\n",
    "result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'run_name': run_name,\n",
    "                'vb_time': vb_time,'hess_time': hess_time, \n",
    "                'moment_indices': moment_indices.dictval(),\n",
    "                'prior_indices': prior_indices.dictval(),\n",
    "                'vp_indices': vp_indices.dictval(),\n",
    "                'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "result_json = json.dumps(result_dict)\n",
    "json_file = open(json_output_filename, 'w')\n",
    "json_file.write(result_json)\n",
    "json_file.close()\n",
    "\n",
    "print(json_output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
