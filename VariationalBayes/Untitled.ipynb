{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import copy\n",
    "from itertools import product\n",
    "import numpy.testing as np_test\n",
    "import Parameters\n",
    "from Parameters import \\\n",
    "    VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "import unittest\n",
    "\n",
    "from autograd.util import quick_grad_check\n",
    "from autograd import grad, jacobian, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient of <function ScalarFun at 0x7f933682ef50> at 0.0\n",
      "Gradient projection OK (numeric grad: -1.37499999972, analytic grad: -1.375)\n",
      "Checking gradient of <function VecFun at 0x7f933682ed70> at [-3.98898405  3.98898405]\n",
      "Gradient projection OK (numeric grad: 0.056986754462, analytic grad: 0.0569867544487)\n",
      "Checking gradient of <function MatFun at 0x7f933682e5f0> at [ 1.09544512  0.18257419  1.08012345]\n",
      "Gradient projection OK (numeric grad: -0.0127102872982, analytic grad: -0.0127102877958)\n",
      "Checking gradient of <function ParamsFun at 0x7f933682e8c0> at [ 0.         -3.98898405  3.98898405  1.09544512  0.18257419  1.08012345]\n",
      "Gradient projection OK (numeric grad: 0.219365717591, analytic grad: 0.219365717742)\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "mat = np.full(k ** 2, 0.2).reshape(k, k) + np.eye(k)\n",
    "\n",
    "lb = -0.1\n",
    "ub = 5.2\n",
    "val = 0.5 * (ub - lb) + lb\n",
    "vec = np.linspace(lb, ub, k)\n",
    "\n",
    "vp_scalar = ScalarParam('scalar', lb=lb - 0.1, ub=ub + 0.1)\n",
    "vp_mat = PosDefMatrixParam('matrix', k)\n",
    "vp_vec = VectorParam('vector', k, lb=lb - 0.1, ub=ub + 0.1)\n",
    "\n",
    "vp_scalar.set(val)\n",
    "vp_vec.set(vec)\n",
    "vp_mat.set(mat)\n",
    "\n",
    "mp = ModelParamsDict()\n",
    "mp.push_param(vp_scalar)\n",
    "mp.push_param(vp_vec)\n",
    "mp.push_param(vp_mat)\n",
    "\n",
    "# To take advantage of quick_grad_check(), define scalar functions of\n",
    "# each parameter.\n",
    "def ScalarFun(val_free):\n",
    "    vp_scalar_ad = copy.deepcopy(vp_scalar)\n",
    "    vp_scalar_ad.set_free(val_free)\n",
    "    return vp_scalar_ad.get()\n",
    "\n",
    "def VecFun(val_free):\n",
    "    vp_vec_ad = copy.deepcopy(vp_vec)\n",
    "    vp_vec_ad.set_free(val_free)\n",
    "    return np.linalg.norm(vp_vec_ad.get())\n",
    "\n",
    "def MatFun(val_free):\n",
    "    vp_mat_ad = copy.deepcopy(vp_mat)\n",
    "    vp_mat_ad.set_free(val_free)\n",
    "    return np.linalg.norm(vp_mat_ad.get())\n",
    "\n",
    "def ParamsFun(val_free):\n",
    "    mp_ad = copy.deepcopy(mp)\n",
    "    mp_ad.set_free(val_free)\n",
    "    return mp_ad['scalar'].get() + \\\n",
    "           np.linalg.norm(mp_ad['vector'].get()) + \\\n",
    "           np.linalg.norm(mp_ad['matrix'].get())\n",
    "\n",
    "\n",
    "quick_grad_check(ScalarFun, vp_scalar.get_free())\n",
    "quick_grad_check(VecFun, vp_vec.get_free())\n",
    "quick_grad_check(MatFun, vp_mat.get_free())\n",
    "quick_grad_check(ParamsFun, mp.get_free())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
