{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "from autograd import grad, hessian, jacobian\n",
    "import math\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "from autograd.core import primitive\n",
    "from autograd.numpy.numpy_grads import unbroadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sets the param using the slice in free_vec starting at offset.\n",
    "# Returns the next offset.\n",
    "def set_free_offset(param, free_vec, offset):\n",
    "    param.set_free(free_vec[offset:(offset + param.free_size())])\n",
    "    return offset + param.free_size()\n",
    "\n",
    "# Sets the value of vec starting at offset with the param's free value.\n",
    "# Returns the next offset.\n",
    "def get_free_offset(param, vec, offset):\n",
    "    vec[offset:(offset + param.free_size())] = param.get_free()\n",
    "    return offset + param.free_size()\n",
    "\n",
    "class MVNParam(object):\n",
    "    def __init__(self, name, dim):\n",
    "        self.name = name\n",
    "        self.__dim = dim\n",
    "        self.mean = VectorParam(name + '_mean', dim)\n",
    "        self.cov = PosDefMatrixParam(name + '_cov', dim)\n",
    "        self.__free_size = self.mean.free_size() + self.cov.free_size()\n",
    "    def __str__(self):\n",
    "        return self.name + ':\\n' + str(self.mean) + '\\n' + str(self.cov)\n",
    "    def names(self):\n",
    "        return self.mean.names() + self.cov.names()\n",
    "    def e(self):\n",
    "        return self.mean.get()\n",
    "    def e_outer(self):\n",
    "        mean = self.mean.get()\n",
    "        return np.outer(mean, mean) + self.cov.get()\n",
    "    def set_free(self, free_val):\n",
    "        if free_val.size != self.__free_size: raise ValueError('Wrong size for MVNParam ' + self.name)\n",
    "        offset = 0\n",
    "        offset = set_free_offset(self.mean, free_val, offset)\n",
    "        offset = set_free_offset(self.cov, free_val, offset)\n",
    "    def get_free(self):\n",
    "        vec = np.empty(self.__free_size)\n",
    "        offset = 0\n",
    "        offset = get_free_offset(self.mean, vec, offset)\n",
    "        offset = get_free_offset(self.cov, vec, offset)\n",
    "        return vec\n",
    "    def free_size(self):\n",
    "        return self.__free_size\n",
    "    def dim(self):\n",
    "        return self.__dim\n",
    "    \n",
    "    \n",
    "class MVNParamVector(object):\n",
    "    def __init__(self, name, dim, length):\n",
    "        self.name = name\n",
    "        self.__dim = dim\n",
    "        self.mvn_params = [ MVNParam(name + str(g), dim) for g in range(length) ]\n",
    "        self.__free_size = np.sum([ par.free_size() for par in self.mvn_params ])\n",
    "    def __str__(self):\n",
    "        return '\\n'.join([ str(par) for par in self.mvn_params ])\n",
    "    def __len__(self):\n",
    "        return len(self.mvn_params)\n",
    "    def names(self):\n",
    "        return '\\n'.join([ names(par) for par in self.mvn_params ])\n",
    "    def set_free(self, free_val):\n",
    "        if free_val.size != self.__free_size: raise ValueError('Wrong size for MVNParamVector ' + self.name)\n",
    "        offset = 0\n",
    "        for par in self.mvn_params:\n",
    "            offset = set_free_offset(par, free_val, offset)\n",
    "    def get_free(self):\n",
    "        vec = np.empty(self.__free_size)\n",
    "        offset = 0\n",
    "        for par in self.mvn_params:\n",
    "            offset = get_free_offset(par, vec, offset)\n",
    "        return vec\n",
    "    def free_size(self):\n",
    "        return self.__free_size\n",
    "    def dim(self):\n",
    "        return self.__dim\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic check\n",
    "\n",
    "if False:\n",
    "    K = 3\n",
    "    mu = MVNParam('mu', K)\n",
    "    mu.mean.set(np.random.rand(K))\n",
    "    x_cov = np.full([K, K], 0.9)\n",
    "    for k in range(K):\n",
    "        x_cov[k, k] = 1\n",
    "    mu.cov.set(x_cov)\n",
    "    print mu.e()\n",
    "    print mu.e_outer()\n",
    "    print mu.cov.get()\n",
    "    par_free = mu.get_free()\n",
    "    print par_free\n",
    "\n",
    "    mu.mean.set(np.array([1., 3., 4.]))\n",
    "    print mu\n",
    "    mu.set_free(par_free)\n",
    "    print mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if False:\n",
    "    K = 3\n",
    "    x_cov = np.full([K, K], 0.9)\n",
    "    for k in range(K):\n",
    "        x_cov[k, k] = 1\n",
    "    G = 5\n",
    "    mu_g = MVNParamVector('mu_g', K, G)\n",
    "    for par in mu_g.mvn_params:\n",
    "        par.mean.set(np.random.rand(par.dim()))\n",
    "        par.cov.set(x_cov)\n",
    "\n",
    "    print len(mu_g)\n",
    "\n",
    "    print mu_g\n",
    "    par_free = mu_g.get_free()\n",
    "    for par in mu_g.mvn_params:\n",
    "        par.mean.set(np.random.rand(par.dim()))\n",
    "        par.cov.set(x_cov)\n",
    "    print mu_g\n",
    "    mu_g.set_free(par_free)\n",
    "    print mu_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "\n",
    "K = 3\n",
    "G = 10\n",
    "mvn_par = ModelParamsDict()\n",
    "\n",
    "mvn_par.push_param(MVNParam('mu', K))\n",
    "mvn_par.push_param(MVNParamVector('mu_g', K, G))\n",
    "\n",
    "mvn_par['mu'].mean.set(np.full(K, 0.1))\n",
    "mvn_par['mu'].cov.set(np.eye(K))\n",
    "\n",
    "for mu_g_par in mvn_par['mu_g'].mvn_params:\n",
    "    mu_g_par.mean.set(np.full(K, 0.5))\n",
    "    mu_g_par.cov.set(0.2 * np.eye(K))\n",
    "\n",
    "# print mvn_par\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 5000\n",
    "true_mu = np.random.rand(K).T\n",
    "true_mu_g = []\n",
    "x_cov = np.full([K, K], 0.9)\n",
    "for k in range(K):\n",
    "    x_cov[k, k] = 1\n",
    "\n",
    "x_draws = np.array([]).reshape(0, K)\n",
    "true_mu_g = []\n",
    "g_mat = []\n",
    "for g in range(G):\n",
    "    this_mu_g = np.random.rand(K)\n",
    "    true_mu_g.append(this_mu_g)\n",
    "    x_draws = np.append(x_draws, np.random.multivariate_normal(this_mu_g, x_cov, N), axis=0)\n",
    "    g_mat.append([g] * N)\n",
    "\n",
    "print x_draws.shape\n",
    "print len(true_mu_g)\n",
    "g_mat = np.concatenate(g_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['g'] = g_mat\n",
    "for col in range(x_draws.shape[1]):\n",
    "    df['x' + str(col)] = x_draws[:,col]\n",
    "df['row'] = range(df.shape[0])\n",
    "df_melt = pd.melt(df, id_vars=['g', 'row'])\n",
    "\n",
    "print df_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ggplot(aes(x='value'), data=df_melt) + geom_histogram(bins=30) + facet_grid('g', 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_info = np.linalg.inv(x_cov)\n",
    "g = 1\n",
    "x_g = x_draws[g_mat == g, :]\n",
    "x_g_sum = x_g.sum(axis=0)\n",
    "# x_g_outer = np.matmul(x_g.T, x_g)\n",
    "# print np.sum([x_g[i, 0] ** 2 for i in range(x_g.shape[0])])\n",
    "# print x_g_outer\n",
    "\n",
    "mu_g = mvn_par['mu_g'].mvn_params[g]\n",
    "e_mu = mu_g.e()\n",
    "e_mu_outer = mu_g.e_outer()\n",
    "e_mu_cov = mu_g.cov.get()\n",
    "\n",
    "def LogLikelihood(x_row, x_info, e_mu, e_mu_cov):\n",
    "    # TODO: if you're not using autodiff you can just do the matrix multiply once.\n",
    "    return 0.5 * (np.dot(e_mu, np.matmul(x_info, x_row)) + \\\n",
    "                  np.dot(x_row, np.matmul(x_info, e_mu)) - \\\n",
    "                  np.dot(e_mu, x_info, e_mu) - \\\n",
    "                  np.trace(np.matmul(x_info, e_mu_cov)))\n",
    "\n",
    "@primitive\n",
    "def LogLikelihoodAD(x_row, x_info, e_mu, e_mu_cov):\n",
    "    return LogLikelihood(x_row, x_info, e_mu, e_mu_cov)\n",
    "\n",
    "def LogLikelihoodGrad_e_mu(x_row, x_info, e_mu):\n",
    "    return np.matmul(x_info, x_row)\n",
    "\n",
    "def LogLikelihoodGrad_e_mu_cov(x_info):\n",
    "    return x_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the variational objective\n",
    "\n",
    "def LogLikelihood(x_row, x_info, e_mu, e_mu_outer):\n",
    "    return 0.5 * (np.dot(e_mu, np.matmul(x_info, x_row)) + \\\n",
    "                  np.dot(x_row, np.matmul(x_info, e_mu)) - \\\n",
    "                  np.trace(np.matmul(x_info, e_mu_outer)))\n",
    "\n",
    "\n",
    "def UnivariateNormalExpectedEntropy(var_mu):\n",
    "    return 0.5 * np.log(var_mu)\n",
    "\n",
    "\n",
    "def Elbo(x_draws, mvn_par_elbo):\n",
    "    x_info = np.linalg.inv(x_cov)\n",
    "    var_mu = mvn_par_elbo['var_mu'].get()\n",
    "    e_mu = mvn_par_elbo['e_mu'].get()\n",
    "    e_mu_outer = np.outer(e_mu, e_mu) + np.diag(var_mu)\n",
    "\n",
    "    ll = sum([ LogLikelihood(x, x_info, e_mu, e_mu_outer) for x in x_draws ])\n",
    "    entropy = sum([ UnivariateNormalExpectedEntropy(var_mu_k) for var_mu_k in var_mu])\n",
    "\n",
    "    return ll + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, mvn_par):\n",
    "        self.__mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(x_draws, self.__mvn_par_ad)\n",
    "        if verbose: print kl\n",
    "        return kl\n",
    "    \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMu(self, free_par_vec):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        return self.__mvn_par_ad['e_mu'].get()\n",
    "\n",
    "    \n",
    "kl_wrapper = KLWrapper(mvn_par)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMu)\n",
    "\n",
    "print mvn_par\n",
    "mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "print mvn_par_ad\n",
    "        \n",
    "mvn_par['e_mu'].set(np.array([1., 2., 3.]))\n",
    "print mvn_par['e_mu']\n",
    "print mvn_par_ad['e_mu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that the AD functions are working:\n",
    "free_par_vec = mvn_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "print KLGrad(free_par_vec)\n",
    "print KLHess(free_par_vec)\n",
    "print MomentJacobian(free_par_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian time:'\n",
    "print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set initial values.\n",
    "\n",
    "# Is there not a better way than reduce?\n",
    "true_means = reduce(lambda x, y: x + y, x_draws) / N\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 1.0))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimize.\n",
    "\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-6)\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hess=KLHess)\n",
    "mvn_par_opt = copy.deepcopy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean parameters match, as expected.\n",
    "print mvn_par_opt['e_mu']\n",
    "print true_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "opt_hess = KLHess(vb_opt.x)\n",
    "mu_cov = np.matmul(moment_jac, np.linalg.solve(opt_hess, moment_jac.T))\n",
    "\n",
    "# The VB variance is underestimated.\n",
    "print np.diag(mu_cov)\n",
    "print mvn_par_opt['var_mu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
