{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "from autograd import grad, hessian, jacobian\n",
    "import math\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622459331202\n",
      "[ 0.95257413  0.98201379]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01814993, -0.04858735])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "\n",
    "K = 3\n",
    "mvn_par = ModelParamsDict()\n",
    "\n",
    "mvn_par.push_param(VectorParam('e_mu', K))\n",
    "mvn_par.push_param(VectorParam('var_mu', K, lb=0))\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 0.1))\n",
    "mvn_par['var_mu'].set(np.full(K, 2.))\n",
    "\n",
    "def Logistic(rho):\n",
    "    return np.exp(rho) / (1 + np.exp(rho))\n",
    "\n",
    "print Logistic(0.5)\n",
    "print Logistic(np.array([3., 4.]))\n",
    "\n",
    "\n",
    "# From Stan:\n",
    "#     inline double log1m_inv_logit(double u) {\n",
    "#       using std::exp;\n",
    "#       if (u > 0.0)\n",
    "#         return -u - log1p(exp(-u));  // prevent underflow\n",
    "#       return -log1p(exp(u));\n",
    "#     }\n",
    "\n",
    "def Log1mInvLogit(u):\n",
    "    return -np.log1p(np.exp(-u))\n",
    "    \n",
    "Log1mInvLogit(5.0)\n",
    "Log1mInvLogit(np.array([4., 3.]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[ 0.20925728  0.68612165  0.1123016 ]\n",
      "[-0.34514176 -0.08677326  0.11753542]\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 100\n",
    "true_mu = np.random.rand(K).T - 0.5\n",
    "x_mat = np.full([N, K], float('nan'))\n",
    "y_vec = np.full([N], float('nan'))\n",
    "for n in range(N):\n",
    "    x_mat[n, :] = np.random.random(K) - 0.5\n",
    "    y_vec[n] = np.random.random(1) < Logistic(np.dot(x_mat[n, :], true_mu))\n",
    "\n",
    "print K\n",
    "print np.random.random(K)\n",
    "print x_mat[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2., 3.])\n",
    "a * a\n",
    "np.sum(a * a * a)\n",
    "\n",
    "foo_mat = np.full([10, 3], 2.)\n",
    "\n",
    "# for foo_row in foo_mat:\n",
    "#     print '-----\\n'\n",
    "#     print foo_row\n",
    "\n",
    "print foo_mat.shape[0]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0456006707902\n",
      "2.65016042208\n",
      "-1.09201937507\n",
      "-0.670606750294\n",
      "[-3.49283452 -2.36195842 -1.55664749 -0.87865787 -0.25700868  0.34821002\n",
      "  0.96985921  1.64784883  2.45315976  3.58403586]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "num_draws = 10\n",
    "target_quantiles = np.linspace(1 / float(num_draws + 1), 1 - 1 / float(num_draws + 1), num_draws)\n",
    "std_draws = scipy.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "x_row = x_mat[1]\n",
    "y = y_vec[1]\n",
    "\n",
    "e_mu = true_mu\n",
    "mu_var = 2\n",
    "\n",
    "rho_mean = np.dot(x_row, e_mu)\n",
    "rho_sd = math.sqrt(np.sum(x_row * x_row * mu_var))\n",
    "e_log_1mrho = np.mean(Log1mInvLogit(std_draws * rho_sd + rho_mean))\n",
    "\n",
    "print rho_mean\n",
    "print rho_sd\n",
    "print e_log_1mrho\n",
    "print Log1mInvLogit(rho_mean)\n",
    "print std_draws * rho_sd + rho_mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelParamsList:\n",
      "\tvar_mu: [ 2.  2.  2.]\n",
      "\te_mu: [ 1.  2.  3.]\n",
      "ModelParamsList:\n",
      "\te_mu: [ 1.  2.  3.]\n",
      "\tvar_mu: [ 2.  2.  2.]\n",
      "e_mu: [ 1.  2.  3.]\n",
      "e_mu: [ 1.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "# Define the variational objective\n",
    "def LogLikelihood(x_row, y, e_mu, mu_var, std_draws):\n",
    "    # logit(rho) is the probability of y being 1, which has a normal distribution under q().\n",
    "    rho_mean = np.dot(x_row, e_mu)\n",
    "    rho_sd = np.sqrt(np.sum(x_row * x_row * mu_var))\n",
    "    e_log_1mrho = np.mean(Log1mInvLogit(std_draws * rho_sd + rho_mean))\n",
    "    return y * rho_mean + e_log_1mrho\n",
    "\n",
    "\n",
    "def UnivariateNormalExpectedEntropy(var_mu):\n",
    "    return 0.5 * np.log(var_mu)\n",
    "\n",
    "\n",
    "def Elbo(y_vec, x_mat, mvn_par_elbo, num_draws=10):\n",
    "    var_mu = mvn_par_elbo['var_mu'].get()\n",
    "    e_mu = mvn_par_elbo['e_mu'].get()\n",
    "\n",
    "    num_draws = 10\n",
    "    draw_spacing = 1 / float(num_draws + 1)\n",
    "    target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "    std_draws = scipy.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    assert y_vec.size == x_mat.shape[0]\n",
    "    assert e_mu.size == x_mat.shape[1]\n",
    "\n",
    "    ll = 0\n",
    "    for n in range(y_vec.size):\n",
    "        ll += LogLikelihood(x_mat[n, :], y_vec[n], e_mu, var_mu, std_draws)\n",
    "\n",
    "    entropy = sum([ UnivariateNormalExpectedEntropy(var_mu_k) for var_mu_k in var_mu])\n",
    "\n",
    "    return ll + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, mvn_par, x_mat, y_vec, num_draws):\n",
    "        self.__mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.num_draws = num_draws\n",
    "        \n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.__mvn_par_ad, num_draws=self.num_draws)\n",
    "        if verbose: print kl\n",
    "        return kl\n",
    "    \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMu(self, free_par_vec):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        return self.__mvn_par_ad['e_mu'].get()\n",
    "\n",
    "    \n",
    "kl_wrapper = KLWrapper(mvn_par, x_mat, y_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMu)\n",
    "\n",
    "print mvn_par\n",
    "mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "print mvn_par_ad\n",
    "        \n",
    "mvn_par['e_mu'].set(np.array([1., 2., 3.]))\n",
    "print mvn_par['e_mu']\n",
    "print mvn_par_ad['e_mu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.3637408438\n",
      "[ 1.68791352  6.6138131   4.75812245  1.09712622  3.45784933  8.02444811]\n",
      "[[ 1.76989961 -0.04916582 -0.35450619 -0.03815249 -0.06505899 -0.06444692]\n",
      " [-0.04916582  1.60702487  0.25394906 -0.02481552 -0.12399148 -0.1236297 ]\n",
      " [-0.35450619  0.25394906  1.25392492 -0.00833073 -0.03277036 -0.16887471]\n",
      " [-0.03815249 -0.02481552 -0.00833073  1.54802586 -0.06801167 -0.12478301]\n",
      " [-0.06505899 -0.12399148 -0.03277036 -0.06801167  3.6678677  -0.27765126]\n",
      " [-0.06444692 -0.1236297  -0.16887471 -0.12478301 -0.27765126  7.24896791]]\n",
      "[[ 1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Check that the AD functions are working:\n",
    "free_par_vec = mvn_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "print KLGrad(free_par_vec)\n",
    "print KLHess(free_par_vec)\n",
    "print MomentJacobian(free_par_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.00340960025787\n",
      "Grad time:\n",
      "0.0393475055695\n",
      "Hessian time:\n",
      "0.291237211227\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "# Pretty fast!\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian time:'\n",
    "print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set initial values.\n",
    "\n",
    "# Is there not a better way than reduce?\n",
    "true_means = reduce(lambda x, y: x + y, x_draws) / N\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 1.0))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFGS\n",
      "2732.76192496\n",
      "inf\n",
      "2732.73603852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/bin/anaconda2/lib/python2.7/site-packages/autograd/core.py:134: RuntimeWarning: divide by zero encountered in log\n",
      "  result = self.fun(*argvals, **kwargs)\n",
      "/home/rgiordan/bin/anaconda2/lib/python2.7/site-packages/autograd/core.py:134: RuntimeWarning: divide by zero encountered in divide\n",
      "  result = self.fun(*argvals, **kwargs)\n",
      "/home/rgiordan/bin/anaconda2/lib/python2.7/site-packages/autograd/core.py:134: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = self.fun(*argvals, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558.32455446\n",
      "303669.763199\n",
      "1553.74963671\n",
      "1544.56032712\n",
      "1508.83904737\n",
      "1382.23377577\n",
      "1095.86488507\n",
      "641.186715507\n",
      "268.675994152\n",
      "115.096105596\n",
      "55541.5199031\n",
      "114.867294796\n",
      "114.405755296\n",
      "112.572701931\n",
      "105.446077532\n",
      "79.9825880193\n",
      "27.2497601176\n",
      "69.2804084502\n",
      "17.5547960997\n",
      "1.43803056927\n",
      "-9.24001870708\n",
      "-25.0536097994\n",
      "-34.3067174834\n",
      "-38.7341808603\n",
      "-40.6332768776\n",
      "-41.3151337798\n",
      "-41.4932009191\n",
      "-41.5201766956\n",
      "-41.5229853189\n",
      "-41.524823725\n",
      "-41.5280095513\n",
      "-41.5332868461\n",
      "-41.5399419253\n",
      "-41.5415517145\n",
      "-41.5421710368\n",
      "-41.5422947856\n",
      "-41.5423871811\n",
      "-41.5425438616\n",
      "-41.5427929597\n",
      "-41.5430401867\n",
      "-41.5431013571\n",
      "-41.5431166283\n",
      "-41.543117084\n",
      "-41.5431170911\n",
      "-41.5431170911\n",
      "Running Newton Trust Region\n",
      "-41.5431170911\n",
      "-41.5431170911\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-6)\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hess=KLHess)\n",
    "mvn_par_opt = copy.deepcopy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_mu: [ 0.89950874  0.62786963  0.8276449 ]\n",
      "[ 0.89950874  0.62786963  0.8276449 ]\n"
     ]
    }
   ],
   "source": [
    "# The mean parameters match, as expected.\n",
    "print mvn_par_opt['e_mu']\n",
    "print true_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.01  0.01]\n",
      "var_mu: [ 0.00147368  0.00147368  0.00147368]\n"
     ]
    }
   ],
   "source": [
    "# LRVB\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "opt_hess = KLHess(vb_opt.x)\n",
    "mu_cov = np.matmul(moment_jac, np.linalg.solve(opt_hess, moment_jac.T))\n",
    "\n",
    "# The VB variance is underestimated.\n",
    "print np.diag(mu_cov)\n",
    "print mvn_par_opt['var_mu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
