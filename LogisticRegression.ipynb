{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "import math\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "from autograd.core import primitive\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "import copy\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "\n",
    "K = 5\n",
    "mvn_par = ModelParamsDict()\n",
    "\n",
    "mvn_par.push_param(VectorParam('e_mu', K))\n",
    "mvn_par.push_param(VectorParam('var_mu', K, lb=0))\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 0.1))\n",
    "mvn_par['var_mu'].set(np.full(K, 2.))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Log1mInvLogit(u):\n",
    "    # log(1 + exp(-u)) = u + log(1 + exp(u))\n",
    "    return -np.log1p(np.exp(u))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 200000\n",
    "true_mu = np.random.rand(K).T - 0.5\n",
    "x_mat = np.full([N, K], float('nan'))\n",
    "y_vec = np.full([N], float('nan'))\n",
    "for n in range(N):\n",
    "    x_mat[n, :] = np.random.random(K) - 0.5\n",
    "    y_vec[n] = np.random.random(1) < Logistic(np.dot(x_mat[n, :], true_mu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the variational objective\n",
    "def LogLikelihood(x_row, y, e_mu, mu_var, std_draws):\n",
    "    # logit(rho) is the probability of y being 1, which has a normal distribution under q().\n",
    "    rho_mean = np.dot(x_row, e_mu)\n",
    "    rho_sd = np.sqrt(np.sum(x_row * x_row * mu_var))\n",
    "    e_log_1mrho = 0.\n",
    "    for std_draw in std_draws:\n",
    "        e_log_1mrho += Log1mInvLogit(std_draw * rho_sd + rho_mean)\n",
    "    e_log_1mrho /= len(std_draws)\n",
    "    # e_log_1mrho = np.mean(Log1mInvLogit(std_draws * rho_sd + rho_mean))\n",
    "    return y * rho_mean + e_log_1mrho\n",
    "\n",
    "# Just to see how much faster a simpler function is\n",
    "def LogLikelihoodJunk(x_row, y, e_mu, mu_var, std_draws):\n",
    "    # logit(rho) is the probability of y being 1, which has a normal distribution under q().\n",
    "    rho_mean = np.dot(x_row, e_mu)\n",
    "    rho_sd = np.sum(mu_var)\n",
    "    e_log_1mrho = 0.\n",
    "    for std_draw in std_draws:\n",
    "        e_log_1mrho += np.exp(std_draw * rho_sd + rho_mean)\n",
    "    e_log_1mrho /= len(std_draws)\n",
    "    # e_log_1mrho = np.mean(Log1mInvLogit(std_draws * rho_sd + rho_mean))\n",
    "    return y * rho_mean + e_log_1mrho\n",
    "\n",
    "\n",
    "def UnivariateNormalExpectedEntropy(var_mu):\n",
    "    return 0.5 * np.log(var_mu)\n",
    "\n",
    "\n",
    "def Elbo(y_vec, x_mat, mvn_par_elbo, num_draws=10):\n",
    "    var_mu = mvn_par_elbo['var_mu'].get()\n",
    "    e_mu = mvn_par_elbo['e_mu'].get()\n",
    "\n",
    "    num_draws = 10\n",
    "    draw_spacing = 1 / float(num_draws + 1)\n",
    "    target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "    std_draws = scipy.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    assert y_vec.size == x_mat.shape[0]\n",
    "    assert e_mu.size == x_mat.shape[1]\n",
    "\n",
    "    ll = 0\n",
    "    for n in range(y_vec.size):\n",
    "        #ll += LogLikelihood(x_mat[n, :], y_vec[n], e_mu, var_mu, std_draws)\n",
    "        ll += LogLikelihoodJunk(x_mat[n, :], y_vec[n], e_mu, var_mu, std_draws)\n",
    "\n",
    "    entropy = sum([ UnivariateNormalExpectedEntropy(var_mu_k) for var_mu_k in var_mu])\n",
    "\n",
    "    return ll + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, mvn_par, x_mat, y_vec, num_draws):\n",
    "        self.__mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.num_draws = num_draws\n",
    "        \n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.__mvn_par_ad, num_draws=self.num_draws)\n",
    "        if verbose: print kl\n",
    "        return kl\n",
    "    \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMu(self, free_par_vec):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        return self.__mvn_par_ad['e_mu'].get()\n",
    "\n",
    "    \n",
    "kl_wrapper = KLWrapper(mvn_par, x_mat, y_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMu)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-916375487.479\n",
      "Grad:\n",
      "[  2.56821327e+08   2.14038365e+08   2.22173668e+08   2.65241202e+08\n",
      "   2.59800995e+08  -1.03331548e+09  -1.73837905e+09  -1.62902433e+09\n",
      "  -1.04581870e+09  -1.34448324e+09]\n",
      "Hess:\n",
      "[[ -1.08601594e+08  -5.97832492e+07  -6.20320320e+07  -7.46762397e+07\n",
      "   -7.26689854e+07   2.89591835e+08   4.87189427e+08   4.56542221e+08\n",
      "    2.93095923e+08   3.76798155e+08]\n",
      " [ -5.97832492e+07  -9.81902660e+07  -5.17464564e+07  -6.23715383e+07\n",
      "   -6.05022931e+07   2.41351910e+08   4.06033889e+08   3.80491864e+08\n",
      "    2.44272291e+08   3.14031487e+08]\n",
      " [ -6.20320320e+07  -5.17464564e+07  -1.00303898e+08  -6.47180963e+07\n",
      "   -6.28799236e+07   2.50525114e+08   4.21466257e+08   3.94953442e+08\n",
      "    2.53556491e+08   3.25967066e+08]\n",
      " [ -7.46762397e+07  -6.23715383e+07  -6.47180963e+07  -1.12241665e+08\n",
      "   -7.54802529e+07   2.99086183e+08   5.03162067e+08   4.71510084e+08\n",
      "    3.02705154e+08   3.89151587e+08]\n",
      " [ -7.26689854e+07  -6.05022931e+07  -6.28799236e+07  -7.54802529e+07\n",
      "   -1.09826192e+08   2.92952884e+08   4.92843825e+08   4.61840923e+08\n",
      "    2.96497641e+08   3.81171334e+08]\n",
      " [  2.89591835e+08   2.41351910e+08   2.50525114e+08   2.99086183e+08\n",
      "    2.92952884e+08  -2.21533135e+09  -1.98854236e+09  -1.86345084e+09\n",
      "   -1.19631836e+09  -1.53796255e+09]\n",
      " [  4.87189427e+08   4.06033889e+08   4.21466257e+08   5.03162067e+08\n",
      "    4.92843825e+08  -1.98854236e+09  -5.08376622e+09  -3.13494179e+09\n",
      "   -2.01260390e+09  -2.58736263e+09]\n",
      " [  4.56542221e+08   3.80491864e+08   3.94953442e+08   4.71510084e+08\n",
      "    4.61840923e+08  -1.86345084e+09  -3.13494179e+09  -4.56675903e+09\n",
      "   -1.88599876e+09  -2.42460163e+09]\n",
      " [  2.93095923e+08   2.44272291e+08   2.53556491e+08   3.02705154e+08\n",
      "    2.96497641e+08  -1.19631836e+09  -2.01260390e+09  -1.88599876e+09\n",
      "   -2.25661262e+09  -1.55657204e+09]\n",
      " [  3.76798155e+08   3.14031487e+08   3.25967066e+08   3.89151587e+08\n",
      "    3.81171334e+08  -1.53796255e+09  -2.58736263e+09  -2.42460163e+09\n",
      "   -1.55657204e+09  -3.34558057e+09]]\n",
      "Jac:\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "Hess vector product:\n",
      "[  3.35860020e+09   2.80629598e+09   2.91354057e+09   3.46861322e+09\n",
      "   3.39545181e+09  -1.40500631e+10  -2.45411327e+10  -2.28915041e+10\n",
      "  -1.42326487e+10  -1.86349508e+10]\n"
     ]
    }
   ],
   "source": [
    "# Check that the AD functions are working:\n",
    "mvn_par['e_mu'].set(true_mu)\n",
    "mvn_par['var_mu'].set(np.abs(true_mu) * 0.1)\n",
    "free_par_vec = mvn_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "if K < 10:\n",
    "    print 'Grad:'\n",
    "    print KLGrad(free_par_vec)\n",
    "    print 'Hess:'\n",
    "    print KLHess(free_par_vec)\n",
    "    print 'Jac:'\n",
    "    print MomentJacobian(free_par_vec)\n",
    "    print 'Hess vector product:'\n",
    "    print KLHessVecProd(free_par_vec, free_par_vec + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.0106568336487\n",
      "Grad time:\n",
      "0.308406114578\n",
      "Hessian vector product time:\n",
      "0.609016895294\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 1\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "if K < 10:\n",
    "    print 'Hessian time:'\n",
    "    print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run('kl_wrapper.Eval(free_par_vec)', '/tmp/cprofilestats_func.prof')\n",
    "cProfile.run('KLHess(free_par_vec)', '/tmp/cprofilestats_hess.prof')\n",
    "cProfile.run('KLGrad(free_par_vec)', '/tmp/cprofilestats_grad.prof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 22 18:17:23 2017    /tmp/cprofilestats\n",
      "\n",
      "         12676517 function calls (12415228 primitive calls) in 7.331 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 183 to 100 due to restriction <100>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.010    0.010    7.331    7.331 <string>:1(<module>)\n",
      "      2/1    0.000    0.000    7.321    7.321 convenience_wrappers.py:53(jacfun)\n",
      "214857/14    0.124    0.000    7.088    0.506 {map}\n",
      "       11    0.036    0.003    7.088    0.644 core.py:18(<lambda>)\n",
      "       11    0.886    0.081    7.051    0.641 core.py:31(backward_pass)\n",
      "   221916    0.164    0.000    2.397    0.000 core.py:76(vjp)\n",
      "222222/175779    0.888    0.000    1.606    0.000 core.py:59(__call__)\n",
      "   179768    0.650    0.000    1.515    0.000 core.py:166(toposort)\n",
      "   265957    0.276    0.000    1.147    0.000 core.py:253(assert_vspace_match)\n",
      "   179757    0.153    0.000    0.854    0.000 core.py:127(vsum)\n",
      "      2/1    0.000    0.000    0.852    0.852 core.py:13(vjp)\n",
      "      2/1    0.004    0.002    0.852    0.852 core.py:21(forward_pass)\n",
      "   289396    0.231    0.000    0.676    0.000 core.py:238(vspace)\n",
      "   183231    0.261    0.000    0.658    0.000 numpy_grads.py:451(unbroadcast)\n",
      "  2393443    0.454    0.000    0.584    0.000 numpy_extra.py:66(__hash__)\n",
      "   359514    0.403    0.000    0.536    0.000 core.py:167(relevant_parents)\n",
      "   210649    0.149    0.000    0.527    0.000 core.py:115(__call__)\n",
      "     4200    0.094    0.000    0.494    0.000 numpy_grads.py:298(grad_tensordot)\n",
      "    46443    0.093    0.000    0.458    0.000 core.py:133(primitive_vsum)\n",
      "    68410    0.061    0.000    0.446    0.000 numpy_grads.py:21(<lambda>)\n",
      "   289372    0.274    0.000    0.405    0.000 numpy_extra.py:69(__init__)\n",
      "    66431    0.053    0.000    0.375    0.000 numpy_extra.py:45(__mul__)\n",
      "   609924    0.187    0.000    0.318    0.000 core.py:260(<lambda>)\n",
      "     2200    0.008    0.000    0.306    0.000 numpy_grads.py:289(grad_dot)\n",
      "    20000    0.038    0.000    0.274    0.000 numpy_grads.py:25(<lambda>)\n",
      "    46443    0.054    0.000    0.246    0.000 numpy_extra.py:76(zeros)\n",
      "    24010    0.029    0.000    0.239    0.000 numpy_grads.py:20(<lambda>)\n",
      "        1    0.000    0.000    0.229    0.229 <ipython-input-37-d3da326ac3c2>:47(Eval)\n",
      "        1    0.001    0.001    0.228    0.228 <ipython-input-37-d3da326ac3c2>:18(Elbo)\n",
      "  1081336    0.227    0.000    0.227    0.000 core.py:259(<lambda>)\n",
      "      200    0.011    0.000    0.224    0.001 <ipython-input-37-d3da326ac3c2>:2(LogLikelihood)\n",
      "    24200    0.022    0.000    0.197    0.000 numpy_extra.py:46(__pow__)\n",
      "    44211    0.019    0.000    0.176    0.000 numpy_grads.py:18(<lambda>)\n",
      "    22011    0.018    0.000    0.150    0.000 numpy_grads.py:60(<lambda>)\n",
      "   304004    0.148    0.000    0.148    0.000 {numpy.core.multiarray.array}\n",
      "   265957    0.143    0.000    0.143    0.000 core.py:203(__eq__)\n",
      "  2393444    0.130    0.000    0.130    0.000 {id}\n",
      "     2000    0.007    0.000    0.122    0.000 numpy_grads.py:66(<lambda>)\n",
      "    23417    0.022    0.000    0.122    0.000 core.py:232(new_node)\n",
      "   132620    0.119    0.000    0.119    0.000 core.py:199(mut_add)\n",
      "     6201    0.005    0.000    0.115    0.000 numpy_extra.py:43(__add__)\n",
      "    23417    0.016    0.000    0.100    0.000 core.py:151(__init__)\n",
      "    24400    0.010    0.000    0.094    0.000 numpy_grads.py:19(<lambda>)\n",
      "     2000    0.068    0.000    0.090    0.000 numpy_extra.py:55(__rdiv__)\n",
      "    12432    0.030    0.000    0.089    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "     6200    0.010    0.000    0.087    0.000 fromnumeric.py:826(argsort)\n",
      "   567552    0.079    0.000    0.079    0.000 {method 'append' of 'list' objects}\n",
      "     4600    0.007    0.000    0.076    0.000 numpy_extra.py:53(__rmul__)\n",
      "     4200    0.037    0.000    0.072    0.000 numeric.py:1213(tensordot)\n",
      "     2200    0.002    0.000    0.069    0.000 numpy_grads.py:213(grad_np_sum)\n",
      "    16169    0.020    0.000    0.069    0.000 numpy_extra.py:116(<lambda>)\n",
      "     2200    0.006    0.000    0.067    0.000 numpy_grads.py:189(repeat_to_match_shape)\n",
      "   204431    0.062    0.000    0.062    0.000 fromnumeric.py:2564(ndim)\n",
      "    12600    0.008    0.000    0.062    0.000 newrange.py:140(__iter__)\n",
      "     2000    0.004    0.000    0.060    0.000 <ipython-input-35-bcc62171d39e>:2(Log1mInvLogit)\n",
      "   445713    0.059    0.000    0.059    0.000 {method 'pop' of 'list' objects}\n",
      "     8400    0.015    0.000    0.057    0.000 numpy_grads.py:311(convert_negative_indices)\n",
      "    12600    0.040    0.000    0.054    0.000 newrange.py:149(__init__)\n",
      "    21000    0.046    0.000    0.053    0.000 newrange.py:37(__init__)\n",
      "     6200    0.019    0.000    0.047    0.000 fromnumeric.py:42(_wrapit)\n",
      "     2000    0.008    0.000    0.045    0.000 numpy_grads.py:45(<lambda>)\n",
      "   422030    0.042    0.000    0.044    0.000 {len}\n",
      "     2000    0.004    0.000    0.043    0.000 numpy_grads.py:183(grad_transpose)\n",
      "     2200    0.013    0.000    0.036    0.000 fromnumeric.py:2388(prod)\n",
      "     2200    0.008    0.000    0.034    0.000 numpy_grads.py:84(<lambda>)\n",
      "    46454    0.034    0.000    0.034    0.000 {numpy.core.multiarray.zeros}\n",
      "     4401    0.032    0.000    0.032    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "    14603    0.008    0.000    0.026    0.000 numeric.py:463(asarray)\n",
      "     2000    0.002    0.000    0.024    0.000 numpy_grads.py:102(<lambda>)\n",
      "     2200    0.002    0.000    0.024    0.000 _methods.py:34(_prod)\n",
      "    16169    0.015    0.000    0.020    0.000 type_check.py:237(iscomplexobj)\n",
      "     2001    0.002    0.000    0.019    0.000 numpy_extra.py:42(__neg__)\n",
      "     2200    0.006    0.000    0.018    0.000 fromnumeric.py:1710(sum)\n",
      "     4200    0.017    0.000    0.018    0.000 {sorted}\n",
      "     6200    0.003    0.000    0.016    0.000 fromnumeric.py:504(transpose)\n",
      "   121844    0.014    0.000    0.014    0.000 {method 'update' of 'set' objects}\n",
      "   179757    0.014    0.000    0.014    0.000 {method 'extend' of 'list' objects}\n",
      "    21000    0.009    0.000    0.013    0.000 newrange.py:155(next)\n",
      "     2200    0.001    0.000    0.011    0.000 _methods.py:31(_sum)\n",
      "    12626    0.010    0.000    0.010    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "     2200    0.003    0.000    0.009    0.000 numeric.py:258(full)\n",
      "     2000    0.009    0.000    0.009    0.000 {numpy.core.multiarray.where}\n",
      "     4400    0.009    0.000    0.009    0.000 {numpy.core.multiarray.dot}\n",
      "    12600    0.008    0.000    0.008    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "     6200    0.007    0.000    0.007    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "    18634    0.007    0.000    0.007    0.000 {getattr}\n",
      "    23200    0.007    0.000    0.007    0.000 {max}\n",
      "     4400    0.004    0.000    0.006    0.000 newrange.py:117(__getitem__)\n",
      "    44020    0.005    0.000    0.005    0.000 core.py:142(<lambda>)\n",
      "    16169    0.005    0.000    0.005    0.000 {issubclass}\n",
      "    21000    0.005    0.000    0.005    0.000 {next}\n",
      "     6627    0.004    0.000    0.004    0.000 {isinstance}\n",
      "    12601    0.004    0.000    0.004    0.000 {range}\n",
      "     2201    0.004    0.000    0.004    0.000 {numpy.core.multiarray.copyto}\n",
      "    16800    0.003    0.000    0.003    0.000 newrange.py:87(__len__)\n",
      "      200    0.000    0.000    0.003    0.000 numpy_extra.py:47(__div__)\n",
      "     2000    0.003    0.000    0.003    0.000 {method 'transpose' of 'numpy.generic' objects}\n",
      "    12600    0.002    0.000    0.002    0.000 newrange.py:64(start)\n",
      "      201    0.000    0.000    0.002    0.000 numpy_extra.py:51(__radd__)\n",
      "     2201    0.002    0.000    0.002    0.000 {numpy.core.multiarray.empty}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats instance at 0x7fde9c733e18>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('/tmp/cprofilestats')\n",
    "p.strip_dirs().sort_stats('cumulative').print_stats(100)\n",
    "# p.strip_dirs().sort_stats('cumulative').print_callers(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set initial values.\n",
    "\n",
    "# Is there not a better way than reduce?\n",
    "true_means = reduce(lambda x, y: x + y, x_draws) / N\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 1.0))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimize.\n",
    "\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-6)\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hess=KLHess)\n",
    "mvn_par_opt = copy.deepcopy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean parameters match, as expected.\n",
    "print mvn_par_opt['e_mu']\n",
    "print true_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "opt_hess = KLHess(vb_opt.x)\n",
    "mu_cov = np.matmul(moment_jac, np.linalg.solve(opt_hess, moment_jac.T))\n",
    "\n",
    "# The VB variance is underestimated.\n",
    "print np.diag(mu_cov)\n",
    "print mvn_par_opt['var_mu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
