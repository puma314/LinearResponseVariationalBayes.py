{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "import math\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "from autograd.core import primitive\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "import copy\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "\n",
    "K = 5\n",
    "mvn_par = ModelParamsDict()\n",
    "\n",
    "mvn_par.push_param(VectorParam('e_mu', K))\n",
    "mvn_par.push_param(VectorParam('var_mu', K, lb=0))\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 0.1))\n",
    "mvn_par['var_mu'].set(np.full(K, 2.))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log1mInvLogit as a function of u, but with cacheing through the second and third arguments.\n",
    "\n",
    "@primitive\n",
    "def Log1mInvLogit(u, exp_u, logit_u):\n",
    "    return -np.log1p(exp_u)\n",
    "    \n",
    "@primitive\n",
    "def Log1mInvLogitDerivative(u, exp_u, logit_u):\n",
    "    return -logit_u\n",
    "\n",
    "@primitive\n",
    "def Log1mInvLogitSecondDerivative(u, exp_u, logit_u):\n",
    "    return -logit_u * (1 - logit_u)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 2000\n",
    "true_mu = np.random.rand(K).T - 0.5\n",
    "x_mat = np.full([N, K], float('nan'))\n",
    "y_vec = np.full([N], float('nan'))\n",
    "for n in range(N):\n",
    "    x_mat[n, :] = np.random.random(K) - 0.5\n",
    "    y_vec[n] = np.random.random(1) < Logistic(np.dot(x_mat[n, :], true_mu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the variational objective\n",
    "def LogLikelihood(x_row, y, e_mu, mu_var, std_draws):\n",
    "    # logit(rho) is the probability of y being 1, which has a normal distribution under q().\n",
    "    rho_mean = np.dot(x_row, e_mu)\n",
    "    rho_sd = np.sqrt(np.sum(x_row * x_row * mu_var))\n",
    "    e_log_1mrho = 0.\n",
    "    for std_draw in std_draws:\n",
    "        e_log_1mrho += Log1mInvLogit(std_draw * rho_sd + rho_mean)\n",
    "    e_log_1mrho /= len(std_draws)\n",
    "    # e_log_1mrho = np.mean(Log1mInvLogit(std_draws * rho_sd + rho_mean))\n",
    "    return y * rho_mean + e_log_1mrho\n",
    "\n",
    "\n",
    "def UnivariateNormalExpectedEntropy(var_mu):\n",
    "    return 0.5 * np.log(var_mu)\n",
    "\n",
    "\n",
    "def Elbo(y_vec, x_mat, mvn_par_elbo, num_draws=10):\n",
    "    var_mu = mvn_par_elbo['var_mu'].get()\n",
    "    e_mu = mvn_par_elbo['e_mu'].get()\n",
    "\n",
    "    num_draws = 10\n",
    "    draw_spacing = 1 / float(num_draws + 1)\n",
    "    target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "    std_draws = scipy.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    assert y_vec.size == x_mat.shape[0]\n",
    "    assert e_mu.size == x_mat.shape[1]\n",
    "\n",
    "    ll = 0\n",
    "    for n in range(y_vec.size):\n",
    "        ll += LogLikelihood(x_mat[n, :], y_vec[n], e_mu, var_mu, std_draws)\n",
    "\n",
    "    entropy = sum([ UnivariateNormalExpectedEntropy(var_mu_k) for var_mu_k in var_mu])\n",
    "\n",
    "    return ll + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, mvn_par, x_mat, y_vec, num_draws):\n",
    "        self.__mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.num_draws = num_draws\n",
    "        \n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.__mvn_par_ad, num_draws=self.num_draws)\n",
    "        if verbose: print kl\n",
    "        return kl\n",
    "    \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMu(self, free_par_vec):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        return self.__mvn_par_ad['e_mu'].get()\n",
    "\n",
    "    \n",
    "kl_wrapper = KLWrapper(mvn_par, x_mat, y_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMu)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2579.63452921\n",
      "[-115.07877279  -85.3541339   -89.38439757  -77.76775508 -103.60087118\n",
      "    6.69562197   10.34572124   10.86197333    4.49925244    9.70880184]\n",
      "[[  2.04679907e+01  -4.13480773e+00  -3.62714885e+00  -4.67434094e+00\n",
      "   -3.62158347e+00   6.37240467e-01   4.27846693e-01   4.79172288e-01\n",
      "    1.74230068e-01   3.79573780e-01]\n",
      " [ -4.13480773e+00   2.19003055e+01  -2.49240733e+00  -1.89805624e+00\n",
      "   -1.75929790e+00   2.04668793e-01   6.97109712e-01   4.05351554e-01\n",
      "    1.58815788e-01   2.97076745e-01]\n",
      " [ -3.62714885e+00  -2.49240733e+00   2.23301967e+01  -2.60297719e+00\n",
      "   -2.37872576e+00   1.72397323e-01   3.08149750e-01   5.98881571e-01\n",
      "    1.61331665e-01   2.93191353e-01]\n",
      " [ -4.67434094e+00  -1.89805624e+00  -2.60297719e+00   2.10269172e+01\n",
      "   -2.99783040e+00   2.14655270e-01   3.93053296e-01   3.95711575e-01\n",
      "    3.38140342e-01   3.22622279e-01]\n",
      " [ -3.62158347e+00  -1.75929790e+00  -2.37872576e+00  -2.99783040e+00\n",
      "    2.16954031e+01   2.02499307e-01   3.72006603e-01   3.84069508e-01\n",
      "    1.82463186e-01   7.02910783e-01]\n",
      " [  6.37240467e-01   2.04668793e-01   1.72397323e-01   2.14655270e-01\n",
      "    2.02499307e-01   7.18073212e+00  -1.33657346e-02  -1.64599949e-02\n",
      "   -5.87147915e-03  -1.34760829e-02]\n",
      " [  4.27846693e-01   6.97109712e-01   3.08149750e-01   3.93053296e-01\n",
      "    3.72006603e-01  -1.33657346e-02   1.07985728e+01  -2.64322448e-02\n",
      "   -9.98873656e-03  -2.35241633e-02]\n",
      " [  4.79172288e-01   4.05351554e-01   5.98881571e-01   3.95711575e-01\n",
      "    3.84069508e-01  -1.64599949e-02  -2.64322448e-02   1.13056464e+01\n",
      "   -1.28365331e-02  -2.81586743e-02]\n",
      " [  1.74230068e-01   1.58815788e-01   1.61331665e-01   3.38140342e-01\n",
      "    1.82463186e-01  -5.87147915e-03  -9.98873656e-03  -1.28365331e-02\n",
      "    4.98899285e+00  -1.22153730e-02]\n",
      " [  3.79573780e-01   2.97076745e-01   2.93191353e-01   3.22622279e-01\n",
      "    7.02910783e-01  -1.34760829e-02  -2.35241633e-02  -2.81586743e-02\n",
      "   -1.22153730e-02   1.01610112e+01]]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "[-31.45021776 -15.08582627 -13.45657323 -20.79883876 -16.49515198\n",
      "   4.00650034  10.30190443  11.14001526   1.03743447   9.32374177]\n"
     ]
    }
   ],
   "source": [
    "# Check that the AD functions are working:\n",
    "mvn_par['e_mu'].set(true_mu)\n",
    "mvn_par['var_mu'].set(np.abs(true_mu) * 0.1)\n",
    "free_par_vec = mvn_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "if K < 10:\n",
    "    print KLGrad(free_par_vec)\n",
    "    print KLHess(free_par_vec)\n",
    "    print MomentJacobian(free_par_vec)\n",
    "    print KLHessVecProd(free_par_vec, free_par_vec + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.116110960642\n",
      "Grad time:\n",
      "3.5185303688\n",
      "Hessian vector product time:\n",
      "7.93109003703\n",
      "Hessian time:\n",
      "40.0598433812\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 3\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "if K < 10:\n",
    "    print 'Hessian time:'\n",
    "    print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('kl_wrapper.Eval(free_par_vec)', '/tmp/cprofilestats')\n",
    "# cProfile.run('KLGrad(free_par_vec)', '/tmp/cprofilestats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ordered by: cumulative time\n",
      "   List reduced from 170 to 100 due to restriction <100>\n",
      "\n",
      "Function                                          was called by...\n",
      "                                                      ncalls  tottime  cumtime\n",
      "<string>:1(<module>)                              <-\n",
      "convenience_wrappers.py:21(gradfun)               <-       1    0.000    8.578  <string>:1(<module>)\n",
      "core.py:18(<lambda>)                              <-       1    0.047    4.564  convenience_wrappers.py:21(gradfun)\n",
      "core.py:31(backward_pass)                         <-       1    0.628    4.517  core.py:18(<lambda>)\n",
      "core.py:59(__call__)                              <-    6000    0.023    0.066  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "                                                           5    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:14(UnivariateNormalExpectedEntropy)\n",
      "                                                           7    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:18(Elbo)\n",
      "                                                       40000    1.374    1.513  <ipython-input-8-1b8076e6fdbe>:1(Log1mInvLogit)\n",
      "                                                           1    0.000    0.000  Parameters.py:32(constrain)\n",
      "                                                           2    0.000    0.000  Parameters.py:197(set_free)\n",
      "                                                       14012    0.050    0.197  core.py:127(vsum)\n",
      "                                                           7    0.000    0.000  numpy_extra.py:12(grad_take)\n",
      "                                                       30010    0.111    0.222  numpy_extra.py:42(__neg__)\n",
      "                                                       62005    0.319    0.505  numpy_extra.py:43(__add__)\n",
      "                                                       10009    0.054    0.092  numpy_extra.py:44(__sub__)\n",
      "                                                       20001    0.078    0.090  numpy_extra.py:45(__mul__)\n",
      "                                                        2000    0.012    0.013  numpy_extra.py:46(__pow__)\n",
      "                                                        2000    0.013    0.022  numpy_extra.py:47(__div__)\n",
      "                                                        2002    0.012    0.019  numpy_extra.py:51(__radd__)\n",
      "                                                       24005    1.250    1.348  numpy_extra.py:53(__rmul__)\n",
      "                                                           5    0.000    0.000  numpy_extra.py:55(__rdiv__)\n",
      "                                                       14012    0.019    0.032  numpy_extra.py:76(zeros)\n",
      "                                                        4000    0.010    0.042  numpy_grads.py:189(repeat_to_match_shape)\n",
      "                                                        4000    0.011    0.047  numpy_grads.py:298(grad_tensordot)\n",
      "core.py:13(vjp)                                   <-       1    0.000    4.014  convenience_wrappers.py:21(gradfun)\n",
      "core.py:21(forward_pass)                          <-       1    0.000    4.014  core.py:13(vjp)\n",
      "convenience_wrappers.py:18(scalar_fun)            <-       1    0.000    4.014  core.py:21(forward_pass)\n",
      "<ipython-input-14-eb31a6dbdeac>:46(Eval)          <-       1    0.000    4.014  convenience_wrappers.py:18(scalar_fun)\n",
      "<ipython-input-14-eb31a6dbdeac>:18(Elbo)          <-       1    0.005    4.014  <ipython-input-14-eb31a6dbdeac>:46(Eval)\n",
      "<ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)  <-    2000    0.091    3.989  <ipython-input-14-eb31a6dbdeac>:18(Elbo)\n",
      "<ipython-input-8-1b8076e6fdbe>:1(Log1mInvLogit)   <-   20000    0.062    2.023  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "core.py:76(vjp)                                   <-  208057    0.131    1.425  core.py:31(backward_pass)\n",
      "numpy_extra.py:53(__rmul__)                       <-   24000    0.020    1.368  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "                                                           5    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:14(UnivariateNormalExpectedEntropy)\n",
      "core.py:166(toposort)                             <-  156046    0.483    1.097  core.py:31(backward_pass)\n",
      "core.py:253(assert_vspace_match)                  <-  208058    0.189    0.804  core.py:31(backward_pass)\n",
      "core.py:238(vspace)                               <-       1    0.000    0.000  convenience_wrappers.py:203(as_scalar)\n",
      "                                                      156045    0.104    0.314  core.py:151(__init__)\n",
      "                                                      208058    0.126    0.423  core.py:253(assert_vspace_match)\n",
      "                                                           7    0.000    0.000  numpy_extra.py:16(untake)\n",
      "numpy_grads.py:451(unbroadcast)                   <-   42005    0.058    0.222  numpy_grads.py:18(<lambda>)\n",
      "                                                       44006    0.055    0.213  numpy_grads.py:19(<lambda>)\n",
      "                                                       24005    0.030    0.077  numpy_grads.py:21(<lambda>)\n",
      "                                                       10009    0.013    0.061  numpy_grads.py:22(<lambda>)\n",
      "                                                       10009    0.013    0.072  numpy_grads.py:23(<lambda>)\n",
      "                                                        2000    0.003    0.012  numpy_grads.py:24(<lambda>)\n",
      "core.py:115(__call__)                             <-   20000    0.038    0.080  numpy_extra.py:61(__gt__)\n",
      "                                                        4000    0.003    0.008  numpy_grads.py:289(grad_dot)\n",
      "                                                        6000    0.004    0.037  numpy_grads.py:298(grad_tensordot)\n",
      "                                                        4000    0.003    0.007  numpy_grads.py:311(convert_negative_indices)\n",
      "                                                      132034    0.119    0.478  numpy_grads.py:451(unbroadcast)\n",
      "numpy_extra.py:43(__add__)                        <-   40000    0.034    0.396  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "                                                        2000    0.001    0.019  <ipython-input-14-eb31a6dbdeac>:18(Elbo)\n",
      "                                                           1    0.000    0.000  Parameters.py:32(constrain)\n",
      "                                                       20000    0.017    0.142  numpy_grads.py:66(<lambda>)\n",
      "                                                           4    0.000    0.000  {sum}\n",
      "core.py:232(new_node)                             <-  156044    0.116    0.510  core.py:59(__call__)\n",
      "                                                           1    0.000    0.000  core.py:119(new_progenitor)\n",
      "numpy_extra.py:69(__init__)                       <-  336072    0.294    0.411  core.py:238(vspace)\n",
      "                                                       28032    0.024    0.039  numpy_extra.py:116(<lambda>)\n",
      "numpy_extra.py:66(__hash__)                       <-       1    0.000    0.000  core.py:13(vjp)\n",
      "                                                      676193    0.116    0.151  core.py:31(backward_pass)\n",
      "                                                           1    0.000    0.000  core.py:119(new_progenitor)\n",
      "                                                      780212    0.132    0.168  core.py:166(toposort)\n",
      "                                                      416114    0.073    0.094  core.py:167(relevant_parents)\n",
      "                                                           1    0.000    0.000  {method 'add' of 'set' objects}\n",
      "                                                           1    0.000    0.000  {method 'remove' of 'set' objects}\n",
      "core.py:151(__init__)                             <-  156045    0.080    0.394  core.py:232(new_node)\n",
      "core.py:127(vsum)                                 <-  156045    0.109    0.383  core.py:31(backward_pass)\n",
      "core.py:167(relevant_parents)                     <-  312090    0.284    0.378  core.py:166(toposort)\n",
      "core.py:260(<lambda>)                             <-       1    0.000    0.000  convenience_wrappers.py:203(as_scalar)\n",
      "                                                      142033    0.040    0.066  core.py:127(vsum)\n",
      "                                                      208058    0.054    0.095  core.py:253(assert_vspace_match)\n",
      "                                                      186034    0.053    0.091  {map}\n",
      "numpy_extra.py:42(__neg__)                        <-       1    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:46(Eval)\n",
      "                                                       30009    0.024    0.247  <ipython-input-8-1b8076e6fdbe>:1(Log1mInvLogit)\n",
      "numpy_grads.py:18(<lambda>)                       <-   42005    0.016    0.238  core.py:76(vjp)\n",
      "fromnumeric.py:2564(ndim)                         <-  144034    0.155    0.233  core.py:115(__call__)\n",
      "numpy_grads.py:19(<lambda>)                       <-   44006    0.015    0.228  core.py:76(vjp)\n",
      "numpy_grads.py:289(grad_dot)                      <-    2000    0.006    0.217  core.py:76(vjp)\n",
      "{map}                                             <-       2    0.000    0.000  _distn_infrastructure.py:1871(ppf)\n",
      "                                                      166034    0.093    0.185  core.py:115(__call__)\n",
      "                                                        2000    0.003    0.030  numpy_grads.py:298(grad_tensordot)\n",
      "numpy_grads.py:298(grad_tensordot)                <-    2000    0.040    0.202  numpy_grads.py:289(grad_dot)\n",
      "core.py:259(<lambda>)                             <-       1    0.000    0.000  core.py:13(vjp)\n",
      "                                                      428159    0.080    0.080  core.py:59(__call__)\n",
      "                                                           1    0.000    0.000  core.py:119(new_progenitor)\n",
      "                                                      536126    0.105    0.105  core.py:260(<lambda>)\n",
      "{numpy.core.multiarray.array}                     <-   74036    0.054    0.054  numeric.py:463(asarray)\n",
      "                                                          18    0.000    0.000  numeric.py:534(asanyarray)\n",
      "                                                      364104    0.131    0.131  numpy_extra.py:69(__init__)\n",
      "numpy_grads.py:66(<lambda>)                       <-   20000    0.022    0.164  core.py:76(vjp)\n",
      "core.py:133(primitive_vsum)                       <-   14012    0.036    0.135  core.py:59(__call__)\n",
      "numpy_grads.py:60(<lambda>)                       <-   20001    0.014    0.119  core.py:76(vjp)\n",
      "numpy_extra.py:45(__mul__)                        <-   20001    0.015    0.105  numpy_grads.py:60(<lambda>)\n",
      "numpy_extra.py:44(__sub__)                        <-   10009    0.010    0.102  <ipython-input-8-1b8076e6fdbe>:1(Log1mInvLogit)\n",
      "numpy_extra.py:61(__gt__)                         <-   20000    0.020    0.099  <ipython-input-8-1b8076e6fdbe>:1(Log1mInvLogit)\n",
      "numpy_grads.py:21(<lambda>)                       <-   24005    0.020    0.098  core.py:76(vjp)\n",
      "core.py:203(__eq__)                               <-  208058    0.097    0.097  core.py:253(assert_vspace_match)\n",
      "numpy_extra.py:116(<lambda>)                      <-   28032    0.026    0.095  core.py:238(vspace)\n",
      "{id}                                              <-       1    0.000    0.000  copy.py:306(_reconstruct)\n",
      "                                                     1872523    0.092    0.092  numpy_extra.py:66(__hash__)\n",
      "numeric.py:463(asarray)                           <-    2000    0.001    0.006  fromnumeric.py:42(_wrapit)\n",
      "                                                       68033    0.030    0.077  fromnumeric.py:2564(ndim)\n",
      "                                                        4000    0.002    0.003  numeric.py:1213(tensordot)\n",
      "                                                           3    0.000    0.000  {map}\n",
      "numpy_grads.py:23(<lambda>)                       <-   10009    0.004    0.077  core.py:76(vjp)\n",
      "{method 'append' of 'list' objects}               <-  208057    0.029    0.029  core.py:31(backward_pass)\n",
      "                                                      250064    0.032    0.032  core.py:59(__call__)\n",
      "                                                      156044    0.011    0.011  core.py:166(toposort)\n",
      "                                                           5    0.000    0.000  shape_base.py:9(atleast_1d)\n",
      "numpy_grads.py:22(<lambda>)                       <-   10009    0.004    0.064  core.py:76(vjp)\n",
      "core.py:199(mut_add)                              <-   66018    0.049    0.049  core.py:133(primitive_vsum)\n",
      "numpy_extra.py:76(zeros)                          <-   14012    0.017    0.049  core.py:133(primitive_vsum)\n",
      "numpy_grads.py:213(grad_np_sum)                   <-    2000    0.001    0.048  core.py:76(vjp)\n",
      "numpy_grads.py:189(repeat_to_match_shape)         <-    2000    0.005    0.047  numpy_grads.py:213(grad_np_sum)\n",
      "{method 'pop' of 'list' objects}                  <-  364103    0.045    0.045  core.py:166(toposort)\n",
      "type_check.py:237(iscomplexobj)                   <-   28032    0.021    0.030  numpy_extra.py:116(<lambda>)\n",
      "numeric.py:1213(tensordot)                        <-    2000    0.015    0.030  core.py:59(__call__)\n",
      "{len}                                             <-    2000    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "                                                           2    0.000    0.000  copy.py:306(_reconstruct)\n",
      "                                                      156045    0.012    0.012  core.py:127(vsum)\n",
      "                                                       10000    0.001    0.001  newrange.py:37(__init__)\n",
      "                                                        6000    0.003    0.004  newrange.py:149(__init__)\n",
      "                                                        8000    0.001    0.001  numeric.py:1213(tensordot)\n",
      "                                                        4000    0.000    0.000  numpy_grads.py:298(grad_tensordot)\n",
      "                                                      132034    0.010    0.010  numpy_grads.py:451(unbroadcast)\n",
      "                                                           8    0.000    0.000  shape_base.py:9(atleast_1d)\n",
      "numpy_grads.py:311(convert_negative_indices)      <-    4000    0.007    0.027  {map}\n",
      "fromnumeric.py:826(argsort)                       <-    2000    0.003    0.026  core.py:115(__call__)\n",
      "fromnumeric.py:55(_wrapfunc)                      <-       5    0.000    0.000  fromnumeric.py:70(take)\n",
      "                                                        2000    0.001    0.003  fromnumeric.py:504(transpose)\n",
      "                                                        2000    0.008    0.023  fromnumeric.py:826(argsort)\n",
      "                                                           5    0.000    0.000  fromnumeric.py:1471(nonzero)\n",
      "fromnumeric.py:2388(prod)                         <-    2000    0.008    0.024  core.py:59(__call__)\n",
      "{method 'reduce' of 'numpy.ufunc' objects}        <-    2000    0.009    0.009  _methods.py:31(_sum)\n",
      "                                                        2000    0.015    0.015  _methods.py:34(_prod)\n",
      "                                                           1    0.000    0.000  _methods.py:37(_any)\n",
      "numpy_extra.py:47(__div__)                        <-    2000    0.002    0.024  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "{method 'update' of 'set' objects}                <-  250064    0.023    0.023  core.py:59(__call__)\n",
      "newrange.py:37(__init__)                          <-    6000    0.013    0.015  numpy_grads.py:298(grad_tensordot)\n",
      "                                                        4000    0.007    0.008  numpy_grads.py:311(convert_negative_indices)\n",
      "numpy_extra.py:51(__radd__)                       <-    2000    0.002    0.021  <ipython-input-14-eb31a6dbdeac>:2(LogLikelihood)\n",
      "                                                           1    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:18(Elbo)\n",
      "                                                           1    0.000    0.000  {sum}\n",
      "numpy_grads.py:84(<lambda>)                       <-    2000    0.006    0.021  core.py:76(vjp)\n",
      "newrange.py:140(__iter__)                         <-    6000    0.004    0.020  numpy_grads.py:298(grad_tensordot)\n",
      "fromnumeric.py:1710(sum)                          <-    2000    0.005    0.017  core.py:59(__call__)\n",
      "newrange.py:149(__init__)                         <-    6000    0.011    0.016  newrange.py:140(__iter__)\n",
      "_methods.py:34(_prod)                             <-    2000    0.001    0.016  fromnumeric.py:2388(prod)\n",
      "numpy_extra.py:46(__pow__)                        <-    2000    0.002    0.015  numpy_grads.py:84(<lambda>)\n",
      "fromnumeric.py:42(_wrapit)                        <-    2000    0.005    0.014  fromnumeric.py:55(_wrapfunc)\n",
      "numpy_grads.py:24(<lambda>)                       <-    2000    0.001    0.014  core.py:76(vjp)\n",
      "{method 'extend' of 'list' objects}               <-  156045    0.012    0.012  core.py:166(toposort)\n",
      "{numpy.core.multiarray.zeros}                     <-   14012    0.011    0.011  core.py:59(__call__)\n",
      "_methods.py:31(_sum)                              <-    2000    0.001    0.010  fromnumeric.py:1710(sum)\n",
      "{issubclass}                                      <-   28032    0.009    0.009  type_check.py:237(iscomplexobj)\n",
      "{sorted}                                          <-    2000    0.007    0.008  numpy_grads.py:298(grad_tensordot)\n",
      "numeric.py:258(full)                              <-    2000    0.002    0.007  core.py:59(__call__)\n",
      "numpy_grads.py:54(<lambda>)                       <-   30010    0.006    0.006  core.py:76(vjp)\n",
      "{numpy.core.multiarray.dot}                       <-    2000    0.003    0.003  core.py:59(__call__)\n",
      "                                                        2000    0.003    0.003  numeric.py:1213(tensordot)\n",
      "newrange.py:155(next)                             <-   10000    0.004    0.006  numpy_grads.py:298(grad_tensordot)\n",
      "{method 'reshape' of 'numpy.ndarray' objects}     <-    6000    0.005    0.005  numeric.py:1213(tensordot)\n",
      "                                                           4    0.000    0.000  shape_base.py:9(atleast_1d)\n",
      "newrange.py:117(__getitem__)                      <-    4000    0.003    0.005  numpy_grads.py:311(convert_negative_indices)\n",
      "fromnumeric.py:504(transpose)                     <-    2000    0.001    0.004  core.py:59(__call__)\n",
      "{isinstance}                                      <-       3    0.000    0.000  _distn_infrastructure.py:520(argsreduce)\n",
      "                                                           1    0.000    0.000  _util.py:14(_valarray)\n",
      "                                                           1    0.000    0.000  convenience_wrappers.py:196(safe_type)\n",
      "                                                           3    0.000    0.000  copy.py:306(_reconstruct)\n",
      "                                                          10    0.000    0.000  fromnumeric.py:1364(ravel)\n",
      "                                                        2000    0.002    0.002  fromnumeric.py:1710(sum)\n",
      "                                                           3    0.000    0.000  function_base.py:2171(place)\n",
      "                                                        4000    0.002    0.002  newrange.py:117(__getitem__)\n",
      "{method 'transpose' of 'numpy.ndarray' objects}   <-    2000    0.001    0.001  fromnumeric.py:55(_wrapfunc)\n",
      "                                                        4000    0.002    0.002  numeric.py:1213(tensordot)\n",
      "{numpy.core.multiarray.copyto}                    <-       1    0.000    0.000  numeric.py:150(ones)\n",
      "                                                        2000    0.003    0.003  numeric.py:258(full)\n",
      "{max}                                             <-   10000    0.002    0.002  newrange.py:37(__init__)\n",
      "                                                        2000    0.001    0.001  numpy_grads.py:289(grad_dot)\n",
      "{method 'argsort' of 'numpy.ndarray' objects}     <-    2000    0.002    0.002  fromnumeric.py:42(_wrapit)\n",
      "{numpy.core.multiarray.empty}                     <-       1    0.000    0.000  numeric.py:150(ones)\n",
      "                                                        2000    0.002    0.002  numeric.py:258(full)\n",
      "{getattr}                                         <-       2    0.000    0.000  copy.py:66(copy)\n",
      "                                                        2000    0.000    0.000  fromnumeric.py:42(_wrapit)\n",
      "                                                        4010    0.001    0.001  fromnumeric.py:55(_wrapfunc)\n",
      "{next}                                            <-   10000    0.002    0.002  newrange.py:155(next)\n",
      "{range}                                           <-       1    0.000    0.000  <ipython-input-14-eb31a6dbdeac>:18(Elbo)\n",
      "                                                        6000    0.001    0.001  numeric.py:1213(tensordot)\n",
      "newrange.py:87(__len__)                           <-    2000    0.000    0.000  numpy_grads.py:298(grad_tensordot)\n",
      "                                                        6000    0.001    0.001  {len}\n",
      "newrange.py:64(start)                             <-    6000    0.001    0.001  newrange.py:149(__init__)\n",
      "newrange.py:72(step)                              <-    6000    0.001    0.001  newrange.py:149(__init__)\n",
      "numpy_grads.py:332(<lambda>)                      <-    2000    0.000    0.000  {sorted}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats instance at 0x7fde598b87a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('/tmp/cprofilestats')\n",
    "# p.strip_dirs().sort_stats('cumulative').print_stats(100)\n",
    "p.strip_dirs().sort_stats('cumulative').print_callers(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set initial values.\n",
    "\n",
    "# Is there not a better way than reduce?\n",
    "true_means = reduce(lambda x, y: x + y, x_draws) / N\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 1.0))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimize.\n",
    "\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-6)\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hess=KLHess)\n",
    "mvn_par_opt = copy.deepcopy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean parameters match, as expected.\n",
    "print mvn_par_opt['e_mu']\n",
    "print true_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "opt_hess = KLHess(vb_opt.x)\n",
    "mu_cov = np.matmul(moment_jac, np.linalg.solve(opt_hess, moment_jac.T))\n",
    "\n",
    "# The VB variance is underestimated.\n",
    "print np.diag(mu_cov)\n",
    "print mvn_par_opt['var_mu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
