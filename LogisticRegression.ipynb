{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "import math\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "from autograd.core import primitive\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "import copy\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Log1mInvLogit(u):\n",
    "    # log(1 + exp(-u)) = u + log(1 + exp(u))\n",
    "    return -np.log1p(np.exp(u))\n",
    "\n",
    "def Logistic(u):\n",
    "    return np.exp(u) / (1 + np.exp(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 20000\n",
    "K = 50\n",
    "\n",
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "mvn_par = ModelParamsDict()\n",
    "\n",
    "mvn_par.push_param(VectorParam('e_mu', K))\n",
    "mvn_par.push_param(VectorParam('var_mu', K, lb=0))\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 0.1))\n",
    "mvn_par['var_mu'].set(np.full(K, 2.))\n",
    "\n",
    "# Generate data\n",
    "true_mu = np.random.rand(K) - 0.5\n",
    "x_mat = np.full([N, K], float('nan'))\n",
    "y_vec = np.full([N], float('nan'))\n",
    "for n in range(N):\n",
    "    x_mat[n, :] = np.random.random(K) - 0.5\n",
    "    y_vec[n] = np.random.random(1) < Logistic(np.dot(x_mat[n, :], true_mu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the variational objective\n",
    "def LogLikelihood(x_row, y, e_mu, mu_var, std_draws):\n",
    "    # logit(rho) is the probability of y being 1, which has a normal distribution under q().\n",
    "    rho_mean = np.dot(x_row, e_mu)\n",
    "    rho_sd = np.sqrt(np.sum(x_row * x_row * mu_var))\n",
    "    e_log_1mrho = 0.\n",
    "    for std_draw in std_draws:\n",
    "        e_log_1mrho += Log1mInvLogit(std_draw * rho_sd + rho_mean)\n",
    "    e_log_1mrho /= len(std_draws)\n",
    "    # e_log_1mrho = np.mean(Log1mInvLogit(std_draws * rho_sd + rho_mean))\n",
    "    return y * rho_mean + e_log_1mrho\n",
    "\n",
    "def LogLikelihoodVectorized(x_mat, y_vec, e_mu, mu_var, std_draws):\n",
    "    rho_sd = np.sqrt(np.einsum('ik,ik,k->i', x_mat, x_mat, mu_var))\n",
    "    rho_mean = np.einsum('ij,j->i', x_mat, e_mu)\n",
    "    z = np.einsum('i,j->ij', rho_sd, std_draws) + np.expand_dims(rho_mean, 1)\n",
    "\n",
    "    # log(1 + exp(-u)) = u + log(1 + exp(u))\n",
    "    logit_term = np.sum(rho_mean) + np.sum(np.log(1 + np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * rho_mean)\n",
    "    return y_term - logit_term\n",
    "\n",
    "\n",
    "def UnivariateNormalExpectedEntropy(var_mu):\n",
    "    return 0.5 * np.sum(np.log(var_mu))\n",
    "\n",
    "\n",
    "def Elbo(y_vec, x_mat, mvn_par_elbo, num_draws=10):\n",
    "    var_mu = mvn_par_elbo['var_mu'].get()\n",
    "    e_mu = mvn_par_elbo['e_mu'].get()\n",
    "\n",
    "    num_draws = 10\n",
    "    draw_spacing = 1 / float(num_draws + 1)\n",
    "    target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "    std_draws = scipy.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    assert y_vec.size == x_mat.shape[0]\n",
    "    assert e_mu.size == x_mat.shape[1]\n",
    "\n",
    "    ll = LogLikelihoodVectorized(x_mat, y_vec, e_mu, var_mu, std_draws)\n",
    "    #ll = 0\n",
    "    #for n in range(y_vec.size):\n",
    "    #    #ll += LogLikelihood(x_mat[n, :], y_vec[n], e_mu, var_mu, std_draws)\n",
    "    #    ll += LogLikelihoodJunk(x_mat[n, :], y_vec[n], e_mu, var_mu, std_draws)\n",
    "\n",
    "    entropy = UnivariateNormalExpectedEntropy(var_mu)\n",
    "\n",
    "    return ll + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, mvn_par, x_mat, y_vec, num_draws):\n",
    "        self.__mvn_par_ad = copy.deepcopy(mvn_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.num_draws = num_draws\n",
    "        \n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.__mvn_par_ad, num_draws=self.num_draws)\n",
    "        if verbose: print kl\n",
    "        return kl\n",
    "    \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMu(self, free_par_vec):\n",
    "        self.__mvn_par_ad.set_free(free_par_vec)\n",
    "        return self.__mvn_par_ad['e_mu'].get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41533.9253034\n"
     ]
    }
   ],
   "source": [
    "kl_wrapper = KLWrapper(mvn_par, x_mat, y_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMu)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "\n",
    "# Check that the AD functions are working:\n",
    "mvn_par['e_mu'].set(true_mu)\n",
    "mvn_par['var_mu'].set(np.abs(true_mu) * 0.1)\n",
    "free_par_vec = mvn_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "if K < 10:\n",
    "    print 'Grad:'\n",
    "    print KLGrad(free_par_vec)\n",
    "    print 'Hess:'\n",
    "    print KLHess(free_par_vec)\n",
    "    print 'Jac:'\n",
    "    print MomentJacobian(free_par_vec)\n",
    "    print 'Hess vector product:'\n",
    "    print KLHessVecProd(free_par_vec, free_par_vec + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.0109079122543\n",
      "Grad time:\n",
      "0.0134150981903\n",
      "Hessian vector product time:\n",
      "0.0242169857025\n",
      "Hessian time:\n",
      "0.322512412071\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian time:'\n",
    "print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run('kl_wrapper.Eval(free_par_vec)', '/tmp/cprofilestats_func.prof')\n",
    "cProfile.run('KLHess(free_par_vec)', '/tmp/cprofilestats_hess.prof')\n",
    "cProfile.run('KLGrad(free_par_vec)', '/tmp/cprofilestats_grad.prof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('/tmp/cprofilestats')\n",
    "p.strip_dirs().sort_stats('cumulative').print_stats(100)\n",
    "# p.strip_dirs().sort_stats('cumulative').print_callers(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set initial values.\n",
    "\n",
    "# Is there not a better way than reduce?\n",
    "true_means = reduce(lambda x, y: x + y, x_draws) / N\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 1.0))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimize.\n",
    "\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-6)\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hess=KLHess)\n",
    "mvn_par_opt = copy.deepcopy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean parameters match, as expected.\n",
    "print mvn_par_opt['e_mu']\n",
    "print true_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "opt_hess = KLHess(vb_opt.x)\n",
    "mu_cov = np.matmul(moment_jac, np.linalg.solve(opt_hess, moment_jac.T))\n",
    "\n",
    "# The VB variance is underestimated.\n",
    "print np.diag(mu_cov)\n",
    "print mvn_par_opt['var_mu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
