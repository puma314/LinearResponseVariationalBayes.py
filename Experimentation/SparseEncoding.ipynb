{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "import autograd\n",
    "from autograd.core import primitive\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from VariationalBayes import Parameters\n",
    "from VariationalBayes import \\\n",
    "    ScalarParam, VectorParam, ArrayParam, \\\n",
    "    PosDefMatrixParam, PosDefMatrixParamVector, SimplexParam\n",
    "from VariationalBayes.ParameterDictionary import ModelParamsDict\n",
    "import scipy as osp\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3123354.63772\n",
      "3123354.63772\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "\n",
    "mat = np.full(k ** 2, 0.2).reshape(k, k) + np.eye(k)\n",
    "vp_array = ArrayParam('array', shape=(4, 5, 7))\n",
    "vp_mat = PosDefMatrixParam('mat', k, val=mat)\n",
    "vp_simplex = SimplexParam('simplex', shape=(5, 3))\n",
    "\n",
    "\n",
    "mp = ModelParamsDict()\n",
    "mp.push_param(vp_mat)\n",
    "mp.push_param(vp_simplex)\n",
    "mp.push_param(vp_array)\n",
    "\n",
    "def model(mp):\n",
    "    mat = mp['mat'].get()\n",
    "    array = mp['array'].get()\n",
    "    simplex = mp['simplex'].get()\n",
    "    \n",
    "    return np.sum(mat)**2 * np.sum(array)**2 * np.sum(simplex)**2\n",
    "\n",
    "def model_wrap_free(free_param, mp):\n",
    "    mp.set_free(free_param)\n",
    "    return model_wrap_vec(mp.get_vector(), mp)\n",
    "\n",
    "def model_wrap_vec(vec_param, mp):\n",
    "    mp.set_vector(vec_param)\n",
    "    return model(mp)\n",
    "\n",
    "free_vec = np.random.random(mp.free_size())\n",
    "mp.set_free(free_vec)\n",
    "mp_vec = mp.get_vector()\n",
    "\n",
    "print(model_wrap_free(free_vec, mp))\n",
    "print(model_wrap_vec(mp_vec, mp))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 2)\t2.0\n",
      "  (1, 3)\t3.0\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  3.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "  (3, 4)\t2.0\n",
      "  (3, 5)\t3.0\n"
     ]
    }
   ],
   "source": [
    "foo = csr_matrix(([2., 3.], ([1, 1], [2, 3])), (4, 4))\n",
    "bar = csr_matrix(([4., 4.], ([0, 3], [1, 2])), (4, 4))\n",
    "print(foo)\n",
    "print(foo.toarray())\n",
    "#print(sparse.block_diag((foo, bar)).toarray())\n",
    "foo_offset = sparse.block_diag((csr_matrix(((), ((), ())), (2, 2)), foo))\n",
    "print(foo_offset.toarray())\n",
    "print(foo_offset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we need two steps.  Let $L$ be the objective and $f$ be the constraining function, so that \n",
    "\n",
    "$$\n",
    "\\theta = f(z) \\\\\n",
    "L(\\theta) = L(f(z))\n",
    "$$\n",
    "\n",
    "We need\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dz^T} = \\frac{dL}{d\\theta^T} \\frac{d\\theta}{dz} = \\frac{dL}{d\\theta^T} \\frac{df}{dz^T}\n",
    "$$\n",
    "\n",
    "and, using Einstein summation notation,\n",
    "\n",
    "$$\n",
    "\\frac{d^2 L}{dz_i dz_j} =\n",
    "    \\frac{d^2 L}{d\\theta_a d\\theta_b} \\frac{d\\theta_a}{dz_i} \\frac{d\\theta_b}{dz_j} +\n",
    "    \\frac{d L}{d\\theta_a} \\frac{d^2 \\theta_a}{dz_i dz_j}\n",
    "$$\n",
    "\n",
    "The term $\\frac{d^2 L}{d\\theta_a d\\theta_b}$ can be expressed using a combination of our ```get_vector()``` functions and a sparse matrix for the local variables.  $\\frac{d\\theta_a}{dz_i}$ can also be represented as a sparse matrix.  It may be best to store the term $\\frac{d^2 \\theta_a}{dz_i dz_j}$ in ```(value, a, i, j)``` format, and write a custom aggregator to return a sparse matrix when multiplied by $\\frac{d L}{d\\theta_a}$, since it is possible that this is not efficient in general [(discussion)](https://stackoverflow.com/questions/29871669/python-multi-dimensional-sparse-array).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# For an ArrayParam\n",
    "s = ArrayParam(name='scalar', shape=(5, 3), lb=0.0)\n",
    "s.set(np.exp(np.random.random(s.shape())))\n",
    "\n",
    "set_free_and_get_jacobian = autograd.jacobian(s.free_to_vector)\n",
    "set_free_and_get_hessian = autograd.hessian(s.free_to_vector)\n",
    "\n",
    "target_jac = set_free_and_get_jacobian(s.get_free())\n",
    "target_hess = set_free_and_get_hessian(s.get_free())\n",
    "\n",
    "sparse_jac = s.free_to_vector_jac(s.get_free())\n",
    "sparse_hess = s.free_to_vector_hess(s.get_free())\n",
    "\n",
    "print(np.max(np.abs(sparse_jac - target_jac)))\n",
    "print(np.max(np.abs([ sparse_hess[ind].toarray() - target_hess[ind] for ind in range(s.vector_size()) ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a SimplexParam\n",
    "\n",
    "from VariationalBayes.MultinomialParams import SimplexParam\n",
    "s = SimplexParam(name='simplex', shape=(10, 3))\n",
    "s_val = np.random.random(s.shape())\n",
    "s_val = s_val / np.expand_dims(np.sum(s_val, 1), axis=1)\n",
    "s.set(s_val)\n",
    "\n",
    "free_val = s.get_free()\n",
    "\n",
    "# Evidently the free params are in the columns and the vector params are in the rows.\n",
    "print(target_jac.shape)\n",
    "\n",
    "jac_time = time.time()\n",
    "target_jac = set_free_and_get_jacobian(s, free_val)\n",
    "jac_time = time.time() - jac_time\n",
    "print(jac_time)\n",
    "\n",
    "hess_time = time.time()\n",
    "target_hess = set_free_and_get_hessian(s, free_val)\n",
    "hess_time = time.time() - hess_time\n",
    "print(hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def constrain_simplex_vector(free_vec):\n",
    "    # The first column is the reference value.\n",
    "    free_vec_aug = np.hstack([[0.], free_vec])\n",
    "    log_norm = sp.misc.logsumexp(free_vec_aug)\n",
    "    return np.exp(free_vec_aug - log_norm)\n",
    "\n",
    "constrain_simplex_vector(free_vec)\n",
    "constrain_grad = autograd.jacobian(constrain_simplex_vector)\n",
    "constrain_hess = autograd.hessian(constrain_simplex_vector)\n",
    "\n",
    "constrain_grad(free_vec)\n",
    "constrain_hess(free_vec).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_jac_time = time.time()\n",
    "\n",
    "jac_rows = []\n",
    "jac_cols = []\n",
    "grads = []\n",
    "free_cols = range(s.free_shape()[1])\n",
    "vec_cols = range(s.shape()[1])\n",
    "for row in range(s.shape()[0]):\n",
    "    # Each of the output depends only on one row of the input.\n",
    "    free_inds = np.ravel_multi_index([[row], free_cols], s.free_shape())\n",
    "    vec_inds = np.ravel_multi_index([[row], vec_cols], s.shape())\n",
    "    row_jac = constrain_grad(free_val[free_inds])\n",
    "    for vec_col in vec_cols:\n",
    "        for free_col in free_cols: \n",
    "            jac_rows.append(vec_inds[vec_col])\n",
    "            jac_cols.append(free_inds[free_col])\n",
    "            grads.append(row_jac[vec_col,free_col])\n",
    "\n",
    "jac_sparse = csr_matrix((grads, (jac_rows, jac_cols)), (s.vector_size(), s.free_size()))\n",
    "print(np.max(np.abs(jac_sparse - target_jac)))\n",
    "\n",
    "sparse_jac_time = time.time() - sparse_jac_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_hess_time = time.time()\n",
    "\n",
    "free_cols = range(s.free_shape()[1])\n",
    "vec_cols = range(s.shape()[1])\n",
    "hesses = []\n",
    "hess_shape = (s.free_size(), s.free_size())\n",
    "\n",
    "for row in range(s.shape()[0]):\n",
    "    # Each of the output depends only on one row of the input.\n",
    "    free_inds = np.ravel_multi_index([[row], free_cols], s.free_shape())\n",
    "    vec_inds = np.ravel_multi_index([[row], vec_cols], s.shape())\n",
    "    row_hess = constrain_hess(free_val[free_inds])\n",
    "    #print(row_hess)\n",
    "    for vec_col in vec_cols:\n",
    "        vec_ind = vec_inds[vec_col]\n",
    "        hess_rows = []\n",
    "        hess_cols = []\n",
    "        hess_vals = []\n",
    "        for free_col1 in free_cols:\n",
    "            for free_col2 in free_cols:\n",
    "                hess_rows.append(free_inds[free_col1])\n",
    "                hess_cols.append(free_inds[free_col2])\n",
    "                hess_vals.append(row_hess[vec_col, free_col1, free_col2])\n",
    "        hesses.append(csr_matrix((hess_vals, (hess_rows, hess_cols)), hess_shape))\n",
    "\n",
    "        \n",
    "sparse_hess_time = time.time() - sparse_hess_time\n",
    "\n",
    "print(np.max(np.abs([ hesses[ind].toarray() - target_hess[ind] for ind in range(s.vector_size()) ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-----------')\n",
    "print(sparse_hess_time)\n",
    "print(hess_time)\n",
    "\n",
    "print('-----------')\n",
    "print(sparse_jac_time)\n",
    "print(jac_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
