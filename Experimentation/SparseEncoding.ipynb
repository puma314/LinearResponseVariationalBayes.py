{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "import autograd\n",
    "from autograd.core import primitive\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from VariationalBayes import Parameters\n",
    "from VariationalBayes.Parameters import \\\n",
    "    ScalarParam, VectorParam, ArrayParam, \\\n",
    "    PosDefMatrixParam, PosDefMatrixParamVector\n",
    "from VariationalBayes.ParameterDictionary import ModelParamsDict\n",
    "import scipy as osp\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelParamsDict:\n",
      "\tmat1:\n",
      "[[ 1.2  0.2]\n",
      " [ 0.2  1.2]]\n",
      "\tmat2:\n",
      "[[ 2.4  0.4]\n",
      " [ 0.4  2.4]]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "\n",
    "mat = np.full(k ** 2, 0.2).reshape(k, k) + np.eye(k)\n",
    "vp_mat1 = PosDefMatrixParam('mat1', k, val=mat)\n",
    "vp_mat2 = PosDefMatrixParam('mat2', k, val=mat * 2.)\n",
    "\n",
    "mp = ModelParamsDict()\n",
    "mp.push_param(vp_mat1)\n",
    "mp.push_param(vp_mat2)\n",
    "\n",
    "print(mp)\n",
    "\n",
    "free_vec = mp.get_free()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  0.2]\n",
      " [ 0.2  1.2]]\n",
      "[[ 2.4  0.4]\n",
      " [ 0.4  2.4]]\n",
      "--------\n",
      "[[[ 2.4         0.          0.          0.          0.          0.        ]\n",
      "  [ 0.2         1.09544512  0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.2         1.09544512  0.          0.          0.          0.        ]\n",
      "  [ 0.          0.36514837  2.33333333  0.          0.          0.        ]]]\n",
      "--------\n",
      "[[[ 0.          0.          0.          4.8         0.          0.        ]\n",
      "  [ 0.          0.          0.          0.4         1.54919334  0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.4         1.54919334  0.        ]\n",
      "  [ 0.          0.          0.          0.          0.51639778  4.66666667]]]\n"
     ]
    }
   ],
   "source": [
    "def get_param(mp, free_vec, par_name):\n",
    "    mp[par_name].set_free(free_vec[mp.free_indices_dict[par_name]])\n",
    "    return mp[par_name].get()\n",
    "\n",
    "print(get_param(mp, free_vec, 'mat1'))\n",
    "print(get_param(mp, free_vec, 'mat2'))\n",
    "\n",
    "get_param_jac = autograd.jacobian(get_param, argnum=1)\n",
    "\n",
    "print('--------')\n",
    "print(get_param_jac(mp, free_vec, 'mat1'))\n",
    "print('--------')\n",
    "print(get_param_jac(mp, free_vec, 'mat2'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  0.2]\n",
      " [ 0.2  1.2]]\n",
      "[[ 2.4  0.4]\n",
      " [ 0.4  2.4]]\n",
      "-----------------\n",
      "[[[ 2.4         0.          0.        ]\n",
      "  [ 0.2         1.09544512  0.        ]]\n",
      "\n",
      " [[ 0.2         1.09544512  0.        ]\n",
      "  [ 0.          0.36514837  2.33333333]]]\n",
      "-----------------\n",
      "[[[ 4.8         0.          0.        ]\n",
      "  [ 0.4         1.54919334  0.        ]]\n",
      "\n",
      " [[ 0.4         1.54919334  0.        ]\n",
      "  [ 0.          0.51639778  4.66666667]]]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "@primitive\n",
    "def get_param_sparse(mp, free_vec, par_name):\n",
    "    return get_param(mp, free_vec, par_name)\n",
    "\n",
    "def get_free_vec(mp, free_vec, par_name):\n",
    "    return free_vec[mp.free_indices_dict[par_name]]\n",
    "\n",
    "def set_free_and_get(free_vec_par, par):\n",
    "    par.set_free(free_vec_par)\n",
    "    return par.get()\n",
    "\n",
    "mat1_sub_vec = get_free_vec(mp, free_vec, 'mat1')\n",
    "mat2_sub_vec = get_free_vec(mp, free_vec, 'mat2')\n",
    "print(set_free_and_get(mat1_sub_vec, mp['mat1']))\n",
    "print(set_free_and_get(mat2_sub_vec, mp['mat2']))\n",
    "\n",
    "jac_dict = OrderedDict()\n",
    "jac_dict['mat1'] = autograd.jacobian(lambda free_sub_vec: set_free_and_get(free_sub_vec, mp['mat1']))\n",
    "jac_dict['mat2'] = autograd.jacobian(lambda free_sub_vec: set_free_and_get(free_sub_vec, mp['mat2']))\n",
    "\n",
    "print(\"-----------------\")\n",
    "print(jac_dict['mat1'](mat1_sub_vec))\n",
    "print(\"-----------------\")\n",
    "print(jac_dict['mat2'](mat2_sub_vec))\n",
    "print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "[ 1.68249408  1.07076969  0.52732613]\n",
      "[[ 0.87334886  0.52234057  0.44086049]\n",
      " [ 0.80914522  0.54842912  0.08646564]]\n",
      "[ 1.68249408  1.07076969  0.52732613]\n"
     ]
    }
   ],
   "source": [
    "foo = np.random.random((2, 2, 3))\n",
    "bar = np.random.random((2, 2))\n",
    "\n",
    "print((foo * np.expand_dims(bar, axis=2)).shape)\n",
    "print(np.sum(foo * np.expand_dims(bar, axis=2), (0, 1)))\n",
    "print(np.sum(foo * np.expand_dims(bar, axis=2), -2))\n",
    "print(np.sum([ foo[:, :, k] * bar for k in range(3) ], (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]]\n",
      "[[[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "def get_param_sparse_vjp(g, ans, vs, gvs, mp, free_vec, par_name):\n",
    "    jac = jac_dict[par_name](get_free_vec(mp, free_vec, par_name))\n",
    "    par_jac = np.sum(jac * np.expand_dims(g, axis=2), (0, 1))\n",
    "    full_jac = np.zeros(free_vec.shape)\n",
    "    inds = mp.free_indices_dict[par_name]\n",
    "    full_jac[inds] = par_jac\n",
    "    return full_jac\n",
    "\n",
    "    # Doesn't work:\n",
    "    #return csr_matrix((np.full(6, 0), (np.array(range(6)), np.full(6, 0))), (6, 1))\n",
    "    \n",
    "get_param_sparse.defvjp(get_param_sparse_vjp, argnum=1)\n",
    "\n",
    "get_param_sparse_jac = autograd.jacobian(get_param_sparse, argnum=1)\n",
    "print(get_param_sparse_jac(mp, free_vec, 'mat2') - get_param_jac(mp, free_vec, 'mat2'))\n",
    "print(get_param_sparse_jac(mp, free_vec, 'mat1') - get_param_jac(mp, free_vec, 'mat1'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 4.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 7.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1., 3., 4.]\n",
    "rows = [0, 2, 4]\n",
    "cols = [0, 0, 0]\n",
    "\n",
    "full_jac_sparse = csr_matrix((data, (rows, cols)), (5, 1))\n",
    "print(full_jac_sparse.toarray())\n",
    "\n",
    "\n",
    "# Are duplicates summed?  Yes.\n",
    "data = [1., 3., 4.]\n",
    "rows = [0, 2, 2]\n",
    "cols = [0, 0, 0]\n",
    "\n",
    "full_jac_sparse = csr_matrix((data, (rows, cols)), (5, 1))\n",
    "full_jac_sparse.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 6, 6)\n",
      "(2, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hessians get appended to the end\n",
    "get_param_hess = autograd.hessian(get_param, argnum=1)\n",
    "mat1_hess = get_param_hess(mp, free_vec, 'mat1')\n",
    "print(mat1_hess.shape)\n",
    "\n",
    "# As do Jacobians\n",
    "mat1_jac = get_param_jac(mp, free_vec, 'mat1')\n",
    "print(mat1_jac.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we need two steps.  Let $L$ be the objective and $f$ be the constraining function, so that \n",
    "\n",
    "$$\n",
    "\\theta = f(z) \\\\\n",
    "L(\\theta) = L(f(z))\n",
    "$$\n",
    "\n",
    "We need\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dz^T} = \\frac{dL}{d\\theta^T} \\frac{d\\theta}{dz} = \\frac{dL}{d\\theta^T} \\frac{df}{dz^T}\n",
    "$$\n",
    "\n",
    "and, using Einstein summation notation,\n",
    "\n",
    "$$\n",
    "\\frac{d^2 L}{dz_i dz_j} =\n",
    "    \\frac{d^2 L}{d\\theta_a d\\theta_b} \\frac{d\\theta_a}{dz_i} \\frac{d\\theta_b}{dz_j} +\n",
    "    \\frac{d L}{d\\theta_a} \\frac{d^2 \\theta_a}{dz_i dz_j}\n",
    "$$\n",
    "\n",
    "The term $\\frac{d^2 L}{d\\theta_a d\\theta_b}$ can be expressed using a combination of our ```get_vector()``` functions and a sparse matrix for the local variables.  $\\frac{d\\theta_a}{dz_i}$ can also be represented as a sparse matrix.  It may be best to store the term $\\frac{d^2 \\theta_a}{dz_i dz_j}$ in ```(value, a, i, j)``` format, and write a custom aggregator to return a sparse matrix when multiplied by $\\frac{d L}{d\\theta_a}$, since it is possible that this is not efficient in general [(discussion)](https://stackoverflow.com/questions/29871669/python-multi-dimensional-sparse-array).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# For an ArrayParam\n",
    "s = ArrayParam(name='scalar', shape=(5, 3), lb=0.0)\n",
    "s.set(np.exp(np.random.random(s.shape())))\n",
    "\n",
    "set_free_and_get_jacobian = autograd.jacobian(s.free_to_vector)\n",
    "set_free_and_get_hessian = autograd.hessian(s.free_to_vector)\n",
    "\n",
    "target_jac = set_free_and_get_jacobian(s.get_free())\n",
    "target_hess = set_free_and_get_hessian(s.get_free())\n",
    "\n",
    "sparse_jac = s.free_to_vector_jac(s.get_free())\n",
    "sparse_hess = s.free_to_vector_hess(s.get_free())\n",
    "\n",
    "print(np.max(np.abs(sparse_jac - target_jac)))\n",
    "print(np.max(np.abs([ sparse_hess[ind].toarray() - target_hess[ind] for ind in range(s.vector_size()) ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a SimplexParam\n",
    "\n",
    "from VariationalBayes.MultinomialParams import SimplexParam\n",
    "s = SimplexParam(name='simplex', shape=(10, 3))\n",
    "s_val = np.random.random(s.shape())\n",
    "s_val = s_val / np.expand_dims(np.sum(s_val, 1), axis=1)\n",
    "s.set(s_val)\n",
    "\n",
    "free_val = s.get_free()\n",
    "\n",
    "# Evidently the free params are in the columns and the vector params are in the rows.\n",
    "print(target_jac.shape)\n",
    "\n",
    "jac_time = time.time()\n",
    "target_jac = set_free_and_get_jacobian(s, free_val)\n",
    "jac_time = time.time() - jac_time\n",
    "print(jac_time)\n",
    "\n",
    "hess_time = time.time()\n",
    "target_hess = set_free_and_get_hessian(s, free_val)\n",
    "hess_time = time.time() - hess_time\n",
    "print(hess_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def constrain_simplex_vector(free_vec):\n",
    "    # The first column is the reference value.\n",
    "    free_vec_aug = np.hstack([[0.], free_vec])\n",
    "    log_norm = sp.misc.logsumexp(free_vec_aug)\n",
    "    return np.exp(free_vec_aug - log_norm)\n",
    "\n",
    "constrain_simplex_vector(free_vec)\n",
    "constrain_grad = autograd.jacobian(constrain_simplex_vector)\n",
    "constrain_hess = autograd.hessian(constrain_simplex_vector)\n",
    "\n",
    "constrain_grad(free_vec)\n",
    "constrain_hess(free_vec).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_jac_time = time.time()\n",
    "\n",
    "jac_rows = []\n",
    "jac_cols = []\n",
    "grads = []\n",
    "free_cols = range(s.free_shape()[1])\n",
    "vec_cols = range(s.shape()[1])\n",
    "for row in range(s.shape()[0]):\n",
    "    # Each of the output depends only on one row of the input.\n",
    "    free_inds = np.ravel_multi_index([[row], free_cols], s.free_shape())\n",
    "    vec_inds = np.ravel_multi_index([[row], vec_cols], s.shape())\n",
    "    row_jac = constrain_grad(free_val[free_inds])\n",
    "    for vec_col in vec_cols:\n",
    "        for free_col in free_cols: \n",
    "            jac_rows.append(vec_inds[vec_col])\n",
    "            jac_cols.append(free_inds[free_col])\n",
    "            grads.append(row_jac[vec_col,free_col])\n",
    "\n",
    "jac_sparse = csr_matrix((grads, (jac_rows, jac_cols)), (s.vector_size(), s.free_size()))\n",
    "print(np.max(np.abs(jac_sparse - target_jac)))\n",
    "\n",
    "sparse_jac_time = time.time() - sparse_jac_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_hess_time = time.time()\n",
    "\n",
    "free_cols = range(s.free_shape()[1])\n",
    "vec_cols = range(s.shape()[1])\n",
    "hesses = []\n",
    "hess_shape = (s.free_size(), s.free_size())\n",
    "\n",
    "for row in range(s.shape()[0]):\n",
    "    # Each of the output depends only on one row of the input.\n",
    "    free_inds = np.ravel_multi_index([[row], free_cols], s.free_shape())\n",
    "    vec_inds = np.ravel_multi_index([[row], vec_cols], s.shape())\n",
    "    row_hess = constrain_hess(free_val[free_inds])\n",
    "    #print(row_hess)\n",
    "    for vec_col in vec_cols:\n",
    "        vec_ind = vec_inds[vec_col]\n",
    "        hess_rows = []\n",
    "        hess_cols = []\n",
    "        hess_vals = []\n",
    "        for free_col1 in free_cols:\n",
    "            for free_col2 in free_cols:\n",
    "                hess_rows.append(free_inds[free_col1])\n",
    "                hess_cols.append(free_inds[free_col2])\n",
    "                hess_vals.append(row_hess[vec_col, free_col1, free_col2])\n",
    "        hesses.append(csr_matrix((hess_vals, (hess_rows, hess_cols)), hess_shape))\n",
    "\n",
    "        \n",
    "sparse_hess_time = time.time() - sparse_hess_time\n",
    "\n",
    "print(np.max(np.abs([ hesses[ind].toarray() - target_hess[ind] for ind in range(s.vector_size()) ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------')\n",
    "print(sparse_hess_time)\n",
    "print(hess_time)\n",
    "\n",
    "print('-----------')\n",
    "print(sparse_jac_time)\n",
    "print(jac_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
