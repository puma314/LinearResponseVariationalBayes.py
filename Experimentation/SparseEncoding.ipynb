{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "import autograd\n",
    "from autograd.core import primitive\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from VariationalBayes import Parameters\n",
    "from VariationalBayes.Parameters import \\\n",
    "    ScalarParam, VectorParam, ArrayParam, \\\n",
    "    PosDefMatrixParam, PosDefMatrixParamVector\n",
    "from VariationalBayes.ParameterDictionary import ModelParamsDict\n",
    "import scipy as osp\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelParamsDict:\n",
      "\tmat1:\n",
      "[[ 1.2  0.2]\n",
      " [ 0.2  1.2]]\n",
      "\tmat2:\n",
      "[[ 2.4  0.4]\n",
      " [ 0.4  2.4]]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "\n",
    "mat = np.full(k ** 2, 0.2).reshape(k, k) + np.eye(k)\n",
    "vp_mat1 = PosDefMatrixParam('mat1', k, val=mat)\n",
    "vp_mat2 = PosDefMatrixParam('mat2', k, val=mat * 2.)\n",
    "\n",
    "mp = ModelParamsDict()\n",
    "mp.push_param(vp_mat1)\n",
    "mp.push_param(vp_mat2)\n",
    "\n",
    "print(mp)\n",
    "\n",
    "free_vec = mp.get_free()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  0.2]\n",
      " [ 0.2  1.2]]\n",
      "[[ 2.4  0.4]\n",
      " [ 0.4  2.4]]\n",
      "--------\n",
      "[[[ 2.4         0.          0.          0.          0.          0.        ]\n",
      "  [ 0.2         1.09544512  0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.2         1.09544512  0.          0.          0.          0.        ]\n",
      "  [ 0.          0.36514837  2.33333333  0.          0.          0.        ]]]\n",
      "--------\n",
      "[[[ 0.          0.          0.          4.8         0.          0.        ]\n",
      "  [ 0.          0.          0.          0.4         1.54919334  0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.4         1.54919334  0.        ]\n",
      "  [ 0.          0.          0.          0.          0.51639778  4.66666667]]]\n"
     ]
    }
   ],
   "source": [
    "def get_param(mp, free_vec, par_name):\n",
    "    mp[par_name].set_free(free_vec[mp.free_indices_dict[par_name]])\n",
    "    return mp[par_name].get()\n",
    "\n",
    "print(get_param(mp, free_vec, 'mat1'))\n",
    "print(get_param(mp, free_vec, 'mat2'))\n",
    "\n",
    "get_param_jac = autograd.jacobian(get_param, argnum=1)\n",
    "\n",
    "print('--------')\n",
    "print(get_param_jac(mp, free_vec, 'mat1'))\n",
    "print('--------')\n",
    "print(get_param_jac(mp, free_vec, 'mat2'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  0.2]\n",
      " [ 0.2  1.2]]\n",
      "[[ 2.4  0.4]\n",
      " [ 0.4  2.4]]\n",
      "-----------------\n",
      "[[[ 2.4         0.          0.        ]\n",
      "  [ 0.2         1.09544512  0.        ]]\n",
      "\n",
      " [[ 0.2         1.09544512  0.        ]\n",
      "  [ 0.          0.36514837  2.33333333]]]\n",
      "-----------------\n",
      "[[[ 4.8         0.          0.        ]\n",
      "  [ 0.4         1.54919334  0.        ]]\n",
      "\n",
      " [[ 0.4         1.54919334  0.        ]\n",
      "  [ 0.          0.51639778  4.66666667]]]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "@primitive\n",
    "def get_param_sparse(mp, free_vec, par_name):\n",
    "    return get_param(mp, free_vec, par_name)\n",
    "\n",
    "def get_free_vec(mp, free_vec, par_name):\n",
    "    return free_vec[mp.free_indices_dict[par_name]]\n",
    "\n",
    "def set_free_and_get(free_vec_par, par):\n",
    "    par.set_free(free_vec_par)\n",
    "    return par.get()\n",
    "\n",
    "mat1_sub_vec = get_free_vec(mp, free_vec, 'mat1')\n",
    "mat2_sub_vec = get_free_vec(mp, free_vec, 'mat2')\n",
    "print(set_free_and_get(mat1_sub_vec, mp['mat1']))\n",
    "print(set_free_and_get(mat2_sub_vec, mp['mat2']))\n",
    "\n",
    "jac_dict = OrderedDict()\n",
    "jac_dict['mat1'] = autograd.jacobian(lambda free_sub_vec: set_free_and_get(free_sub_vec, mp['mat1']))\n",
    "jac_dict['mat2'] = autograd.jacobian(lambda free_sub_vec: set_free_and_get(free_sub_vec, mp['mat2']))\n",
    "\n",
    "print(\"-----------------\")\n",
    "print(jac_dict['mat1'](mat1_sub_vec))\n",
    "print(\"-----------------\")\n",
    "print(jac_dict['mat2'](mat2_sub_vec))\n",
    "print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "[ 0.93946763  0.91549415  1.01996112]\n",
      "[[ 0.47065522  0.83499778  0.58313265]\n",
      " [ 0.46881241  0.08049637  0.43682847]]\n",
      "[ 0.93946763  0.91549415  1.01996112]\n"
     ]
    }
   ],
   "source": [
    "foo = np.random.random((2, 2, 3))\n",
    "bar = np.random.random((2, 2))\n",
    "\n",
    "print((foo * np.expand_dims(bar, axis=2)).shape)\n",
    "print(np.sum(foo * np.expand_dims(bar, axis=2), (0, 1)))\n",
    "print(np.sum(foo * np.expand_dims(bar, axis=2), -2))\n",
    "print(np.sum([ foo[:, :, k] * bar for k in range(3) ], (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]]\n",
      "[[[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "def get_param_sparse_vjp(g, ans, vs, gvs, mp, free_vec, par_name):\n",
    "    jac = jac_dict[par_name](get_free_vec(mp, free_vec, par_name))\n",
    "    par_jac = np.sum(jac * np.expand_dims(g, axis=2), (0, 1))\n",
    "    full_jac = np.zeros(free_vec.shape)\n",
    "    inds = mp.free_indices_dict[par_name]\n",
    "    full_jac[inds] = par_jac\n",
    "    return full_jac\n",
    "\n",
    "    # Doesn't work:\n",
    "    #return csr_matrix((np.full(6, 0), (np.array(range(6)), np.full(6, 0))), (6, 1))\n",
    "    \n",
    "get_param_sparse.defvjp(get_param_sparse_vjp, argnum=1)\n",
    "\n",
    "get_param_sparse_jac = autograd.jacobian(get_param_sparse, argnum=1)\n",
    "print(get_param_sparse_jac(mp, free_vec, 'mat2') - get_param_jac(mp, free_vec, 'mat2'))\n",
    "print(get_param_sparse_jac(mp, free_vec, 'mat1') - get_param_jac(mp, free_vec, 'mat1'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 4.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 7.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1., 3., 4.]\n",
    "rows = [0, 2, 4]\n",
    "cols = [0, 0, 0]\n",
    "\n",
    "full_jac_sparse = csr_matrix((data, (rows, cols)), (5, 1))\n",
    "print(full_jac_sparse.toarray())\n",
    "\n",
    "\n",
    "# Are duplicates summed?  Yes.\n",
    "data = [1., 3., 4.]\n",
    "rows = [0, 2, 2]\n",
    "cols = [0, 0, 0]\n",
    "\n",
    "full_jac_sparse = csr_matrix((data, (rows, cols)), (5, 1))\n",
    "full_jac_sparse.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 6, 6)\n",
      "(2, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hessians get appended to the end\n",
    "get_param_hess = autograd.hessian(get_param, argnum=1)\n",
    "mat1_hess = get_param_hess(mp, free_vec, 'mat1')\n",
    "print(mat1_hess.shape)\n",
    "\n",
    "# As do Jacobians\n",
    "mat1_jac = get_param_jac(mp, free_vec, 'mat1')\n",
    "print(mat1_jac.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we need two steps.  Let $L$ be the objective and $f$ be the constraining function, so that \n",
    "\n",
    "$$\n",
    "\\theta = f(z) \\\\\n",
    "L(\\theta) = L(f(z))\n",
    "$$\n",
    "\n",
    "We need\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dz^T} = \\frac{dL}{d\\theta^T} \\frac{d\\theta}{dz} = \\frac{dL}{d\\theta^T} \\frac{df}{dz^T}\n",
    "$$\n",
    "\n",
    "and, using Einstein summation notation,\n",
    "\n",
    "$$\n",
    "\\frac{d^2 L}{dz_i dz_j} =\n",
    "    \\frac{d^2 L}{d\\theta_a d\\theta_b} \\frac{d\\theta_a}{dz_i} \\frac{d\\theta_b}{dz_j} +\n",
    "    \\frac{d L}{d\\theta_a} \\frac{d^2 \\theta_a}{dz_i dz_j}\n",
    "$$\n",
    "\n",
    "The term $\\frac{d^2 L}{d\\theta_a d\\theta_b}$ can be expressed using a combination of our ```get_vector()``` functions and a sparse matrix for the local variables.  $\\frac{d\\theta_a}{dz_i}$ can also be represented as a sparse matrix.  It may be best to store the term $\\frac{d^2 \\theta_a}{dz_i dz_j}$ in ```(value, a, i, j)``` format, and write a custom aggregator to return a sparse matrix when multiplied by $\\frac{d L}{d\\theta_a}$, since it is possible that this is not efficient in general [(discussion)](https://stackoverflow.com/questions/29871669/python-multi-dimensional-sparse-array).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_free_and_get(par, free_vec_par):\n",
    "    par.set_free(free_vec_par)\n",
    "    return par.get_vector()\n",
    "\n",
    "set_free_and_get_jacobian = autograd.jacobian(set_free_and_get, argnum=1)\n",
    "set_free_and_get_hessian = autograd.hessian(set_free_and_get, argnum=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# For an ArrayParam\n",
    "s = ArrayParam(name='scalar', shape=(5, 3), lb=0.0)\n",
    "s.set(np.exp(np.random.random(s.shape())))\n",
    "\n",
    "target_jac = set_free_and_get_jacobian(s, s.get_free())\n",
    "target_hess = set_free_and_get_hessian(s, s.get_free())\n",
    "\n",
    "# Pre-compute necessary stuff\n",
    "s.__lb = 0.0\n",
    "s.__ub = float('inf')\n",
    "constrain_grad = autograd.grad(Parameters.constrain)\n",
    "free_val = s.get_free()\n",
    "\n",
    "# Get a sparse version of the Jacobian\n",
    "rows = np.array(range(s.vector_size()))\n",
    "grads = [ constrain_grad(free_val[vec_ind], s.__lb, s.__ub) \\\n",
    "          for vec_ind in range(s.vector_size()) ]\n",
    "    \n",
    "jac_sparse = csr_matrix((grads, (rows, rows)), (s.vector_size(), s.free_size()))\n",
    "\n",
    "print(np.max(np.abs(jac_sparse - target_jac)))\n",
    "\n",
    "constrain_hess = autograd.hessian(Parameters.constrain)\n",
    "\n",
    "def get_ind_hess(vec_ind):\n",
    "    hess = constrain_hess(free_val[vec_ind], s.__lb, s.__ub)\n",
    "    return csr_matrix(([ hess ], ([vec_ind], [vec_ind])), (s.free_size(), s.vector_size()))\n",
    "\n",
    "# Get a sparse version of the Hessian\n",
    "hesses = np.array([ get_ind_hess(vec_ind)\n",
    "                    for vec_ind in range(s.vector_size()) ])\n",
    "\n",
    "print(np.max(np.abs([ hesses[ind].toarray() - target_hess[ind] for ind in range(s.vector_size()) ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n"
     ]
    }
   ],
   "source": [
    "# For a SimplexParam\n",
    "from VariationalBayes.MultinomialParams import SimplexParam\n",
    "s = SimplexParam(name='simplex', shape=(2, 3))\n",
    "s_val = np.random.random(s.shape())\n",
    "s_val = s_val / np.expand_dims(np.sum(s_val, 1), axis=1)\n",
    "s.set(s_val)\n",
    "\n",
    "free_val = s.get_free()\n",
    "\n",
    "target_jac = set_free_and_get_jacobian(s, free_val)\n",
    "target_hess = set_free_and_get_hessian(s, free_val)\n",
    "\n",
    "# Evidently the free params are in the columns and the vector params are in the rows.\n",
    "print(target_jac.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 6, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def constrain_simplex_vector(free_vec):\n",
    "    # The first column is the reference value.\n",
    "    free_vec_aug = np.hstack([[0.], free_vec])\n",
    "    log_norm = sp.misc.logsumexp(free_vec_aug)\n",
    "    return np.exp(free_vec_aug - log_norm)\n",
    "\n",
    "constrain_simplex_vector(free_vec)\n",
    "constrain_grad = autograd.jacobian(constrain_simplex_vector)\n",
    "constrain_grad(free_vec)\n",
    "constrain_hess = autograd.hessian(constrain_simplex_vector)\n",
    "constrain_hess(free_vec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jac_rows = []\n",
    "jac_cols = []\n",
    "grads = []\n",
    "free_cols = range(s.free_shape()[1])\n",
    "vec_cols = range(s.shape()[1])\n",
    "for row in range(s.shape()[0]):\n",
    "    # Each of the output depends only on one row of the input.\n",
    "    free_inds = np.ravel_multi_index([[row], free_cols], s.free_shape())\n",
    "    vec_inds = np.ravel_multi_index([[row], vec_cols], s.shape())\n",
    "    row_jac = constrain_grad(free_val[free_inds])\n",
    "    for vec_col in vec_cols:\n",
    "        for free_col in free_cols: \n",
    "            jac_rows.append(vec_inds[vec_col])\n",
    "            jac_cols.append(free_inds[free_col])\n",
    "            grads.append(row_jac[vec_col,free_col])\n",
    "            \n",
    "            \n",
    "jac_sparse = csr_matrix((grads, (jac_rows, jac_cols)), (s.vector_size(), s.free_size()))\n",
    "print(np.max(np.abs(jac_sparse - target_jac)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.03473296,  0.03607573,  0.        ,  0.        ],\n",
      "       [ 0.03607573, -0.02944033,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[ 0.06552671, -0.03079374,  0.        ,  0.        ],\n",
      "       [-0.03079374, -0.00528199,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[-0.03079374, -0.00528199,  0.        ,  0.        ],\n",
      "       [-0.00528199,  0.03472232,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.00331646,  0.03308621],\n",
      "       [ 0.        ,  0.        ,  0.03308621, -0.00730627]]), array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        , -0.01899114,  0.01567468],\n",
      "       [ 0.        ,  0.        ,  0.01567468, -0.04876089]]), array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.01567468, -0.04876089],\n",
      "       [ 0.        ,  0.        , -0.04876089,  0.05606716]])]\n",
      "[[[-0.03473296  0.03607573  0.          0.        ]\n",
      "  [ 0.03607573 -0.02944033  0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.06552671 -0.03079374  0.          0.        ]\n",
      "  [-0.03079374 -0.00528199  0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.03079374 -0.00528199  0.          0.        ]\n",
      "  [-0.00528199  0.03472232  0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.00331646  0.03308621]\n",
      "  [ 0.          0.          0.03308621 -0.00730627]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.         -0.01899114  0.01567468]\n",
      "  [ 0.          0.          0.01567468 -0.04876089]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.01567468 -0.04876089]\n",
      "  [ 0.          0.         -0.04876089  0.05606716]]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "free_cols = range(s.free_shape()[1])\n",
    "vec_cols = range(s.shape()[1])\n",
    "hesses = []\n",
    "hess_shape = (s.free_size(), s.free_size())\n",
    "\n",
    "for row in range(s.shape()[0]):\n",
    "    # Each of the output depends only on one row of the input.\n",
    "    free_inds = np.ravel_multi_index([[row], free_cols], s.free_shape())\n",
    "    vec_inds = np.ravel_multi_index([[row], vec_cols], s.shape())\n",
    "    row_hess = constrain_hess(free_val[free_inds])\n",
    "    #print(row_hess)\n",
    "    for vec_col in vec_cols:\n",
    "        vec_ind = vec_inds[vec_col]\n",
    "        hess_rows = []\n",
    "        hess_cols = []\n",
    "        hess_vals = []\n",
    "        for free_col1 in free_cols:\n",
    "            for free_col2 in free_cols:\n",
    "                hess_rows.append(free_inds[free_col1])\n",
    "                hess_cols.append(free_inds[free_col2])\n",
    "                hess_vals.append(row_hess[vec_col, free_col1, free_col2])\n",
    "        hesses.append(csr_matrix((hess_vals, (hess_rows, hess_cols)), hess_shape))\n",
    "\n",
    "print(np.max(np.abs([ hesses[ind].toarray() - target_hess[ind] for ind in range(s.vector_size()) ])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
