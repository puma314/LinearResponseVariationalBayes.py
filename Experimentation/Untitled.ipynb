{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import autograd\n",
    "from VariationalBayes import Modeling as modeling\n",
    "\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.42794278  2.31542069  2.63453555  2.3813179   2.86021061]\n",
      " [ 2.94272615  2.80561421  2.43277259  3.05773451  2.76670037]\n",
      " [ 2.22354862  2.86485362  2.59778288  2.59070149  2.28417594]]\n"
     ]
    }
   ],
   "source": [
    "def fun(z):\n",
    "    return np.log1p(np.exp(z))\n",
    "\n",
    "def fun_grad(z):\n",
    "    return np.exp(z) / (1 + np.exp(z))\n",
    "\n",
    "def fun_hess(z):\n",
    "    p = np.exp(z) / (1 + np.exp(z))\n",
    "    return p * (1 - p)\n",
    "\n",
    "def log_fun(z):\n",
    "    return np.log(fun(z))\n",
    "\n",
    "def log_fun_grad(z):\n",
    "    return 0. * fun(z)\n",
    "    return fun_grad(z) / fun(z)\n",
    "\n",
    "def log_fun_hess(z):\n",
    "    f_z = fun(z)\n",
    "    return 0. * f_z\n",
    "    return fun_hess(z) / f_z - (fun_grad(z) / f_z) ** 2\n",
    "\n",
    "std_draws = modeling.get_standard_draws(20)\n",
    "\n",
    "z_mean = np.random.random((3, 5)) + 2.0\n",
    "z_sd = np.exp(np.random.random((3, 5)) - 1.0)\n",
    "\n",
    "z0 = z_mean\n",
    "imp_means = modeling.importance_sampling_integrate_univariate_normal(\n",
    "    z_mean, z_sd, z0, log_fun, log_fun_grad, log_fun_hess, std_draws, aggregate_all=False)\n",
    "\n",
    "print(imp_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draws_axis = z_sd.ndim\n",
    "z_draws = \\\n",
    "    np.expand_dims(z_sd, axis=draws_axis) * std_draws + \\\n",
    "    np.expand_dims(z_mean, axis=draws_axis)\n",
    "\n",
    "# By dividing by the number of standard draws after summing,\n",
    "# we add the sample means for all the observations.\n",
    "# Note that\n",
    "# log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "logit_term = \\\n",
    "    np.sum(np.log1p(np.exp(z_draws))) / std_draws.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_draws_vec = [ 3, 5, 10, 30, 50, 100, 200, 500, 5000 ]\n",
    "\n",
    "imp_means = \\\n",
    "    [ modeling.importance_sampling_integrate_univariate_normal(\n",
    "      z_mean, z_sd, z0, log_fun, log_fun_grad, log_fun_hess,\n",
    "      modeling.get_standard_draws(num_std_draws), aggregate_all=True) \\\n",
    "      for num_std_draws in std_draws_vec ]\n",
    "    \n",
    "direct_means = \\\n",
    "    [ modeling.get_e_logistic_term_only(z_mean, z_sd, modeling.get_standard_draws(num_std_draws)) \\\n",
    "      for num_std_draws in std_draws_vec ]\n",
    "\n",
    "plt.plot(np.log10(std_draws_vec), direct_means, 'k.')\n",
    "plt.plot(np.log10(std_draws_vec), imp_means, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3092bd4278>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAEGgiSpMRAkSYCBIElqDARJEgD/BzIaOuTfYQ4kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3092b7d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.log10(std_draws_vec), direct_means, 'k.')\n",
    "plt.plot(np.log10(std_draws_vec), imp_means, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.93572958  0.7626296   1.15765484  1.04964799  0.84785575]\n",
      " [ 0.94445288  0.98396326  1.16130879  1.28169693  0.90664068]\n",
      " [ 0.92360028  1.30242094  1.31187953  0.87827439  1.27274373]]\n"
     ]
    }
   ],
   "source": [
    "from VariationalBayes.Modeling import univariate_normal_log_prob\n",
    "\n",
    "# q(u) will be a univariate normal importance sampling distribution.\n",
    "# Its natural parameters are given by a Taylor expansion of log_fun.\n",
    "z_info = 1 / z_sd ** 2\n",
    "\n",
    "z_nat_param = z_info * z_mean\n",
    "z2_nat_param = -0.5 * z_info\n",
    "\n",
    "u_nat_param = z_nat_param + log_fun_grad(z0)\n",
    "u2_nat_param = z2_nat_param + log_fun_hess(z0)\n",
    "\n",
    "u_info = -2 * u2_nat_param\n",
    "u_sd = 1. / np.sqrt(u_info)\n",
    "u_mean = u_nat_param / u_info\n",
    "\n",
    "# print('log fun --------')\n",
    "# print(log_fun_grad(z0))\n",
    "# print(log_fun_hess(z0))\n",
    "\n",
    "# print('z nat params --------')\n",
    "# print(z_nat_param)\n",
    "# print(z2_nat_param)\n",
    "\n",
    "# print('u nat parmas --------')\n",
    "# print(u_nat_param)\n",
    "# print(u2_nat_param)\n",
    "\n",
    "# print('u sd and mean --------')\n",
    "# print(u_sd)\n",
    "# print(u_mean)\n",
    "\n",
    "# print('z sd and mean --------')\n",
    "# print(z_sd)\n",
    "# print(z_mean)\n",
    "\n",
    "draws_axis = u_sd.ndim\n",
    "u_draws = \\\n",
    "    np.expand_dims(u_sd, axis=draws_axis) * std_draws + \\\n",
    "    np.expand_dims(u_mean, axis=draws_axis)\n",
    "\n",
    "u_log_prob = univariate_normal_log_prob(\n",
    "    u_draws,\n",
    "    np.expand_dims(u_mean, axis=draws_axis),\n",
    "    np.expand_dims(u_info, axis=draws_axis))\n",
    "z_log_prob = univariate_normal_log_prob(\n",
    "    u_draws,\n",
    "    np.expand_dims(z_mean, axis=draws_axis),\n",
    "    np.expand_dims(z_info, axis=draws_axis))\n",
    "log_f_z = log_fun(u_draws)\n",
    "\n",
    "# Importance sampling\n",
    "log_imp_weights = np.exp(z_log_prob + log_f_z - u_log_prob)\n",
    "\n",
    "result = np.sum(log_imp_weights, axis=draws_axis) / len(std_draws)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mu_prior_mean_c', 'beta_prior_var', 'NG', 'mu_prior_var', 'N', 'y_group', 'mu_prior_epsilon', 'x', 'tau_prior_alpha', 'K', 'tau_prior_beta', 'beta_prior_mean', 'mu_prior_var_c', 'y', 'mu_prior_mean', 'mu_prior_t'])\n"
     ]
    }
   ],
   "source": [
    "import VariationalBayes as vb\n",
    "import Models.LogisticGLMM_lib as logit_glmm\n",
    "from VariationalBayes.SparseObjectives import Objective, SparseObjective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from autograd import jacobian\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "analysis_name = 'criteo_subsampled'\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "json_file = open(json_filename, 'r')\n",
    "json_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "stan_dat = json_dat['stan_dat']\n",
    "vp_base = json_dat['vp_base']\n",
    "\n",
    "print(stan_dat.keys())\n",
    "K = stan_dat['K'][0]\n",
    "NObs = stan_dat['N'][0]\n",
    "NG = stan_dat['NG'][0]\n",
    "#N = NObs / NG\n",
    "y_g_vec = np.array(stan_dat['y_group'])\n",
    "y_vec = np.array(stan_dat['y'])\n",
    "x_mat = np.array(stan_dat['x'])\n",
    "\n",
    "mu_info_min = vp_base['mu_info_min'][0]\n",
    "tau_alpha_min = vp_base['tau_alpha_min'][0]\n",
    "tau_beta_min = vp_base['tau_beta_min'][0]\n",
    "beta_diag_min = vp_base['beta_diag_min'][0]\n",
    "u_info_min = vp_base['u_info_min'][0]\n",
    "\n",
    "# Define a class to contain prior parameters.\n",
    "prior_par = vb.ModelParamsDict('Prior Parameters')\n",
    "\n",
    "prior_par.push_param(vb.VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "beta_prior_info = np.linalg.inv(np.array(stan_dat['beta_prior_var']))\n",
    "prior_par.push_param(vb.PosDefMatrixParam('beta_prior_info', K, val=beta_prior_info))\n",
    "\n",
    "prior_par.push_param(vb.ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "prior_par.push_param(vb.ScalarParam('mu_prior_info', val=1 / stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "prior_par.push_param(vb.ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "prior_par.push_param(vb.ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "# An index set to make sure jacobians match the order expected by R.\n",
    "prior_par_indices = copy.deepcopy(prior_par)\n",
    "prior_par_indices.set_name('Prior Indices')\n",
    "prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "\n",
    "glmm_fit = json_dat['glmm_fit']\n",
    "glmm_par['mu'].mean.set(glmm_fit['mu_mean'][0])\n",
    "glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "tau_mean = 1.0 / glmm_fit['mu_sd'][0] ** 2\n",
    "tau_var = 1.0\n",
    "glmm_par['tau'].shape.set((tau_mean ** 2) / tau_var)\n",
    "glmm_par['tau'].rate.set(tau_var / tau_mean)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.array(glmm_fit['beta_mean']))\n",
    "glmm_par['beta'].info.set(np.eye(K))\n",
    "\n",
    "glmm_par['u'].mean.set(np.array(glmm_fit['u_map']))\n",
    "glmm_par['u'].info.set(np.full(NG, 1.0))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmm_par = vb.ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "# print(vp_base)\n",
    "\n",
    "glmm_par.push_param(\n",
    "    vb.UVNParam('mu', min_info=mu_info_min))\n",
    "glmm_par.push_param(\n",
    "    vb.GammaParam('tau', min_shape=tau_alpha_min, min_rate=tau_beta_min))\n",
    "glmm_par.push_param(vb.MVNParam('beta', K, min_info=beta_diag_min))\n",
    "glmm_par.push_param(vb.UVNParamVector('u', NG, min_info=u_info_min))\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "objective = Objective(model.glmm_par, model.get_kl)\n",
    "objective.fun_free(free_par_vec)\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "def tr_optimize(trust_init, num_draws, maxiter=500):\n",
    "    model.set_draws(num_draws)\n",
    "    objective.logger.initialize()\n",
    "    objective.logger.print_every = 5\n",
    "    vb_opt = optimize.minimize(\n",
    "        lambda par: objective.fun_free(par, verbose=True),\n",
    "        x0=trust_init,\n",
    "        method='trust-ncg',\n",
    "        jac=objective.fun_free_grad,\n",
    "        hessp=objective.fun_free_hvp,\n",
    "        tol=1e-6, options={'maxiter': maxiter, 'disp': True, 'gtol': 1e-6 })\n",
    "    return vb_opt.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_beta = glmm_par_opt['beta'].e()\n",
    "e_u = glmm_par_opt['u'].e()[model.y_g_vec]\n",
    "cov_beta = glmm_par['beta'].cov()\n",
    "var_u = glmm_par['u'].var()\n",
    "\n",
    "\n",
    "z_mean = e_u[y_g_vec] + np.matmul(x_mat, e_beta)\n",
    "z_sd = np.sqrt(\n",
    "    var_u[y_g_vec] + np.einsum('nk,kj,nj->n',\n",
    "                      x_mat, cov_beta, x_mat))\n",
    "\n",
    "std_draws_vec = [ 3, 5, 10, 30, 50, 100, 200, 500, 5000 ]\n",
    "\n",
    "z0 = z_mean\n",
    "print('Importance sampling')\n",
    "imp_means = \\\n",
    "    [ modeling.importance_sampling_integrate_univariate_normal(\n",
    "      z_mean, z_sd, z0, log_fun, log_fun_grad, log_fun_hess,\n",
    "      modeling.get_standard_draws(num_std_draws), aggregate_all=True) \\\n",
    "      for num_std_draws in std_draws_vec ]\n",
    "    \n",
    "print('Direct sampling')\n",
    "direct_means = \\\n",
    "    [ modeling.get_e_logistic_term_only(z_mean, z_sd, modeling.get_standard_draws(num_std_draws)) \\\n",
    "      for num_std_draws in std_draws_vec ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13014,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f30927dd828>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f309270e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(z_mean.shape)\n",
    "\n",
    "plt.plot(np.log10(std_draws_vec), direct_means, 'k.')\n",
    "plt.plot(np.log10(std_draws_vec), imp_means, 'r.')\n",
    "plt.plot(0, 0, 'r.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
