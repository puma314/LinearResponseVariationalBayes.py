{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "\n",
    "import VariationalBayes as vb\n",
    "from  VariationalBayes import ExponentialFamilies as ef\n",
    "from  VariationalBayes.SparseObjectives import Objective\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6173231176357886\n",
      "2.00000007679\n",
      "[ 0.32349837  0.43133117  0.53916388  0.64699655]\n",
      "[ 1.00000008]\n",
      "Beta norm:  2.00000007679  lambda:  0.0\n"
     ]
    }
   ],
   "source": [
    "params = vb.ModelParamsDict('par')\n",
    "params.push_param(vb.VectorParam('beta', size=4))\n",
    "\n",
    "params['beta'].set(np.random.random(params['beta'].size()))\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.data = np.linspace(1, 2, self.params['beta'].size())\n",
    "        self.data = self.data / np.linalg.norm(self.data)\n",
    "        self.lam = np.array(0.)\n",
    "        self.mu = np.array(1.)\n",
    "        self.objective = Objective(self.params, self.get_objective)\n",
    "        self.constraint = Objective(self.params, self.get_constraint_vec)\n",
    "\n",
    "    def log_lik(self):\n",
    "        normalize = False\n",
    "        beta = self.params['beta'].get()\n",
    "        if normalize:\n",
    "            beta /= np.linalg.norm(beta)\n",
    "\n",
    "        return -1 * np.dot(beta, self.data)\n",
    "    \n",
    "    def get_beta_norm(self):\n",
    "        return np.linalg.norm(self.params['beta'].get())\n",
    "    \n",
    "    def get_constraint_vec(self):\n",
    "        return np.array([ self.get_beta_norm() - 1])\n",
    "    \n",
    "    def dual_term(self):\n",
    "        return -1 * np.dot(self.lam, self.get_constraint_vec())\n",
    "    \n",
    "    def constraint_term(self):\n",
    "        return 0.5 * np.dot(self.mu, self.get_constraint_vec() ** 2)\n",
    "        \n",
    "    def get_objective(self):\n",
    "        return np.squeeze(self.log_lik() + self.constraint_term() + self.dual_term())\n",
    "    \n",
    "    def optimize(self, x0=None, maxiter=100, print_every=1, verbose=False):\n",
    "        self.objective.logger.print_every = print_every\n",
    "        self.objective.logger.initialize()\n",
    "        if x0 is None:\n",
    "            x0 = self.params.get_free()\n",
    "        \n",
    "        vb_opt = optimize.minimize(\n",
    "            lambda par: self.objective.fun_free(par, verbose=verbose),\n",
    "            x0 = x0,\n",
    "            jac = self.objective.fun_free_grad,\n",
    "            hessp = self.objective.fun_free_hvp,\n",
    "            method = 'trust-ncg',\n",
    "            options = {'maxiter': maxiter, 'gtol': 1e-6, 'disp': verbose})\n",
    "        self.params.set_free(vb_opt.x)\n",
    "        return vb_opt\n",
    "\n",
    "    def update_lambda(self):\n",
    "        new_lam = self.lam - self.get_constraint_vec() * self.mu#\n",
    "        self.lam = new_lam\n",
    "        print('Beta norm: ', self.get_beta_norm(),\n",
    "              ' lambda: ', self.lam,\n",
    "              ' constraint: ', self.get_constraint_vec())\n",
    "\n",
    "\n",
    "model = Model(params)\n",
    "print(model.get_objective())\n",
    "vb_opt = model.optimize()\n",
    "\n",
    "print(model.get_beta_norm())\n",
    "print(model.constraint.fun_free_grad(vb_opt.x))\n",
    "print(model.get_constraint_vec() * model.mu)\n",
    "print('Beta norm: ', model.get_beta_norm(), ' lambda: ', model.lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.44590100823381096)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mu = 2.0\n",
    "model.lam = 0.0\n",
    "model.params['beta'].set(np.full(model.params['beta'].size(), 0.1))\n",
    "model.get_objective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta norm:  0.999999999847  lambda:  [-1.]  constraint:  [ -1.52752144e-10]\n",
      "[ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "model.optimize()\n",
    "model.update_lambda()\n",
    "print(model.params['beta'].get() / model.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
