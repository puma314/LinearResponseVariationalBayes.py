{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd.core import primitive\n",
    "from autograd import grad, jacobian, hessian\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[3, 4, 5]\n",
      "[[ 0.1]\n",
      " [ 0.2]\n",
      " [ 0.5]]\n",
      "[[ 1.01  0.02  0.05]\n",
      " [ 0.02  1.04  0.1 ]\n",
      " [ 0.05  0.1   1.25]]\n",
      "[ 0.1   0.2   0.5   1.01  0.02  0.05  0.02  1.04  0.1   0.05  0.1   1.25]\n"
     ]
    }
   ],
   "source": [
    "foo = [1, 2, 3, 4, 5]\n",
    "print foo[0:2]\n",
    "print foo[2:5]\n",
    "\n",
    "x = np.matrix([1., 3., 4.]).T\n",
    "x_info = np.outer(0.1 * x, x) + np.eye(3)\n",
    "mu = np.matrix([0.1, 0.2, 0.5]).T\n",
    "mu_cov = np.matrix(np.outer(mu, mu) + np.eye(3))\n",
    "print mu\n",
    "print mu_cov\n",
    "print np.concatenate((mu.A1, mu_cov.A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.,   6.,  10.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1., 3., 5.])\n",
    "\n",
    "def Mag(x):\n",
    "    return np.dot(x.T, x)\n",
    "\n",
    "MagGrad = grad(Mag)\n",
    "MagGrad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.891\n",
      "5.891\n",
      "[  3.23   9.79  12.82]\n",
      "[  3.23   9.79  12.82]\n",
      "[[-0.55 -0.15 -0.2 ]\n",
      " [-0.15 -0.95 -0.6 ]\n",
      " [-0.2  -0.6  -1.3 ]]\n",
      "[[-0.55 -0.15 -0.2 ]\n",
      " [-0.15 -0.95 -0.6 ]\n",
      " [-0.2  -0.6  -1.3 ]]\n",
      "[[-1.1 -0.3 -0.4]\n",
      " [-0.3 -1.9 -1.2]\n",
      " [-0.4 -1.2 -2.6]]\n",
      "[[[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "def LogLikelihood(x_row, x_info, e_mu, e_mu_cov):\n",
    "    # TODO: if you're not using autodiff you can just do the matrix multiply once.\n",
    "    retval =  0.5 * (np.dot(e_mu.T, np.matmul(x_info, x_row)) + \\\n",
    "                     np.dot(x_row.T, np.matmul(x_info, e_mu)) - \\\n",
    "                     np.dot(e_mu.T, np.matmul(x_info, e_mu)) - \\\n",
    "                     np.trace(np.matmul(x_info, e_mu_cov)))\n",
    "    return retval\n",
    "\n",
    "@primitive\n",
    "def LogLikelihoodAD(x_row, x_info, e_mu, e_mu_cov):\n",
    "    return LogLikelihood(x_row, x_info, e_mu, e_mu_cov)\n",
    "\n",
    "def LogLikelihoodGrad_e_mu(x_row, x_info, e_mu):\n",
    "    return np.matmul(x_info, x_row - e_mu)\n",
    "\n",
    "def LogLikelihoodGrad_e_mu_cov(x_info):\n",
    "    return -0.5 * x_info\n",
    "\n",
    "def LogLikelihoodAD_e_mu_vjp(g, ans, vs, gvs, x_row, x_info, e_mu, e_mu_cov):\n",
    "    return g * LogLikelihoodGrad_e_mu(x_row, x_info, e_mu)\n",
    "\n",
    "def LogLikelihoodAD_e_mu_cov_vjp(g, ans, vs, gvs, x_row, x_info, e_mu, e_mu_cov):\n",
    "    return g * LogLikelihoodGrad_e_mu_cov(x_info)\n",
    "\n",
    "\n",
    "LogLikelihoodAD.defvjp(LogLikelihoodAD_e_mu_vjp, argnum=2)\n",
    "LogLikelihoodAD.defvjp(LogLikelihoodAD_e_mu_cov_vjp, argnum=3)\n",
    "\n",
    "print LogLikelihood(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodAD(x, x_info, mu, mu_cov)\n",
    "\n",
    "x = np.array([1., 3., 4.])\n",
    "x_info = np.outer(0.1 * x, x) + np.eye(3)\n",
    "mu = np.array([0.1, 0.2, 0.5])\n",
    "mu_cov = np.array(np.outer(mu, mu) + np.eye(3))\n",
    "\n",
    "LogLikelihoodADGrad2 = grad(LogLikelihoodAD, argnum=2)\n",
    "LogLikelihoodADGrad3 = grad(LogLikelihoodAD, argnum=3)\n",
    "LogLikelihoodGrad2 = grad(LogLikelihood, argnum=2)\n",
    "LogLikelihoodGrad3 = grad(LogLikelihood, argnum=3)\n",
    "\n",
    "print LogLikelihoodADGrad2(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodGrad2(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodADGrad3(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodGrad3(x, x_info, mu, mu_cov)\n",
    "\n",
    "LogLikelihoodHess2 = hessian(LogLikelihood, argnum=2)\n",
    "print LogLikelihoodHess2(x, x_info, mu, mu_cov)\n",
    "\n",
    "LogLikelihoodHess3 = hessian(LogLikelihood, argnum=3)\n",
    "print LogLikelihoodHess3(x, x_info, mu, mu_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.72\n",
      "6.629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array([1., 3., 4.])\n",
    "x_info = np.outer(0.1 * x, x) + np.eye(3)\n",
    "mu = np.array([0.1, 0.2, 0.5]).T\n",
    "mu_cov = np.array(np.outer(mu, mu) + np.eye(3))\n",
    "\n",
    "print np.dot(x.T, np.matmul(x_info, mu))\n",
    "print np.trace(np.matmul(x_info, mu_cov))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.,  12.,   6.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It can handle matrices, but not matrix return types.\n",
    "def MyFun(x):\n",
    "    x_mat = np.matrix(x).T\n",
    "    return 3 * np.dot(x_mat.T, x_mat)[0,0]\n",
    "\n",
    "x = np.array([3., 2., 1.])\n",
    "x_mat = np.matrix(x).T\n",
    "print 3 * np.ravel(np.dot(x_mat.T, x_mat))\n",
    "MyFunGrad = grad(MyFun)\n",
    "MyFunGrad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  2.  8.  7.]\n",
      "(2,)\n",
      "(2,)\n",
      "(2,)\n",
      "(2,)\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [ -5.42101086e-20   0.00000000e+00  -1.08420217e-19   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [ -1.08420217e-19   0.00000000e+00  -2.16840434e-19   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def Wrapper(vec, beta):\n",
    "    return(MyTwoArgFun(vec[0:2], vec[2:4], beta))\n",
    "\n",
    "def WrapperRaw(vec, beta):\n",
    "    return(MyTwoArgFunRaw(vec[0:2], vec[2:4], beta))\n",
    "\n",
    "def MyTwoArgFunRaw(x, y, beta):\n",
    "    return np.exp(0.1 * np.dot(beta.T, x) + 0.2 * np.dot(beta.T, y))\n",
    "\n",
    "@primitive\n",
    "def MyTwoArgFun(x, y, beta):\n",
    "    return MyTwoArgFunRaw(x, y, beta)\n",
    "\n",
    "@primitive\n",
    "def MyTwoArgFunGrad_x(x, y, beta):\n",
    "    return MyTwoArgFun(x, y, beta) * 0.1 * beta\n",
    "\n",
    "@primitive\n",
    "def MyTwoArgFunGrad_y(x, y, beta):\n",
    "    return MyTwoArgFun(x, y, beta) * 0.2 * beta\n",
    "\n",
    "def MyTwoArgFun_x_vjp(g, ans, vs, gvs, x, y, beta):\n",
    "    return g * MyTwoArgFunGrad_x(x, y, beta)\n",
    "\n",
    "def MyTwoArgFun_y_vjp(g, ans, vs, gvs, x, y, beta):\n",
    "    return g * MyTwoArgFunGrad_y(x, y, beta)\n",
    "\n",
    "MyTwoArgFun.defvjp(MyTwoArgFun_x_vjp, argnum=0)\n",
    "MyTwoArgFun.defvjp(MyTwoArgFun_y_vjp, argnum=1)\n",
    "\n",
    "def MyTwoArgFunHess_x_x(x, y, beta):\n",
    "    return MyTwoArgFun(x, y, beta) * 0.1 * 0.1 * np.outer(beta, beta)\n",
    "\n",
    "def MyTwoArgFunHess_x_y(x, y, beta):\n",
    "    return MyTwoArgFun(x, y, beta) * 0.1 * 0.2 * np.outer(beta, beta)\n",
    "\n",
    "def MyTwoArgFunHess_y_x(x, y, beta):\n",
    "    return MyTwoArgFunHess_x_y(x, y, beta).T\n",
    "\n",
    "def MyTwoArgFunHess_y_y(x, y, beta):\n",
    "    return MyTwoArgFun(x, y, beta) * 0.2 * 0.2 * np.outer(beta, beta)\n",
    "\n",
    "def MyTwoArgFunGrad_x_x_vjp(g, ans, vs, gvs, x, y, beta):\n",
    "    print g.shape\n",
    "    return np.matmul(MyTwoArgFunHess_x_x(x, y, beta), g)\n",
    "\n",
    "def MyTwoArgFunGrad_x_y_vjp(g, ans, vs, gvs, x, y, beta):\n",
    "    return np.matmul(MyTwoArgFunHess_x_y(x, y, beta), g)\n",
    "\n",
    "def MyTwoArgFunGrad_y_y_vjp(g, ans, vs, gvs, x, y, beta):\n",
    "    return np.matmul(MyTwoArgFunHess_y_y(x, y, beta), g)\n",
    "\n",
    "def MyTwoArgFunGrad_y_x_vjp(g, ans, vs, gvs, x, y, beta):\n",
    "    return np.matmul(MyTwoArgFunHess_y_x(x, y, beta), g)\n",
    "\n",
    "MyTwoArgFunGrad_x.defvjp(MyTwoArgFunGrad_x_x_vjp, argnum=0)\n",
    "MyTwoArgFunGrad_x.defvjp(MyTwoArgFunGrad_x_y_vjp, argnum=1)\n",
    "MyTwoArgFunGrad_y.defvjp(MyTwoArgFunGrad_y_x_vjp, argnum=0)\n",
    "MyTwoArgFunGrad_y.defvjp(MyTwoArgFunGrad_y_y_vjp, argnum=1)\n",
    "\n",
    "\n",
    "x = np.array([3., 2. ])\n",
    "y = x + 5.\n",
    "beta = np.array([1.1, 2.4]) * 0.1\n",
    "print np.concatenate((x, y))\n",
    "\n",
    "WrapperHess = hessian(Wrapper)\n",
    "WrapperRawHess = hessian(WrapperRaw)\n",
    "print WrapperHess(np.concatenate((x, y)), beta) - WrapperRawHess(np.concatenate((x, y)), beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11  0.24]\n",
      "[ 0.11  0.24]\n",
      "[[ 0.0121  0.0264]\n",
      " [ 0.0264  0.0576]]\n",
      "[[ 0.0121  0.0264]\n",
      " [ 0.0264  0.0576]]\n",
      "0.0697\n",
      "0.0697\n",
      "0.0697\n"
     ]
    }
   ],
   "source": [
    "print beta\n",
    "print beta.T\n",
    "print np.outer(beta, beta.T)\n",
    "print np.outer(beta, beta)\n",
    "print np.dot(beta, beta) # WTF\n",
    "print np.dot(beta, beta.T) # WTF\n",
    "print sum(beta * beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
