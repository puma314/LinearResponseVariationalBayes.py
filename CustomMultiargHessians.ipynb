{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd.core import primitive\n",
    "from autograd import grad, jacobian, hessian\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[3, 4, 5]\n",
      "[[ 0.1]\n",
      " [ 0.2]\n",
      " [ 0.5]]\n",
      "[[ 1.01  0.02  0.05]\n",
      " [ 0.02  1.04  0.1 ]\n",
      " [ 0.05  0.1   1.25]]\n",
      "[ 0.1   0.2   0.5   1.01  0.02  0.05  0.02  1.04  0.1   0.05  0.1   1.25]\n"
     ]
    }
   ],
   "source": [
    "foo = [1, 2, 3, 4, 5]\n",
    "print foo[0:2]\n",
    "print foo[2:5]\n",
    "\n",
    "x = np.matrix([1., 3., 4.]).T\n",
    "x_info = np.outer(0.1 * x, x) + np.eye(3)\n",
    "mu = np.matrix([0.1, 0.2, 0.5]).T\n",
    "mu_cov = np.matrix(np.outer(mu, mu) + np.eye(3))\n",
    "print mu\n",
    "print mu_cov\n",
    "print np.concatenate((mu.A1, mu_cov.A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.,   6.,  10.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1., 3., 5.])\n",
    "\n",
    "def Mag(x):\n",
    "    return np.dot(x.T, x)\n",
    "\n",
    "MagGrad = grad(Mag)\n",
    "MagGrad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.891\n",
      "5.891\n",
      "[  3.23   9.79  12.82]\n",
      "[  3.23   9.79  12.82]\n",
      "[[-0.55 -0.15 -0.2 ]\n",
      " [-0.15 -0.95 -0.6 ]\n",
      " [-0.2  -0.6  -1.3 ]]\n",
      "[[-0.55 -0.15 -0.2 ]\n",
      " [-0.15 -0.95 -0.6 ]\n",
      " [-0.2  -0.6  -1.3 ]]\n",
      "[[-1.1 -0.3 -0.4]\n",
      " [-0.3 -1.9 -1.2]\n",
      " [-0.4 -1.2 -2.6]]\n",
      "[[[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "def LogLikelihood(x_row, x_info, e_mu, e_mu_cov):\n",
    "    # TODO: if you're not using autodiff you can just do the matrix multiply once.\n",
    "    retval =  0.5 * (np.dot(e_mu.T, np.matmul(x_info, x_row)) + \\\n",
    "                     np.dot(x_row.T, np.matmul(x_info, e_mu)) - \\\n",
    "                     np.dot(e_mu.T, np.matmul(x_info, e_mu)) - \\\n",
    "                     np.trace(np.matmul(x_info, e_mu_cov)))\n",
    "    return retval\n",
    "\n",
    "@primitive\n",
    "def LogLikelihoodAD(x_row, x_info, e_mu, e_mu_cov):\n",
    "    return LogLikelihood(x_row, x_info, e_mu, e_mu_cov)\n",
    "\n",
    "def LogLikelihoodGrad_e_mu(x_row, x_info, e_mu):\n",
    "    return np.matmul(x_info, x_row - e_mu)\n",
    "\n",
    "def LogLikelihoodGrad_e_mu_cov(x_info):\n",
    "    return -0.5 * x_info\n",
    "\n",
    "def LogLikelihoodAD_e_mu_vjp(g, ans, vs, gvs, x_row, x_info, e_mu, e_mu_cov):\n",
    "    return g * LogLikelihoodGrad_e_mu(x_row, x_info, e_mu)\n",
    "\n",
    "def LogLikelihoodAD_e_mu_cov_vjp(g, ans, vs, gvs, x_row, x_info, e_mu, e_mu_cov):\n",
    "    return g * LogLikelihoodGrad_e_mu_cov(x_info)\n",
    "\n",
    "\n",
    "LogLikelihoodAD.defvjp(LogLikelihoodAD_e_mu_vjp, argnum=2)\n",
    "LogLikelihoodAD.defvjp(LogLikelihoodAD_e_mu_cov_vjp, argnum=3)\n",
    "\n",
    "print LogLikelihood(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodAD(x, x_info, mu, mu_cov)\n",
    "\n",
    "x = np.array([1., 3., 4.])\n",
    "x_info = np.outer(0.1 * x, x) + np.eye(3)\n",
    "mu = np.array([0.1, 0.2, 0.5])\n",
    "mu_cov = np.array(np.outer(mu, mu) + np.eye(3))\n",
    "\n",
    "LogLikelihoodADGrad2 = grad(LogLikelihoodAD, argnum=2)\n",
    "LogLikelihoodADGrad3 = grad(LogLikelihoodAD, argnum=3)\n",
    "LogLikelihoodGrad2 = grad(LogLikelihood, argnum=2)\n",
    "LogLikelihoodGrad3 = grad(LogLikelihood, argnum=3)\n",
    "\n",
    "print LogLikelihoodADGrad2(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodGrad2(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodADGrad3(x, x_info, mu, mu_cov)\n",
    "print LogLikelihoodGrad3(x, x_info, mu, mu_cov)\n",
    "\n",
    "LogLikelihoodHess2 = hessian(LogLikelihood, argnum=2)\n",
    "print LogLikelihoodHess2(x, x_info, mu, mu_cov)\n",
    "\n",
    "LogLikelihoodHess3 = hessian(LogLikelihood, argnum=3)\n",
    "print LogLikelihoodHess3(x, x_info, mu, mu_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.72\n",
      "6.629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array([1., 3., 4.])\n",
    "x_info = np.outer(0.1 * x, x) + np.eye(3)\n",
    "mu = np.array([0.1, 0.2, 0.5]).T\n",
    "mu_cov = np.array(np.outer(mu, mu) + np.eye(3))\n",
    "\n",
    "print np.dot(x.T, np.matmul(x_info, mu))\n",
    "print np.trace(np.matmul(x_info, mu_cov))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.,  12.,   6.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It can handle matrices, but not matrix return types.\n",
    "def MyFun(x):\n",
    "    x_mat = np.matrix(x).T\n",
    "    return 3 * np.dot(x_mat.T, x_mat)[0,0]\n",
    "\n",
    "x = np.array([3., 2., 1.])\n",
    "x_mat = np.matrix(x).T\n",
    "print 3 * np.ravel(np.dot(x_mat.T, x_mat))\n",
    "MyFunGrad = grad(MyFun)\n",
    "MyFunGrad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  2.  8.  7.]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [ -3.46944695e-18   7.95100320e-02   0.00000000e+00  -3.46944695e-18]\n",
      " [ -7.95100320e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def Wrapper(vec, betax, betay):\n",
    "    return(MyTwoArgFun(vec[0:2], vec[2:4], betax, betay))\n",
    "\n",
    "def WrapperRaw(vec, betax, betay):\n",
    "    return(MyTwoArgFunRaw(vec[0:2], vec[2:4], betax, betay))\n",
    "\n",
    "def MyTwoArgFunRaw(x, y, betax, betay):\n",
    "    return np.exp(np.dot(betax, x) + np.dot(betay, y))\n",
    "\n",
    "@primitive\n",
    "def MyTwoArgFun(x, y, betax, betay):\n",
    "    return MyTwoArgFunRaw(x, y, betax, betay)\n",
    "\n",
    "@primitive\n",
    "def MyTwoArgFunGrad_x(x, y, betax, betay):\n",
    "    return MyTwoArgFun(x, y, betax, betay) * betax\n",
    "\n",
    "@primitive\n",
    "def MyTwoArgFunGrad_y(x, y, betax, betay):\n",
    "    return MyTwoArgFun(x, y, betax, betay) *  betay\n",
    "\n",
    "def MyTwoArgFun_x_vjp(g, ans, vs, gvs, x, y, betax, betay):\n",
    "    return g * MyTwoArgFunGrad_x(x, y, betax, betay)\n",
    "MyTwoArgFun.defvjp(MyTwoArgFun_x_vjp, argnum=0)\n",
    "\n",
    "def MyTwoArgFun_y_vjp(g, ans, vs, gvs, x, y, betax, betay):\n",
    "    return g * MyTwoArgFunGrad_y(x, y, betax, betay)\n",
    "MyTwoArgFun.defvjp(MyTwoArgFun_y_vjp, argnum=1)\n",
    "\n",
    "# Terms of the Hessian\n",
    "def MyTwoArgFunHess_x_x(x, y, betax, betay):\n",
    "    return MyTwoArgFun(x, y, betax, betay) * np.outer(betax, betax)\n",
    "\n",
    "def MyTwoArgFunHess_x_y(x, y, betax, betay):\n",
    "    return MyTwoArgFun(x, y, betax, betay) * np.outer(betax, betay)\n",
    "\n",
    "def MyTwoArgFunHess_y_x(x, y, betax, betay):\n",
    "    return MyTwoArgFunHess_x_y(x, y, betax, betay).T\n",
    "\n",
    "def MyTwoArgFunHess_y_y(x, y, betax, betay):\n",
    "    return MyTwoArgFun(x, y, betax, betay) * np.outer(betay, betay)\n",
    "\n",
    "def MyTwoArgFunGrad_x_x_vjp(g, ans, vs, gvs, x, y, betax, betay):\n",
    "    return np.matmul(MyTwoArgFunHess_x_x(x, y, betax, betay), g)\n",
    "MyTwoArgFunGrad_x.defvjp(MyTwoArgFunGrad_x_x_vjp, argnum=0)\n",
    "\n",
    "# This returns a derivative with respect to y, given a derivative\n",
    "# with respect to MyTwoArgFunGrad_x, which explains the use of hess_y_x.\n",
    "def MyTwoArgFunGrad_x_y_vjp(g, ans, vs, gvs, x, y, betax, betay):\n",
    "    return np.matmul(MyTwoArgFunHess_y_x(x, y, betax, betay), g)\n",
    "MyTwoArgFunGrad_x.defvjp(MyTwoArgFunGrad_x_y_vjp, argnum=1)\n",
    "\n",
    "def MyTwoArgFunGrad_y_y_vjp(g, ans, vs, gvs, x, y, betax, betay):\n",
    "    return np.matmul(MyTwoArgFunHess_y_y(x, y, betax, betay), g)\n",
    "MyTwoArgFunGrad_y.defvjp(MyTwoArgFunGrad_y_x_vjp, argnum=0)\n",
    "\n",
    "# This returns a derivative with respect to y, given a derivative\n",
    "# with respect to MyTwoArgFunGrad_y, which explains the use of hess_x_y.\n",
    "def MyTwoArgFunGrad_y_x_vjp(g, ans, vs, gvs, x, y, betax, betay):\n",
    "    return np.matmul(MyTwoArgFunHess_x_y(x, y, betax, betay), g)\n",
    "MyTwoArgFunGrad_y.defvjp(MyTwoArgFunGrad_y_y_vjp, argnum=1)\n",
    "\n",
    "\n",
    "x = np.array([3., 2. ])\n",
    "y = x + 5.\n",
    "betax = np.array([1.1, 2.4]) * 0.1\n",
    "betay = np.array([-0.7, 0.6]) * 0.2\n",
    "print np.concatenate((x, y))\n",
    "\n",
    "WrapperHess = hessian(Wrapper)\n",
    "WrapperRawHess = hessian(WrapperRaw)\n",
    "print WrapperHess(np.concatenate((x, y)), betax, betay) - WrapperRawHess(np.concatenate((x, y)), betax, betay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11  0.24]\n",
      "[ 0.11  0.24]\n",
      "[[ 0.0121  0.0264]\n",
      " [ 0.0264  0.0576]]\n",
      "[[ 0.0121  0.0264]\n",
      " [ 0.0264  0.0576]]\n",
      "0.0697\n",
      "0.0697\n",
      "0.0697\n",
      "[[1 1]\n",
      " [2 2]]\n",
      "(3, 3)\n",
      "(3,)\n",
      "(9, 3)\n",
      "(3, 9)\n"
     ]
    }
   ],
   "source": [
    "print beta\n",
    "print beta.T\n",
    "print np.outer(beta, beta.T)\n",
    "print np.outer(beta, beta)\n",
    "print np.dot(beta, beta) # WTF\n",
    "print np.dot(beta, beta.T) # WTF\n",
    "print sum(beta * beta)\n",
    "print np.outer(np.array([1, 2]), np.array([1, 1]))\n",
    "\n",
    "foo = np.random.rand(9).reshape(3, 3)\n",
    "bar = np.random.rand(3)\n",
    "print foo.shape\n",
    "print bar.shape\n",
    "print np.outer(foo, bar).shape\n",
    "print np.outer(bar, foo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n",
      "[[[ 0.07231331  0.05633414  0.72212465]\n",
      "  [ 0.68453149  0.80449399  0.80044326]]\n",
      "\n",
      " [[ 0.06477375  0.5687207   0.64336569]\n",
      "  [ 0.32819827  0.25632403  0.8521798 ]]]\n"
     ]
    }
   ],
   "source": [
    "def ArrayFunAD(x, b11, b12, b21, b22):\n",
    "    return np.array([[np.dot(b11, x), np.dot(b12, x)], [np.dot(b21, x), np.dot(b22, x)]])\n",
    "\n",
    "@primitive\n",
    "def ArrayFun(x, b11, b12, b21, b22):\n",
    "    return ArrayFunAD(x, b11, b12, b21, b22)\n",
    "\n",
    "def ArrayFun_grad_x(x, b11, b12, b21, b22):\n",
    "    # The last array axis is the x dimension.\n",
    "    return np.array([[b11, b12], [b21, b22]])\n",
    "\n",
    "def ArrayFun_vjp_x(g, ans, vs, gvs, x, b11, b12, b21, b22):\n",
    "    mul = np.expand_dims(g, 2) * ArrayFun_grad_x(x, b11, b12, b21, b22)\n",
    "    return mul.sum(axis=(0,1))\n",
    "ArrayFun.defvjp(ArrayFun_vjp_x, argnum=0)\n",
    "\n",
    "\n",
    "K = 3\n",
    "b11 = np.random.rand(K)\n",
    "b12 = np.random.rand(K)\n",
    "b21 = np.random.rand(K)\n",
    "b22 = np.random.rand(K)\n",
    "x = np.random.rand(K)\n",
    "\n",
    "# print ArrayFun(x, b11, b12, b21, b22)\n",
    "# print ArrayFun_grad_x(x, b11, b12, b21, b22)\n",
    "\n",
    "ArrayFunJac = jacobian(ArrayFun)\n",
    "ArrayFunADJac = jacobian(ArrayFunAD)\n",
    "print ArrayFunJac(x, b11, b12, b21, b22) - ArrayFunADJac(x, b11, b12, b21, b22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[  0.00000000e+00  -6.93889390e-18]\n",
      "[[ -5.55111512e-17  -6.93889390e-18]\n",
      " [ -6.93889390e-18  -5.55111512e-17]]\n"
     ]
    }
   ],
   "source": [
    "# Propotional only.\n",
    "def MVNLikAD(mu, info, obs):\n",
    "    obs_bar = obs - mu\n",
    "    sign, info_logdet = np.linalg.slogdet(info)\n",
    "    assert sign > 0\n",
    "    return np.exp(-0.5 * np.dot(obs_bar, np.matmul(info, obs_bar)) - 0.5 * info_logdet)\n",
    "\n",
    "@primitive\n",
    "def MVNLik(mu, info, obs):\n",
    "    return MVNLikAD(mu, info, obs)\n",
    "\n",
    "# Mu gradient\n",
    "def MVNLik_grad_mu(mu, info, obs, ans):\n",
    "    return ans * (np.matmul(info, obs - mu))\n",
    "\n",
    "def MVNLik_vjp_mu(g, ans, vs, gvs, mu, info, obs):\n",
    "    return g * MVNLik_grad_mu(mu, info, obs, ans)\n",
    "MVNLik.defvjp(MVNLik_vjp_mu, argnum=0)\n",
    "\n",
    "# Info gradient\n",
    "def MVNLik_grad_info(mu, info, obs, ans):\n",
    "    return ans * (-0.5 * np.outer(obs - mu, obs - mu) - 0.5 * np.linalg.inv(info))\n",
    "\n",
    "def MVNLik_vjp_info(g, ans, vs, gvs, mu, info, obs):\n",
    "    return g * MVNLik_grad_info(mu, info, obs, ans)\n",
    "MVNLik.defvjp(MVNLik_vjp_info, argnum=1)\n",
    "\n",
    "# Hessians\n",
    "def MVNLik_grad_mu_grad_mu(mu, info, obs):\n",
    "    # Derivative wrt the exponential term pulls down another info * (obs - mu)\n",
    "    mvn_lik = MVNLik(mu, info, obs)\n",
    "    info_obs_bar = np.matmul(info, obs - mu)\n",
    "    exp_grad = mvn_lik * np.outer(info_obs_bar, info_obs_bar)\n",
    "\n",
    "    # Derivative wr the obs - mu term\n",
    "    mat_grad = -MVNLikAD(mu, info, obs) * info\n",
    "    return exp_grad = mat_grad\n",
    "\n",
    "def MVNLik_grad_mu_grad_info(mu, info, obs):\n",
    "    mvn_lik = MVNLik(mu, info, obs)\n",
    "    info_obs_bar = np.matmul(info, obs - mu)\n",
    "    log_mvn_info_grad = -0.5 * np.outer(obs - mu, obs - mu) - 0.5 * np.linalg.inv(info)\n",
    "\n",
    "    exp_grad = np.outer(ans, np.matmul(info, obs - mu))\n",
    "    mat_grad = -MVNLikAD(mu, info, obs) * info\n",
    "    return mvn_lik * (np.einsum('i,jk->ijk', log_mvn_info_grad, log_mvn_info_grad) +\n",
    "                      )\n",
    "\n",
    "\n",
    "K = 2\n",
    "mu = np.random.rand(K)\n",
    "info = np.full((K, K), 0.1) + np.eye(K)\n",
    "obs = np.random.rand(K)\n",
    "\n",
    "MVNLikGrad0 = grad(MVNLik, argnum=0)\n",
    "MVNLikADGrad0 = grad(MVNLikAD, argnum=0)\n",
    "MVNLikGrad1 = grad(MVNLik, argnum=1)\n",
    "MVNLikADGrad1 = grad(MVNLikAD, argnum=1)\n",
    "\n",
    "print MVNLikAD(mu, info, obs) - MVNLik(mu, info, obs)\n",
    "print MVNLikADGrad0(mu, info, obs) - MVNLikGrad0(mu, info, obs)\n",
    "print MVNLikADGrad1(mu, info, obs) - MVNLikGrad1(mu, info, obs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[[  0  10  20]\n",
      "  [ 30  40  50]\n",
      "  [ 60  70  80]]\n",
      "\n",
      " [[  0  20  40]\n",
      "  [ 60  80 100]\n",
      "  [120 140 160]]\n",
      "\n",
      " [[  0  30  60]\n",
      "  [ 90 120 150]\n",
      "  [180 210 240]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (np.arange(3) + 1) * 10\n",
    "y = np.arange(9).reshape(3, 3)\n",
    "print x\n",
    "print y\n",
    "print np.einsum('i,jk->ijk', x, y) # This produces a general outer product\n",
    "\n",
    "np.full((3, 3), x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
