{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import VectorParam, ScalarParam, PosDefMatrixParam, ModelParamsDict\n",
    "from autograd import grad, hessian, jacobian\n",
    "import math\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 5\n",
      "mu: [ 1.  2.  3.]\n",
      "[[ 1.76082448  0.47044797  0.88434727  0.70025463]\n",
      " [ 0.47044797  2.37708584  0.71429369  0.81753673]\n",
      " [ 0.88434727  0.71429369  2.19961525  1.03427482]\n",
      " [ 0.70025463  0.81753673  1.03427482  1.96084439]]\n",
      "[[  2.22044605e-16   5.55111512e-17   0.00000000e+00   1.11022302e-16]\n",
      " [  5.55111512e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.11022302e-16   0.00000000e+00   0.00000000e+00  -2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "mu = VectorParam(\"mu\", 3, lb=0, ub=10)\n",
    "mu.set(np.array([1., 2., 3.]))\n",
    "mu.get()\n",
    "foo = mu.get_free()\n",
    "mu.set_free(foo)\n",
    "mu.get()\n",
    "\n",
    "tau = ScalarParam('tau', lb=0, ub=float(\"inf\"))\n",
    "tau.set(5)\n",
    "# print dir(tau)\n",
    "tau.get_free()\n",
    "print tau\n",
    "print mu\n",
    "\n",
    "a = np.matrix(np.random.rand(4, 4))\n",
    "sigma_val = a * a.T + np.eye(4)\n",
    "\n",
    "print sigma_val\n",
    "\n",
    "sigma = PosDefMatrixParam('sigma', 4)\n",
    "sigma.set(sigma_val)\n",
    "sigma_0 = PosDefMatrixParam('sigma0', 4)\n",
    "sigma_0.set_free(sigma.get_free())\n",
    "print sigma_0.get() - sigma.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var_mu_0' 'var_mu_1' 'var_mu_2' 'e_mu_0' 'e_mu_1' 'e_mu_2']\n",
      "[ 2.   2.   2.   0.1  0.1  0.1]\n",
      "[ 0.69314718  0.69314718  0.69314718  0.1         0.1         0.1       ]\n",
      "ModelParamsList:\n",
      "\tvar_mu: [ 2.  2.  2.]\n",
      "\te_mu: [ 0.1  0.1  0.1]\n"
     ]
    }
   ],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "K = 3\n",
    "mvn_par = ModelParamsDict()\n",
    "\n",
    "mvn_par.push_param(VectorParam('e_mu', K))\n",
    "mvn_par.push_param(VectorParam('var_mu', K, lb=0))\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 0.1))\n",
    "mvn_par['var_mu'].set(np.full(K, 2.))\n",
    "\n",
    "print mvn_par.names()\n",
    "print mvn_par.get()\n",
    "print mvn_par.get_free()\n",
    "\n",
    "print mvn_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 100\n",
    "true_mu = np.random.rand(K).T\n",
    "x_cov = np.random.rand(K, K)\n",
    "x_cov = 0.5 * (x_cov * x_cov.T)\n",
    "# Make sure the diagonals are equal\n",
    "for k in range(K):\n",
    "    x_cov[k, k] = 2\n",
    "\n",
    "x_draws = [ np.random.multivariate_normal(true_mu, x_cov) for n in range(N) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.66183311823\n",
      "5.66183311823\n",
      "62.7672297674\n",
      "62.7672297674\n",
      "Autograd FloatNode with value 5.66183311823 and 1 tape(s)\n",
      "[  5.06642100e-11   5.01263711e-11  -7.63836974e-11   7.99660112e-01\n",
      "   1.89277298e-01  -2.65443680e+00]\n",
      "Autograd FloatNode with value 5.66183311823 and 2 tape(s)\n",
      "[[  0.5          0.           0.           0.           0.           0.        ]\n",
      " [  0.           0.5          0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.5          0.           0.           0.        ]\n",
      " [  0.           0.           0.          51.88809949  -2.86028613\n",
      "   -8.96373519]\n",
      " [  0.           0.           0.          -2.86028613  51.91171826\n",
      "   -9.03368634]\n",
      " [  0.           0.           0.          -8.96373519  -9.03368634\n",
      "   53.30254414]]\n"
     ]
    }
   ],
   "source": [
    "# Log likelihood\n",
    "def LogLikelihood(x_row, x_info, e_mu, e_mu_outer):\n",
    "    return 0.5 * (np.dot(e_mu, np.matmul(x_info, x_row)) + np.dot(x_row, np.matmul(x_info, e_mu)) - \\\n",
    "                  np.trace(np.matmul(x_info, e_mu_outer)))\n",
    "\n",
    "\n",
    "def UnivariateNormalExpectedEntropy(var_mu):\n",
    "    return 0.5 * np.log(var_mu)\n",
    "\n",
    "\n",
    "def Elbo(x_draws, mvn_par):\n",
    "    x_info = np.linalg.inv(x_cov)\n",
    "    var_mu = mvn_par['var_mu'].get()\n",
    "    e_mu = mvn_par['e_mu'].get()\n",
    "    e_mu_outer = np.outer(e_mu, e_mu) + np.diag(var_mu)\n",
    "\n",
    "    ll = sum([ LogLikelihood(x, x_info, e_mu, e_mu_outer) for x in x_draws ])\n",
    "    entropy = sum([ UnivariateNormalExpectedEntropy(var_mu_k) for var_mu_k in var_mu])\n",
    "\n",
    "    return ll + entropy\n",
    "\n",
    "\n",
    "def KLWrapper(free_par_vec):\n",
    "    # This seems to be necessary to avoid changing the type of mvn_par.\n",
    "    mvn_par_ad = copy.copy(mvn_par)\n",
    "    mvn_par_ad.set_free(free_par_vec)\n",
    "    kl = -Elbo(x_draws, mvn_par_ad)\n",
    "    print kl\n",
    "    return kl\n",
    "\n",
    "# var_mu = mvn_par['var_mu'].get()\n",
    "# e_mu = mvn_par['e_mu'].get()\n",
    "# e_mu_outer = np.outer(e_mu, e_mu) + np.diag(var_mu)\n",
    "\n",
    "# x_info = np.linalg.inv(x_cov)\n",
    "# x_row = x_draws[1]\n",
    "# print x_row\n",
    "# print np.dot(x_row, np.matmul(x_info, e_mu))\n",
    "# print np.dot(e_mu, np.matmul(x_info, x_row))\n",
    "# print e_mu_outer\n",
    "# print np.diag(var_mu)\n",
    "# print np.outer(e_mu, e_mu)\n",
    "\n",
    "# print mvn_par.names()\n",
    "# print mvn_par\n",
    "# print mvn_par.get()\n",
    "# print mvn_par.get_free()\n",
    "\n",
    "KLGrad = grad(KLWrapper)\n",
    "KLHess = hessian(KLWrapper)\n",
    "\n",
    "free_par_vec = mvn_par.get_free()\n",
    "print KLWrapper(free_par_vec)\n",
    "print KLWrapper(free_par_vec + 1)\n",
    "print KLGrad(free_par_vec)\n",
    "print KLHess(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Set initial values.\n",
    "\n",
    "# Is there not a better way than reduce?\n",
    "true_means = reduce(lambda x, y: x + y, x_draws) / N\n",
    "\n",
    "mvn_par['e_mu'].set(np.full(K, 1.0))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "Autograd FloatNode with value 5.59397133479 and 1 tape(s)\n",
      "5.59397133479\n",
      "Newton Trust\n",
      "Autograd FloatNode with value 5.59397133479 and 1 tape(s)\n",
      "Autograd FloatNode with value 5.59397133479 and 2 tape(s)\n",
      "5.59397133479\n",
      "5.59397133479\n"
     ]
    }
   ],
   "source": [
    "print 'BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(KLWrapper, init_par_vec, method='bfgs', jac=KLGrad, tol=1e-10)\n",
    "print 'Newton Trust'\n",
    "vb_opt = optimize.minimize(KLWrapper, vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hess=KLHess)\n",
    "mvn_par_opt = copy.copy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelParamsList:\n",
      "\tvar_mu: [ 0.01927224  0.01926347  0.01876083]\n",
      "\te_mu: [ 0.24924344  0.04456072 -0.05249592]\n",
      "[ 0.24924344  0.04456072 -0.05249592]\n"
     ]
    }
   ],
   "source": [
    "# Mean parameters still don't match.\n",
    "print mvn_par_opt\n",
    "print true_means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
