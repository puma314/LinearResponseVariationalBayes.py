{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "\n",
    "# from VariationalBayes.ParameterDictionary import ModelParamsDict\n",
    "# from VariationalBayes import PosDefMatrixParam, PosDefMatrixParamVector\n",
    "# from VariationalBayes import SimplexParam\n",
    "\n",
    "import math\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "#import copy\n",
    "from copy import deepcopy\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "from scipy import optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of data points:\n",
    "n_num = 100\n",
    "\n",
    "# Dimension of observations:\n",
    "d_num = 2\n",
    "\n",
    "# Number of clusters:\n",
    "k_num = 2\n",
    "\n",
    "mu_scale = 3\n",
    "noise_scale = 0.5\n",
    "\n",
    "true_pi = np.linspace(0.2, 0.8, k_num)\n",
    "true_pi = true_pi / np.sum(true_pi)\n",
    "\n",
    "true_z = np.random.multinomial(1, true_pi, n_num)\n",
    "true_z_ind = np.full(n_num, -1)\n",
    "for row in np.argwhere(true_z):\n",
    "    true_z_ind[row[0]] = row[1]\n",
    "\n",
    "mu_prior_mean = np.full(d_num, 0.)\n",
    "mu_prior_cov = np.diag(np.full(d_num, mu_scale ** 2))\n",
    "mu_prior_info = np.linalg.inv(mu_prior_cov)\n",
    "true_mu = np.random.multivariate_normal(mu_prior_mean, mu_prior_cov, k_num)\n",
    "\n",
    "true_sigma = np.array([ np.diag(np.full(d_num, noise_scale ** 2)) + np.full((d_num, d_num), 0.1) \\\n",
    "                        for k in range(k_num) ])\n",
    "true_info = np.array([ np.linalg.inv(true_sigma[k, :, :]) for k in range(k_num) ])\n",
    "\n",
    "x = np.array([ np.random.multivariate_normal(true_mu[true_z_ind[n]], true_sigma[true_z_ind[n]]) \\\n",
    "               for n in range(n_num) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1db51bad68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Never a bad idea to visualize the dataz\n",
    "plt.plot(x[:,0], x[:,1], 'k.')\n",
    "for k in range(k_num):\n",
    "    plt.plot(true_mu[k, 0], true_mu[k, 1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global:\n",
      "\tinfo:\n",
      "[[[ 1.  0.]\n",
      "  [ 0.  1.]]\n",
      "\n",
      " [[ 1.  0.]\n",
      "  [ 0.  1.]]]\n",
      "\tmu:\n",
      "[[ 0.24313251  0.20012172]\n",
      " [ 0.72277832  0.11224076]]\n",
      "\tpi: [[ 0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "global_params = vb.ModelParamsDict('global')\n",
    "\n",
    "global_params.push_param(\n",
    "    vb.PosDefMatrixParamVector(name='info', length=k_num, matrix_size=d_num))\n",
    "global_params.push_param(\n",
    "    vb.ArrayParam(name='mu', shape=(k_num, d_num)))\n",
    "global_params.push_param(\n",
    "    vb.SimplexParam(name='pi', shape=(1, k_num)))\n",
    "\n",
    "local_params = \\\n",
    "    vb.SimplexParam(name='e_z', shape=(n_num, k_num),\n",
    "                    val=np.full(true_z.shape, 1. / k_num))\n",
    "\n",
    "single_local_params = \\\n",
    "    vb.SimplexParam(name='e_z', shape=(1, k_num), val=np.full((1, k_num), 1. / k_num))\n",
    "\n",
    "params = vb.ModelParamsDict('mixture model')\n",
    "params.push_param(global_params)\n",
    "params.push_param(local_params)\n",
    "\n",
    "true_init = False\n",
    "if true_init:\n",
    "    params['global']['info'].set(true_info)\n",
    "    params['global']['mu'].set(true_mu)\n",
    "    params['global']['pi'].set(true_pi)\n",
    "else:\n",
    "    params['global']['mu'].set(np.random.random(params['global']['mu'].shape()))\n",
    "    \n",
    "\n",
    "single_obs_params = vb.ModelParamsDict('mixture model single obs')\n",
    "single_obs_params.push_param(params['global'])\n",
    "single_obs_params.push_param(single_local_params)\n",
    "\n",
    "init_par_vec = params.get_free()\n",
    "\n",
    "print(params['global'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_params = vb.ModelParamsDict()\n",
    "prior_params.push_param(vb.VectorParam(name='mu_prior_mean', size=d_num, val=mu_prior_mean))\n",
    "prior_params.push_param(vb.PosDefMatrixParam(name='mu_prior_info', size=d_num, val=mu_prior_info))\n",
    "prior_params.push_param(vb.ScalarParam(name='alpha', val=2.0))\n",
    "prior_params.push_param(vb.ScalarParam(name='dof', val=d_num + 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_logdet_array(info):\n",
    "    return np.array([ np.linalg.slogdet(info[k, :, :])[1] for k in range(info.shape[0]) ])\n",
    "\n",
    "# This is the log probability of each observation for each component.\n",
    "def loglik_obs_by_k(mu, info, pi, x):\n",
    "    log_lik = \\\n",
    "        -0.5 * np.einsum('ni, kij, nj -> nk', x, info, x) + \\\n",
    "               np.einsum('ni, kij, kj -> nk', x, info, mu) + \\\n",
    "        -0.5 * np.expand_dims(np.einsum('ki, kij, kj -> k', mu, info, mu), axis=0)\n",
    "\n",
    "    logdet_array = np.expand_dims(get_info_logdet_array(info), axis=0)\n",
    "    log_pi = np.log(pi)\n",
    "\n",
    "    log_lik += 0.5 * logdet_array + log_pi\n",
    "    \n",
    "    return log_lik\n",
    "\n",
    "mu = global_params['mu'].get()\n",
    "info = global_params['info'].get()\n",
    "pi = global_params['pi'].get()\n",
    "\n",
    "log_lik_array = data_log_lik_obs_by_k(mu, info, pi, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def mu_prior(mu, mu_prior_mean, mu_prior_info):\n",
    "    k_num = mu.shape[0]\n",
    "    d_num = len(mu_prior_mean)\n",
    "    assert mu.shape[1] == d_num\n",
    "    assert mu_prior_info.shape[0] == d_num\n",
    "    assert mu_prior_info.shape[1] == d_num\n",
    "    mu_prior_val = 0.0\n",
    "    for k in range(k_num):\n",
    "        mu_centered = mu[k, :] - mu_prior_mean\n",
    "        mu_prior_val += -0.5 * np.matmul(np.matmul(mu_centered, mu_prior_info), mu_centered)\n",
    "    return mu_prior_val\n",
    "    \n",
    "def pi_prior(pi, alpha):\n",
    "    return np.sum(alpha * np.log(pi))\n",
    "\n",
    "def info_prior(info, dof):\n",
    "    k_num = info.shape[0]\n",
    "    d_num = info.shape[1]\n",
    "    assert d_num == info.shape[2]\n",
    "    assert dof > d_num - 1\n",
    "    # Not a complete Wishart prior\n",
    "    # TODO: cache the log determinants.\n",
    "    info_prior_val = 0.0\n",
    "    for k in range(k_num):\n",
    "        sign, logdet = np.linalg.slogdet(info[k, :, :])\n",
    "        info_prior_val += 0.5 * (dof - d_num - 1) * logdet\n",
    "    return info_prior_val\n",
    "\n",
    "def multinoulli_entropy(e_z):\n",
    "    return -1 * np.sum(e_z * np.log(e_z))\n",
    "\n",
    "def get_sparse_multinoulli_entropy_hessian(e_z_vec):\n",
    "    k = len(e_z_vec)\n",
    "    vals = -1. / e_z_vec\n",
    "    return sp.sparse.csr_matrix((vals, ((range(k)), (range(k)))), (k, k))\n",
    "\n",
    "weights = np.full((n_num, 1), 1.0)\n",
    "e_z = params['e_z'].get()\n",
    "data_log_likelihood(true_mu, true_info, e_z, pi, x)\n",
    "mu_prior(true_mu, mu_prior_mean, mu_prior_info)\n",
    "pi_prior(true_pi, 2.0)\n",
    "info_prior(true_info, d_num + 2)\n",
    "multinoulli_entropy(e_z)\n",
    "\n",
    "get_multinoulli_entropy_hessian = autograd.hessian(multinoulli_entropy)\n",
    "e_z0 = e_z[0, :]\n",
    "\n",
    "print(np.max(np.abs(\n",
    "    get_multinoulli_entropy_hessian(e_z0) - get_sparse_multinoulli_entropy_hessian(e_z0).toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VariationalBayes.Parameters import convert_vector_to_free_hessian\n",
    "\n",
    "class Objective(object):\n",
    "    def __init__(self, x, params, prior_params):\n",
    "        self.x = x\n",
    "        self.params = deepcopy(params)\n",
    "        self.prior_params = deepcopy(prior_params)\n",
    "        self.weights = np.full((x.shape[0], 1), 1.0)\n",
    "\n",
    "        # Autograd derivatives\n",
    "        self.kl_free_grad = autograd.grad(self.kl_free)\n",
    "        self.kl_free_hessian = autograd.hessian(self.kl_free) # This will be slow.\n",
    "        self.kl_free_hvp = autograd.hessian_vector_product(self.kl_free)\n",
    "\n",
    "        self.kl_free_global_grad = autograd.grad(self.kl_free_global)\n",
    "        self.kl_free_global_hessian = autograd.hessian(self.kl_free_global)\n",
    "        self.kl_free_global_hvp = autograd.hessian_vector_product(self.kl_free_global)\n",
    "\n",
    "        self.get_z_nat_params = autograd.grad(self.loglik_e_z)\n",
    "\n",
    "        self.get_moment_jacobian = autograd.jacobian(self.get_interesting_moments)\n",
    "        \n",
    "        self.kl_vector_global_jac = autograd.jacobian(self.kl_vector_global_local, argnum=0)\n",
    "        self.kl_vector_global_hessian = autograd.hessian(self.kl_vector_global_local, argnum=0)\n",
    "        self.kl_vector_global_local_hessian = autograd.jacobian(self.kl_vector_global_jac, argnum=1)\n",
    "\n",
    "        self.kl_vector_jac = autograd.jacobian(self.kl_vector)\n",
    "        self.kl_vector_hessian = autograd.hessian(self.kl_vector)\n",
    "\n",
    "    def loglik_obs_by_k(self):\n",
    "        info = self.params['global']['info'].get()\n",
    "        mu = self.params['global']['mu'].get()\n",
    "        pi = self.params['global']['pi'].get()        \n",
    "        return loglik_obs_by_k(mu, info, pi, self.x)\n",
    "\n",
    "    # This needs to be defined so we can differentiate it for CAVI.\n",
    "    def loglik_e_z(self, e_z):\n",
    "        return np.sum(e_z * self.loglik_obs_by_k())\n",
    "\n",
    "    def loglik(self):\n",
    "        e_z = self.params['e_z'].get()\n",
    "        return self.loglik_e_z(e_z)\n",
    "\n",
    "    def loglik_obs(self):\n",
    "        log_lik_array = self.loglik_obs_by_k()\n",
    "        e_z = self.params['e_z'].get()\n",
    "        return np.sum(log_lik_array * e_z, axis=1)    \n",
    "\n",
    "    def prior(self):\n",
    "        info = self.params['global']['info'].get()\n",
    "        mu = self.params['global']['mu'].get()\n",
    "        pi = self.params['global']['pi'].get()        \n",
    "        mu_prior_mean = self.prior_params['mu_prior_mean'].get()\n",
    "        mu_prior_info = self.prior_params['mu_prior_info'].get()\n",
    "        prior = 0.\n",
    "        prior += mu_prior(mu, mu_prior_mean, mu_prior_info)\n",
    "        prior += pi_prior(pi, self.prior_params['alpha'].get())\n",
    "        prior += info_prior(info, self.prior_params['dof'].get())\n",
    "        return prior\n",
    "    \n",
    "    def optimize_z(self):\n",
    "        # Take a CAVI step on Z.\n",
    "        info = self.params['global']['info'].get()\n",
    "        mu = self.params['global']['mu'].get()\n",
    "        pi = self.params['global']['pi'].get()\n",
    "        e_z = self.params['e_z'].get()\n",
    "\n",
    "        natural_parameters = obj.get_z_nat_params(e_z)\n",
    "        z_logsumexp = np.expand_dims(sp.misc.logsumexp(natural_parameters, 1), axis=1)\n",
    "        e_z = np.exp(natural_parameters - z_logsumexp)\n",
    "        self.params['e_z'].set(e_z)\n",
    "    \n",
    "    def kl(self, include_local_entropy=True):\n",
    "        elbo = self.prior() + self.loglik()\n",
    "\n",
    "        if include_local_entropy:\n",
    "            e_z = self.params['e_z'].get()\n",
    "            elbo += multinoulli_entropy(e_z)\n",
    "        \n",
    "        return -1 * elbo\n",
    "    \n",
    "\n",
    "    #######################\n",
    "    # Moments for sensitivity\n",
    "    \n",
    "    def get_interesting_moments(self, free_params):\n",
    "        self.params.set_free(free_params)\n",
    "        return self.params['global']['mu'].get_vector()\n",
    "\n",
    "    ######################################\n",
    "    # Compute sparse hessians by hand.\n",
    "\n",
    "    # Log likelihood by data point.\n",
    "    \n",
    "    # The rows are the z vector indices and the columns are the data points.\n",
    "    def loglik_vector_local_weight_hessian_sparse(self):\n",
    "        log_lik_array = self.loglik_obs_by_k()\n",
    "\n",
    "        hess_vals = [] # These will be the entries of dkl / dz dweight^T\n",
    "        hess_rows = [] # These will be the z indices\n",
    "        hess_cols = [] # These will be the data indices\n",
    "        # This is the Hessian of the negative entropy, which enters the KL divergence.\n",
    "        for row in range(e_z.shape[0]):\n",
    "            z_row_inds = self.params['e_z'].get_vector_indices(row)\n",
    "            for col in range(e_z.shape[1]):\n",
    "                hess_vals.append(log_lik_array[row, col])\n",
    "                hess_rows.append(z_row_inds[col])\n",
    "                hess_cols.append(row)\n",
    "\n",
    "        local_size = self.params['e_z'].vector_size()\n",
    "        return sp.sparse.csr_matrix((hess_vals, (hess_rows, hess_cols)),\n",
    "                                     (local_size, self.x.shape[0]))\n",
    "\n",
    "    def loglik_free_local_weight_hessian_sparse(self):\n",
    "        free_par_local = self.params['e_z'].get_free()\n",
    "        free_to_vec_jac = self.params['e_z'].free_to_vector_jac(free_par_local) \n",
    "        return free_to_vec_jac .T * \\\n",
    "               self.loglik_vector_local_weight_hessian_sparse()\n",
    "        \n",
    "    def loglik_free_weight_hessian_sparse(self):\n",
    "        self.loglik_obs_free_global_jac = \\\n",
    "            autograd.jacobian(self.loglik_obs_free_global_local, argnum=0)\n",
    "        loglik_obs_free_global_jac = \\\n",
    "            self.loglik_obs_free_global_jac(self.params['global'].get_free(),\n",
    "                                            self.params['e_z'].get_free())\n",
    "        loglik_obs_free_local_jac = \\\n",
    "            self.loglik_free_local_weight_hessian_sparse()\n",
    "        return sp.sparse.vstack([loglik_obs_free_global_jac, loglik_obs_free_local_jac])\n",
    "\n",
    "    # KL\n",
    "    def kl_vector_local_hessian_sparse(self):\n",
    "        e_z = self.params['e_z'].get()\n",
    "        hess_vals = []\n",
    "        hess_rows = []\n",
    "        # This is the Hessian of the negative entropy, which enters the KL divergence.\n",
    "        for row in range(e_z.shape[0]):\n",
    "            row_inds = self.params['e_z'].get_vector_indices(row)\n",
    "            for col in range(e_z.shape[1]):\n",
    "                hess_vals.append(1. / e_z[row, col])\n",
    "                hess_rows.append(row_inds[col])\n",
    "        local_size = self.params['e_z'].vector_size()\n",
    "        return sp.sparse.csr_matrix((hess_vals, (hess_rows, hess_rows)),\n",
    "                                    (local_size, local_size))\n",
    "\n",
    "    def kl_vector_hessian_sparse(self):\n",
    "        global_vec = obj.params['global'].get_vector()\n",
    "        local_vec = obj.params['e_z'].get_vector()\n",
    "    \n",
    "        global_hess = obj.kl_vector_global_hessian(global_vec, local_vec)\n",
    "        global_local_hess = obj.kl_vector_global_local_hessian(global_vec, local_vec)\n",
    "        local_hess_sparse = self.kl_vector_local_hessian_sparse()\n",
    "        sp_hess =  sp.sparse.bmat([ [global_hess,         global_local_hess],\n",
    "                                    [global_local_hess.T, local_hess_sparse]])\n",
    "        return np.array(sp_hess.toarray())\n",
    "    \n",
    "\n",
    "    # This takes free_params as an argument so it can be used in optimization.\n",
    "    def kl_free_hessian_sparse(self, free_params):\n",
    "        self.params.set_free(free_params)\n",
    "        kl_vector_hessian_sparse = self.kl_vector_hessian_sparse()\n",
    "        kl_vector_jac = self.kl_vector_jac(vec_par)\n",
    "        kl_hessian_sparse = convert_vector_to_free_hessian(\n",
    "            self.params, free_params, kl_vector_jac, kl_vector_hessian_sparse)\n",
    "\n",
    "        # If you don't convert to an array, it returns a matrix type, which\n",
    "        # seems to cause mysterious problems with scipy.optimize.minimize.\n",
    "        return np.array(kl_hessian_sparse)\n",
    "\n",
    "    ##################################\n",
    "    # Wrappers for autodiff follow. The nomeclature is\n",
    "    # {function}_{free | vector}_{|global|local}_{|sparse}\n",
    "\n",
    "    def kl_free(self, free_params, verbose=False):\n",
    "        self.params.set_free(free_params)\n",
    "        kl = self.kl()\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def kl_free_global(self, global_free_params, verbose=False):\n",
    "        self.params['global'].set_free(global_free_params)\n",
    "        kl = self.kl(include_local_entropy=False)\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def kl_vector_global_local(self, global_vec_params, local_vec_params,\n",
    "                               verbose=False, include_local_entropy=True):\n",
    "        self.params['global'].set_vector(global_vec_params)\n",
    "        self.params['e_z'].set_vector(local_vec_params)\n",
    "        kl = self.kl(include_local_entropy=include_local_entropy)\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def kl_vector(self, vec_params, \n",
    "                  verbose=False, include_local_entropy=True):\n",
    "        self.params.set_vector(vec_params)\n",
    "        kl = self.kl(include_local_entropy=include_local_entropy)\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "    \n",
    "    def loglik_obs_free_global_local(self, free_params_global, free_params_local):\n",
    "        self.params['global'].set_free(free_params_global)\n",
    "        self.params['e_z'].set_free(free_params_local)\n",
    "        return self.loglik_obs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian:  0.4117100238800049\n",
      "Hessian vector product 0.020519733428955078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "obj = Objective(x, params, prior_params)\n",
    "obj.optimize_z()\n",
    "\n",
    "free_par = params.get_free()\n",
    "vec_par = params.get_vector()\n",
    "\n",
    "global_free_par = params['global'].get_free()\n",
    "obj.kl_free(free_par)\n",
    "\n",
    "grad = obj.kl_free_grad(free_par)\n",
    "\n",
    "hvp_time = time.time()\n",
    "hvp = obj.kl_free_hvp(free_par, grad)\n",
    "hvp_time = time.time() - hvp_time\n",
    "\n",
    "grad = obj.kl_free_global_grad(global_free_par)\n",
    "hvp = obj.kl_free_global_hvp(global_free_par, grad)\n",
    "\n",
    "# Not as slow!  You can ignore the autograd warning.\n",
    "sparse_hess_time = time.time()\n",
    "sparse_hessian = obj.kl_free_hessian_sparse(free_par)\n",
    "sparse_hess_time = time.time() - sparse_hess_time\n",
    "\n",
    "print('Hessian: ', sparse_hess_time)\n",
    "print('Hessian vector product', hvp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(100, 100)\n",
      "(200, 100)\n",
      "4.4408920985e-16\n"
     ]
    }
   ],
   "source": [
    "# Check the weight Jacobians.\n",
    "get_loglik_obs_free_local_jac = \\\n",
    "    autograd.jacobian(obj.loglik_obs_free_global_local, argnum=1)\n",
    "\n",
    "free_par_global = obj.params['global'].get_free()\n",
    "free_par_local = obj.params['e_z'].get_free()\n",
    "\n",
    "\n",
    "loglik_obs_free_local_jac = \\\n",
    "    get_loglik_obs_free_local_jac(free_par_global, free_par_local)\n",
    "\n",
    "loglik_vector_local_weight_hessian_sparse = \\\n",
    "    obj.loglik_vector_local_weight_hessian_sparse()\n",
    "\n",
    "likelihood_by_obs_free_local_jac_sparse = \\\n",
    "    obj.loglik_free_local_weight_hessian_sparse()\n",
    "\n",
    "print(obj.x.shape)\n",
    "print(likelihood_by_obs_free_local_jac_sparse.shape)\n",
    "print(loglik_vector_local_weight_hessian_sparse.shape)\n",
    "print(np.max(np.abs(loglik_obs_free_local_jac - likelihood_by_obs_free_local_jac_sparse)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loglik_obs_free_global_local() missing 1 required positional argument: 'free_params_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/errors.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_extra_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/convenience_wrappers.py\u001b[0m in \u001b[0;36mjacfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjacfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0moutshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstart_node\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogenitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/core.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(fun, args, kwargs, argnum)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mactive_progenitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mactive_progenitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: loglik_obs_free_global_local() missing 1 required positional argument: 'free_params_local'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-4fc4e0a5de60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglik_free_weight_hessian_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-f6e322207007>\u001b[0m in \u001b[0;36mloglik_free_weight_hessian_sparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloglik_free_weight_hessian_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglik_obs_free_global_jac\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglik_obs_free_global_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mloglik_obs_free_global_jac\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglik_obs_free_global_jac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'global'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mloglik_obs_free_local_jac\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglik_free_local_weight_hessian_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloglik_obs_free_global_jac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloglik_obs_free_local_jac\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/errors.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_extra_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/errors.py\u001b[0m in \u001b[0;36madd_extra_error_message\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutogradHint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mextra_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rgiordan/.local/lib/python3.5/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/errors.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_extra_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/convenience_wrappers.py\u001b[0m in \u001b[0;36mjacfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0madd_error_hints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjacfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0moutshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstart_node\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogenitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output seems independent of input.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgiordan/Documents/git_repos/autograd/autograd/core.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(fun, args, kwargs, argnum)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mactive_progenitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mactive_progenitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: loglik_obs_free_global_local() missing 1 required positional argument: 'free_params_local'"
     ]
    }
   ],
   "source": [
    "obj.loglik_free_weight_hessian_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAECCAYAAAAGmJmkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLWUC4WkIhcKSUUuFJKKXCgkFf0fIcoTuuJBQgMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1db302d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    # Compare the full and sparse Hessians\n",
    "    kl_vector_hessian = autograd.hessian(obj.kl_vector)\n",
    "    hessian = obj.kl_free_hessian(free_par) # Slow\n",
    "    vector_hessian = kl_vector_hessian(vec_par)  # Slow\n",
    "\n",
    "    # The slow full Hessian and sparse Hessian agree.\n",
    "    plt.matshow(sparse_hessian != 0)\n",
    "    assert np.max(np.abs(hessian - sparse_hessian)) < 1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import cProfile, pstats\n",
    "    from scipy.sparse import csr_matrix\n",
    "\n",
    "    param = obj.params\n",
    "    free_val = free_par\n",
    "\n",
    "    #cProfile.run('obj.get_sparse_hessian(free_par)', 'prof_hess')\n",
    "    cProfile.run('param.free_to_vector_hess(free_val)', 'prof_hess')\n",
    "\n",
    "    param.set_free(free_val)\n",
    "    vec_par = param.get_vector()\n",
    "\n",
    "    print('0')\n",
    "    tic = time.time()\n",
    "    vector_hess = obj.get_sparse_vector_hessian(vec_par)\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    print('1')\n",
    "    tic = time.time()\n",
    "    vector_jac = obj.get_vector_jacobian(vec_par)\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    print('2')\n",
    "    tic = time.time()\n",
    "    vector_jac = obj.get_vector_jacobian(vec_par)\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    print('3')\n",
    "    tic = time.time()\n",
    "    free_hess = csr_matrix((param.free_size(), param.free_size()))\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    print('4')\n",
    "    tic = time.time()\n",
    "    free_to_vec_jacobian = param.free_to_vector_jac(free_val)\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    print('5')\n",
    "    tic = time.time()\n",
    "    free_to_vec_hessian = param.free_to_vector_hess(free_val)\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    # Accumulate the third order terms, which are sparse.\n",
    "    print('6')\n",
    "    tic = time.time()\n",
    "    for vec_ind in range(param.vector_size()):\n",
    "        free_hess += free_to_vec_hessian[vec_ind] * vector_jac[vec_ind]\n",
    "    print(time.time() - tic)\n",
    "\n",
    "    # Then add the second-order terms, which may be dense depending on the\n",
    "    # vec_hess_target.\n",
    "    print('7')\n",
    "    tic = time.time()\n",
    "    free_hess += \\\n",
    "        free_to_vec_jacobian.T * vector_hess * free_to_vec_jacobian\n",
    "    print(time.time() - tic)\n",
    "\n",
    "\n",
    "    import pstats\n",
    "    prof_hess = pstats.Stats('prof_hess')\n",
    "    prof_hess.strip_dirs().sort_stats('cumulative').print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kl: 99.36596941834514\t\tkl_diff = -99.00005454383555\t\tdiff = 1.1063302705533213\n",
      " kl: 97.07326486316953\t\tkl_diff = -2.292704555175618\t\tdiff = 0.14819079070311614\n",
      " kl: 91.0344650304055\t\tkl_diff = -6.0387998327640275\t\tdiff = 0.24128875688728924\n",
      " kl: 77.53292718150888\t\tkl_diff = -13.501537848896618\t\tdiff = 0.6655026873373024\n",
      " kl: 68.79290516026671\t\tkl_diff = -8.740022021242169\t\tdiff = 1.1626734188434344\n",
      " kl: 67.02971871769243\t\tkl_diff = -1.7631864425742805\t\tdiff = 0.2036538004938695\n",
      " kl: 65.1712618933191\t\tkl_diff = -1.8584568243733344\t\tdiff = 0.17864512356269246\n",
      " kl: 62.47244409632887\t\tkl_diff = -2.6988177969902267\t\tdiff = 0.201972737773096\n",
      " kl: 58.25291238310025\t\tkl_diff = -4.219531713228619\t\tdiff = 0.455598326989211\n",
      " kl: 52.78292417231202\t\tkl_diff = -5.46998821078823\t\tdiff = 0.968638523186081\n",
      " kl: 51.4830960986777\t\tkl_diff = -1.2998280736343233\t\tdiff = 1.017606220383827\n",
      " kl: 51.48266270556726\t\tkl_diff = -0.00043339311044121587\t\tdiff = 0.02023628969841429\n",
      " kl: 51.48266248498899\t\tkl_diff = -2.2057826498667055e-07\t\tdiff = 0.00026541035924387835\n",
      " kl: 51.482662484127175\t\tkl_diff = -8.618172842034255e-10\t\tdiff = 3.0307886222047387e-05\n",
      " kl: 51.482662484126756\t\tkl_diff = -4.192202140984591e-13\t\tdiff = 1.9904507109202996e-07\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Perform EM.\n",
    "\n",
    "obj.params.set_free(init_par_vec)\n",
    "obj.optimize_z()\n",
    "global_param_vec = obj.params['global'].get_vector()\n",
    "kl = obj.kl()\n",
    "\n",
    "for step in range(20):\n",
    "    global_free_par = obj.params['global'].get_free()\n",
    "\n",
    "    # Different choices for the M step:\n",
    "    global_vb_opt = optimize.minimize(\n",
    "       lambda par: obj.kl_free_global(par, verbose=False),\n",
    "       x0=global_free_par, jac=obj.kl_free_global_grad, hessp=obj.kl_free_global_hvp,\n",
    "       method='trust-ncg', options={'maxiter': 50, 'gtol': 1e-2})\n",
    "    #global_vb_opt = optimize.minimize(\n",
    "    #    lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "    #    x0=global_free_par, jac=obj.global_kl_grad, hess=obj.global_kl_hessian,\n",
    "    #    method='trust-ncg', options={'maxiter': 50})\n",
    "    #global_vb_opt = optimize.minimize(\n",
    "    #   lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "    #   x0=global_free_par, method='nelder-mead', options={'maxiter': 500})\n",
    "    #global_vb_opt = optimize.minimize(\n",
    "    #   lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "    #  x0=global_free_par, method='bfgs', options={'maxiter': 50})\n",
    "    obj.params['global'].set_free(global_vb_opt.x)\n",
    "\n",
    "    # E-step:\n",
    "    obj.optimize_z()\n",
    "\n",
    "    new_global_param_vec = obj.params['global'].get_vector()\n",
    "    diff = np.max(np.abs(new_global_param_vec - global_param_vec))\n",
    "    global_param_vec = deepcopy(new_global_param_vec)\n",
    "    \n",
    "    new_kl = obj.kl()\n",
    "    kl_diff = new_kl - kl\n",
    "    kl = new_kl\n",
    "    print(' kl: {}\\t\\tkl_diff = {}\\t\\tdiff = {}'.format(kl, kl_diff, diff))\n",
    "    if diff < 1e-6:\n",
    "        break\n",
    "\n",
    "em_free_par = obj.params.get_free()\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.4826624841\n",
      "51.4826624841\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Finish with one joint Newton optimization to ensure global optimality.\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: obj.kl_free(par, verbose=True),\n",
    "    x0=em_free_par, jac=obj.kl_free_grad, hessp=obj.kl_free_hvp,\n",
    "    method='trust-ncg', options={'maxiter': 50})\n",
    "\n",
    "print('Done')\n",
    "obj.params.set_free(vb_opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # This isn't any faster, though with the sparse Hessian it's at least now comparable.\n",
    "    vb_opt_hess = optimize.minimize(\n",
    "        lambda par: obj.kl_free(par, verbose=True),\n",
    "        x0=em_free_par, jac=obj.kl_free_grad, hess=obj.kl_free_hessian_sparse,\n",
    "        method='trust-ncg', options={'maxiter': 50})\n",
    "\n",
    "    print('done')\n",
    "    print(obj.kl_free(vb_opt_hess.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1db2f03d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that the solution looks sensible.\n",
    "mu_fit = obj.params['global']['mu'].get()\n",
    "plt.plot(x[:,0], x[:,1], 'k.')\n",
    "for k in range(k_num):\n",
    "    plt.plot(mu_fit[k, 0], mu_fit[k, 1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "moment_jac = obj.get_moment_jacobian(vb_opt.x)\n",
    "\n",
    "# use_cg = False\n",
    "# if use_cg:\n",
    "#     # Get the sensitivity operator with conjugate gradient to avoid constructing the Hessian.\n",
    "#     # This was necessary before we had the sparse Hessian.\n",
    "#     sensitivity_operator = np.full_like(moment_jac, float('nan'))\n",
    "#     free_param_size = len(vb_opt.x)\n",
    "\n",
    "#     KLHessVecProdLO = LinearOperator((free_param_size, free_param_size),\n",
    "#                                      lambda vec: obj.kl_hvp(vb_opt.x, vec))\n",
    "#     for ind in range(sensitivity_operator.shape[0]):\n",
    "#         cg_res, info = sp.sparse.linalg.cg(KLHessVecProdLO, moment_jac[ind, :].T)\n",
    "#         sensitivity_operator[ind, :] = cg_res\n",
    "\n",
    "kl_free_hessian_sparse = obj.kl_free_hessian_sparse(vb_opt.x)\n",
    "sensitivity_operator = sp.sparse.linalg.spsolve(csc_matrix(kl_free_hessian_sparse), csr_matrix(moment_jac).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f1db2f17cc0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAAOfCAYAAADIOiHOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1db51f2c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(sensitivity_operator.toarray())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.params.set_free(vb_opt.x)\n",
    "def kl_weight_fun(weights):\n",
    "    obj.weights = weights\n",
    "    return obj.kl()\n",
    "\n",
    "default_weights = np.full((n_num, 1), 1.0)\n",
    "get_kl_weight_grad = autograd.grad(kl_weight_fun)\n",
    "kl_weight_grad = get_kl_weight_grad(default_weights)\n",
    "mu_weight_sens = np.matmul(sensitivity_operator, kl_weight_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
