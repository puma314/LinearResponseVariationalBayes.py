{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "# from VariationalBayes.ParameterDictionary import ModelParamsDict\n",
    "\n",
    "# from VariationalBayes import PosDefMatrixParam, PosDefMatrixParamVector\n",
    "# from VariationalBayes import SimplexParam\n",
    "\n",
    "import math\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "#import copy\n",
    "from copy import deepcopy\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "from scipy import optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of data points:\n",
    "n_num = 100\n",
    "\n",
    "# Dimension of observations:\n",
    "d_num = 2\n",
    "\n",
    "# Number of clusters:\n",
    "k_num = 2\n",
    "\n",
    "mu_scale = 3\n",
    "noise_scale = 0.5\n",
    "\n",
    "true_pi = np.linspace(0.2, 0.8, k_num)\n",
    "true_pi = true_pi / np.sum(true_pi)\n",
    "\n",
    "true_z = np.random.multinomial(1, true_pi, n_num)\n",
    "true_z_ind = np.full(n_num, -1)\n",
    "for row in np.argwhere(true_z):\n",
    "    true_z_ind[row[0]] = row[1]\n",
    "\n",
    "mu_prior_mean = np.full(d_num, 0.)\n",
    "mu_prior_cov = np.diag(np.full(d_num, mu_scale ** 2))\n",
    "mu_prior_info = np.linalg.inv(mu_prior_cov)\n",
    "true_mu = np.random.multivariate_normal(mu_prior_mean, mu_prior_cov, k_num)\n",
    "\n",
    "true_sigma = np.array([ np.diag(np.full(d_num, noise_scale ** 2)) + np.full((d_num, d_num), 0.1) \\\n",
    "                        for k in range(k_num) ])\n",
    "true_info = np.array([ np.linalg.inv(true_sigma[k, :, :]) for k in range(k_num) ])\n",
    "\n",
    "x = np.array([ np.random.multivariate_normal(true_mu[true_z_ind[n]], true_sigma[true_z_ind[n]]) \\\n",
    "               for n in range(n_num) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFOJJREFUeJzt3X+IZWd9x/HPd667Y1KlhdmlSsw4lkqpxRbNEByEMjah\nTaU1FC2kBDcxlKGtSRtoaU0X6tAlu5RCsNWCXerabhlU8EdN24g1MaOUvQZnQ2yNwRLFjYrUdUvV\nss2sM/PtH/fe7ez1/jhzz3POeZ7nvF+w7O7MnXufc++cz/2e7/Occ83dBQDIx1zTAwAAhEWwA0Bm\nCHYAyAzBDgCZIdgBIDMEOwBkhmAHgMwQ7ACQGYIdADLzgiYe9MiRI760tNTEQwNAss6fP/8ddz86\n7XaNBPvS0pK2traaeGgASJaZXShyO1oxAJAZgh0AMkOwA0BmCHYAyAzBDgCZIdgBIDMEO4Ckdbtd\nnTp1St1ut+mhRKORdewAEEK329Utt9yiK1eu6PDhw3rssce0srLS9LAaR8UOIFmbm5u6cuWKdnd3\ndeXKFW1ubjY9pCgQ7ACStbq6qsOHD6vT6ejw4cNaXV1tekhRoBUDJK7b7Wpzc1Orq6uta0OsrKzo\nsccea+32j0OwAwmjx9wL97Zt8zS0YoCE0WPGKAQ7kDB6zBiFVgyQMHrMGIVgBxJHjxnDaMUAQGYI\ndgDIDMEOAJkh2AEgMwQ7AGSGYAeAzBDsAJAZgh3AVXxoRR44QQmAJC4olhMqdgCSuKBYTgh2AJK4\noFhOaMUAkMQFxXJSOtjN7EZJZyX9uCSXdNrd/6Ls/QKoHxcUy0OIin1H0u+7+5Nm9mJJ583sU+7+\npQD3DQA4oNI9dnf/lrs/2f/39yU9I+mGsvcLAJhN0MlTM1uS9BpJT4z43pqZbZnZ1sWLF0M+LABg\nn2DBbmYvkvQRSfe7+/eGv+/up9192d2Xjx49GuphAQBDggS7mR1SL9Q33P2jIe4TADCb0sFuZibp\nfZKecfeHyg8JAFBGiIr99ZLeKukXzOyp/p83BrhfAMAMSi93dPd/lWQBxgIACIBLCgBAZgh2AMgM\nwQ4AmSHYASAzBDsAZIZgR1b4aDeA67EjI3y0G9BDxY5s8NFuQA/BjiSNarnw0W5AD60YJGdcy4WP\ndgN6CPaW6na7SQZgt9vV+vq6tre3tbe3d7XlMtgGPtoNINhbKdVJxsG4B6E+NzdHywUYgR57C6U6\nyTgY9yDUb7311mTelDAeS1TDo2JvocEk46Bin7XirbudMzzu9fV1Qj1xqR49xo5gb6EQk4xN7JBV\nTY6mOt+Qg1FHj7wG5RHsLVV2krGpHTL05CgVY7NCHT3iWvTYMZNc1ozvf4Pa3t7W+vo6vd4aDY7C\nTpw4wZtqQObutT/o8vKyb21t1f64CGtUCyO1tsaolTbz8/OEDKJkZufdfXna7WjFYGbDbZEU2xqD\ninF9fV2PPvroyLXxQGpoxSCYVJdRrqysaH19XfPz82NbSyzJQ0qo2BFMyhNhk1bcpHgkgnajYkcw\nqU+Erays6IEHHvihcQc7EtnYkJaWpLm53t8bG2WHDIxExY6gcrxWS5AjkY0NaW1Nuny59/8LF3r/\nl6Q77ww21iqkNiEOVsUAhZQOt6WlXpgPe/nLpa99rezwKkMbKi5FV8XQigGmCFKxPvfcwb4eiVQn\nxNuOVgwwQbCKdXFxdMW+uFh+kBVKeUK8zajYgQmCVawPPihdf/21X7v++t7XI5b6hHhbUbEDEwSr\nWAcTpMeP99ovi4u9UI984lTKc0I8d0yeAlOwKgSx4JICQCBUrEgNPXYAyEyQYDezM2b2bTP7Yoj7\nAwDMLlTF/reSbgt0X0A0uPgXUhSkx+7unzWzpRD3BTRp/0SpJM66RJKYPAX6hk9Guuuuu1r3eZx1\nrABilVH1agt2M1uTtCZJi5GfbYd2Gj4ZSVKrzrqs47owXHumHrWtinH30+6+7O7LR48erethgcKG\nP8f12LFjrTrrso7rwnDtmXrQigH6xn3YRu6BPlDHdWG49kw9gpx5amYfkLQq6Yik/5T0Tnd/37jb\nc+YpECd67HEreuYplxQAMkeQ5oNLCgANiiVMmaxsJ4IdCCymMB01WUmw549rxQCBbW5uant7W7u7\nu9re3m505cfwSh8mK9uBih0IbGFhQXt7e5Kkvb09LSwsFPq5Kto341b6IG8EOxDYpUuXNDc3p729\nPc3NzenSpUtTf6bK9g2XHW4fWjFAYKurq5qfn1en09H8/Hyh9gcn7iAkKnYgsFnaH5y4g5BYxw5E\nIpYlkogX69iBxNALRyj02AEgMwQ7AGSGYAdQGz5qsB702FELJgYR06UWckewo3Ls0JC4bk2daMWg\ncpx8A4nr1tSJih2V4+QbSFy3pk6coIRa0GMHyuMEJUxUd9By8g1QH4K9hZjMBPLG5GkLMZkJ5I1g\nbyFWJwB5oxXTQqxOyAMT0hiHYG8pJjPTxjwJJqEVAySIeRJMQrADCWKeBJPQigESxDwJJiHYgUQx\nT4JxaMUAQGYIdgDIDMEOAJkh2AEgMwQ7AGQmSLCb2W1m9mUze9bM3hHiPgEAsykd7GbWkfRXkn5Z\n0qsk/YaZvars/QIAZhOiYr9Z0rPu/lV3vyLpg5JuD3C/AIAZhAj2GyR9fd//v9H/GgCgAbVNnprZ\nmpltmdnWxYsX63pYYKRut6tTp06p2+02PRQguBCXFPimpBv3/f9l/a9dw91PSzot9T7MOsDjAjPh\nkrfIXYiK/fOSXmlmrzCzw5LukPRwgPsFKsElb5G70hW7u++Y2b2SPimpI+mMuz9demRARQaXvB1U\n7FzyFrkJcnVHd39E0iMh7guoGpe8Re64bC9aiUveImdcUgBIGKt7MAoVO5AoVvdgHCr2xFVZsVEN\nxo3VPRiHij1hVVZsVIPxY3UPxqFiT1iVFRvVYPwGq3tOnDjBGy+uQcWesCorNqrBNLC6B6MQ7Amr\ncj02a70RQrfb5XeoAeZe/2VblpeXfWtrq/bHBVAf5mnCM7Pz7r487Xb02AFUgnma5hDsaARLKfM3\nmKfpdDrM09SMHjtqxyF6OzBP0xyCHbUbdYi+srLCRFuGWLVzrbp+xwl21G7UUkqqeOSuzt9xeuyo\n3agTa5hoQ+7q/B2nYkcjhg/ROSEKuavzd5xgT0Tu/Wcm2pC7On/HOUEpAfSf45H7GyziVvQEJSr2\nBIxbRZKLVMKSN1ikgmBPQM7955TCMvc3WOSDVTEJGF5FIimbszZTWg3DmZRIBRV7IgarSFKqcIso\nczRSdwuHCV6kgmBPTBPtgCoDdNawbOoNbv8yzVTmBtA+BHtiquq3jwupgwTorEE3y2nnTfe7czty\nQl4I9sRU0Q6YFFJFA7TuoGt6QrnpNxZgEoI9QaEvrDQppIoGaOigm1b9N93vbvqNBZiEYMfEkCoa\noCGDrmj13+SVA5t+YwEmIdgxNaSKBGjIoEulzcElaRErgh2SwoRUqKCjzREOK3faiWBHdNrY5igT\nwCFWNCEvBDui1KY2R5kADrGiCfnhkgKoHB9cPVmZyypM+lkugdBepSp2M/t1SeuSflrSze5e6bV4\n6RdWp6rndlJFyevZU2ZOIcSKJmTI3Wf+o16g/5SkTUnLRX/upptu8oM6d+6cX3fddd7pdPy6667z\nc+fOHfg+MFqVz+3Jkye90+m4JO90On7y5MnKHzNF586d85MnT870PJT5WaRF0pYXyNhSFbu7PyNJ\nZlbu3aUA+oXVqfK5HVdR8npeq8ycQpvmI1BMMpOnLIGrTpXP7bh2AK8nUJ2pH41nZo9KesmIbx13\n94/3b7Mp6Q98Qo/dzNYkrUnS4uLiTRcuXDjwYOvoyba171vFdk+7z7Y+18Csin40XpDPPC0S7PvF\n+pmnrPsNh+cSCK9osLPccZ8yy86qFvuSweHxxfxcFhH78w1MUna5469Jereko5L+2cyecvdfCjKy\nBsTa9429+h01vlifyyJieb5pVWFWZVfFfEzSxwKNpXbDO06s635jX0EyanwPPPBAsOey7oCL4fmO\n5c0FaUpmVUxo43acGJeOhah+qwzHceMr9VxubEjHj8ufe043SHpa0okXvrCWgKviaOOgz38Mby5I\nV2uDPaUdp+yRRNXVX/AjnY0NaW1NunxZJmlR0l9L0vPP1/I6hd6eWZ7/lFtZaF5rgz21HadM9VvH\nm1jQI53jx6XLl6/50o9IOinpmzW9TiG3Z5bnP9a24H7MAcSrtcGewo4zyiw700HfxBrfYZ97buSX\nb5S0mMjrtN+sRUSMbcEB5gDi1tpgl+LecUaZdWc6yJvYLI8R/I1gcVEacQKbLS6Wv+8GpFpETJJS\nK7ONWh3sqSmzM417ExsO5YM+RiWV24MPXu2xX3X99b2vJyq1ImKa1FqZbUOw1yREVRt6Zwqx/ryS\nyu3OO3t/Hz/ea8ssLvZCffB1NC7Ho5CcEOw1CFXVht6Zzp49q+eff17uPvP688oqtzvvJMgjl9tR\nSE4I9hqErGpD7Uzdblfvf//7B9fVV6fTmWn9OZXbtRqfeAZEsNcixn7k5uamdnZ2JPWup3/PPfc0\n/mbThJBBzEoRxIJgr0GoqjZkCA2/2Rw7dqzU/aUodBCzUgSxINhrUqSqnRTcoUOIFkr4II7xyAzt\nRLBHYlpwV1ENztpCyaWPHDqIebNELAj2SEwL7rIhFCqMc+ojVxHEKc83IB8EeySmBXeZEAoZxrn1\nkQli5Ihgj0SR4J41hEKGMX3k6XJpVSFdBHtEqqoeQ4YxfeTJqmxV8YaBogj2yIXYmUOHMe2L8apq\nVeU0t4HqEewR63a7esMb3nB1Z3788cejPokoloqyyXFU1arKbW4D1SLYI3b27Fltb29Lkra3t3X2\n7Nlod+bQFeWs4dx0ZVtVq4q5DRwEwY6Z7Q/fkBVlmXCOobKt4uiIuQ0cBMEesWPHjunMmTP6wQ9+\noEOHDkV12v9w+N53332am5uTu5euKMuEc86VLXMbKIpgj9jggy9irNL2h+/29rYeeugh7e7uysx0\n3333NXZqPpUtINngsq11Wl5e9q2trdofF+Hsr9jn5ua0s7Nz9RLAhw4d0mc+85lGeuyhfh6IkZmd\nd/flabejYsdM9lfGCwsLevvb3371MsC7u7ule9tl2g5NT6ACTSPYE1Bl9VnmvofD995779Xu7q7m\n5+cr721PGncME6hAkwj2yFV9JmOo+15bW9OrX/3qWtof08ad8wQqUATBHrkqq8/Q913Xqo1p42YC\nFW1HsEeuyuqz6H3HNhG5sLAwdWklSwPRZgR75KqsPovcd2wTkd1uV/fff792d3c1Nzend73rXQQ4\nMIRgT0CV1ee0+45tInIwnr29PZmZLl261NhYZhXbERDyQ7BjotgmImMbz0HFdgSEPJUKdjP7c0m/\nKumKpK9Iepu7/3eIgSEOsU1Exjaeg4rtCAh5KnXmqZn9oqRPu/uOmf2ZJLn7H037Oc48RVtRsaOM\nWs48dfd/2fffz0l6S5n7A3KX+hEH0hCyx36PpA8FvL/WY5ItTyzFRNWmBruZPSrpJSO+ddzdP96/\nzXFJO5I2JtzPmqQ1SVpcXJxpsG3CITuAWU0Ndne/ddL3zexuSb8i6Raf0LB399OSTku9HvvBhtk+\nTLIBmNVcmR82s9sk/aGkN7n75TBDyl+329WpU6fU7XbH3mawrK/T6SS5rA9Ac8r22N8jaV7Sp8xM\nkj7n7r9VelQZK9piYZINwKzKror5yVADaYuDtFjaOsnGpDFQDmee1iz1MyerVsekMW8cyF2rg72J\nHTzHFkvI57HqSWNWG6ENWhvsTe7gObVYQj+PVR/RpLDaiCMKlNXaYE9hB09BFR/WUeURTeytMI4o\nEEJrgz32HTwVoZ/HqqvV2FthFBwIobXBHvsOnoqQz2Nd1WrMrTAKDoTQ2mCX4t7BUxLqeaRapeBA\nGK0OdsSFarWHggNlEeyIBtUqEAbBjqhQrQLllboIGAAgPgQ7AGSGYAeAzBDsAJAZgh0AMkOwA0Bm\nbMLHlFb3oGYXJV2o/YHDOSLpO00PIoBctkPKZ1vYjrjEth0vd/ej027USLCnzsy23H256XGUlct2\nSPlsC9sRl1S3g1YMAGSGYAeAzBDssznd9AACyWU7pHy2he2IS5LbQY8dADJDxQ4AmSHYJzCz28zs\ny2b2rJm9Y8T3583sQ/3vP2FmS/WPcroC23G3mV00s6f6f36ziXFOY2ZnzOzbZvbFMd83M/vL/nb+\nm5m9tu4xFlFgO1bN7Lv7Xo8/qXuMRZjZjWb2uJl9ycyeNrPfG3Gb6F+TgtuRxGtylbvzZ8QfSR1J\nX5H0E5IOS/qCpFcN3eZ3JL23/+87JH2o6XHPuB13S3pP02MtsC0/L+m1kr445vtvlPQJSSbpdZKe\naHrMM27HqqR/anqcBbbjpZJe2//3iyX9x4jfrehfk4LbkcRrMvhDxT7ezZKedfevuvsVSR+UdPvQ\nbW6X9Hf9f39Y0i1mZjWOsYgi25EEd/+spP+acJPbJZ31ns9J+jEze2k9oyuuwHYkwd2/5e5P9v/9\nfUnPSLph6GbRvyYFtyMpBPt4N0j6+r7/f0M//GJfvY2770j6rqSFWkZXXJHtkKQ39w+VP2xmN9Yz\ntOCKbmsKVszsC2b2CTP7maYHM02/DfkaSU8MfSup12TCdkgJvSYEOyTpHyUtufvPSvqU/v8oBM14\nUr1Tx39O0rsl/UPD45nIzF4k6SOS7nf37zU9nllN2Y6kXhOCfbxvStpfub6s/7WRtzGzF0j6UUmX\nahldcVO3w90vuft2/79/I+mmmsYWWpHXLHru/j13/5/+vx+RdMjMjjQ8rJHM7JB6Ybjh7h8dcZMk\nXpNp25HSayIR7JN8XtIrzewVZnZYvcnRh4du87Cku/r/foukT3t/piUiU7djqOf5JvV6jCl6WNKx\n/kqM10n6rrt/q+lBHZSZvWQwV2NmN6u3n8ZWMKg/xvdJesbdHxpzs+hfkyLbkcprMsCHWY/h7jtm\ndq+kT6q3suSMuz9tZn8qacvdH1bvl+HvzexZ9SbD7mhuxKMV3I7fNbM3SdpRbzvubmzAE5jZB9Rb\nnXDEzL4h6Z2SDkmSu79X0iPqrcJ4VtJlSW9rZqSTFdiOt0j6bTPbkfS/ku6IsGCQpNdLequkfzez\np/pf+2NJi1JSr0mR7UjlNZHEmacAkB1aMQCQGYIdADJDsANAZgh2AMgMwQ4AmSHYASAzBDsAZIZg\nB4DM/B969Tpb7jaORQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f226a04f748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Never a bad idea to visualize the dataz\n",
    "plt.plot(x[:,0], x[:,1], 'k.')\n",
    "for k in range(k_num):\n",
    "    plt.plot(true_mu[k, 0], true_mu[k, 1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global:\n",
      "\tinfo:\n",
      "[[[ 1.  0.]\n",
      "  [ 0.  1.]]\n",
      "\n",
      " [[ 1.  0.]\n",
      "  [ 0.  1.]]]\n",
      "\tmu:\n",
      "[[ 0.94498578  0.34365639]\n",
      " [ 0.4136796   0.04557085]]\n",
      "\tpi: [[ 0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "global_params = vb.ModelParamsDict('global')\n",
    "\n",
    "global_params.push_param(\n",
    "    vb.PosDefMatrixParamVector(name='info', length=k_num, matrix_size=d_num))\n",
    "global_params.push_param(\n",
    "    vb.ArrayParam(name='mu', shape=(k_num, d_num)))\n",
    "global_params.push_param(\n",
    "    vb.SimplexParam(name='pi', shape=(1, k_num)))\n",
    "\n",
    "local_params = \\\n",
    "    vb.SimplexParam(name='e_z', shape=(n_num, k_num),\n",
    "                    val=np.full(true_z.shape, 1. / k_num))\n",
    "\n",
    "single_local_params = \\\n",
    "    vb.SimplexParam(name='e_z', shape=(1, k_num), val=np.full((1, k_num), 1. / k_num))\n",
    "\n",
    "params = vb.ModelParamsDict('mixture model')\n",
    "params.push_param(global_params)\n",
    "params.push_param(local_params)\n",
    "\n",
    "true_init = False\n",
    "if true_init:\n",
    "    params['global']['info'].set(true_info)\n",
    "    params['global']['mu'].set(true_mu)\n",
    "    params['global']['pi'].set(true_pi)\n",
    "else:\n",
    "    params['global']['mu'].set(np.random.random(params['global']['mu'].shape()))\n",
    "    \n",
    "\n",
    "single_obs_params = vb.ModelParamsDict('mixture model single obs')\n",
    "single_obs_params.push_param(params['global'])\n",
    "single_obs_params.push_param(single_local_params)\n",
    "\n",
    "init_par_vec = params.get_free()\n",
    "\n",
    "print(params['global'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_params = vb.ModelParamsDict()\n",
    "prior_params.push_param(vb.VectorParam(name='mu_prior_mean', size=d_num, val=mu_prior_mean))\n",
    "prior_params.push_param(vb.PosDefMatrixParam(name='mu_prior_info', size=d_num, val=mu_prior_info))\n",
    "prior_params.push_param(vb.ScalarParam(name='alpha', val=2.0))\n",
    "prior_params.push_param(vb.ScalarParam(name='dof', val=d_num + 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def data_log_likelihood(mu, info, e_z, x, weights):\n",
    "    k_num = e_z.shape[1]\n",
    "    assert k_num == mu.shape[0]\n",
    "    assert k_num == info.shape[0]\n",
    "    log_lik = 0.0\n",
    "    # I would be interested to see how this could work without a loop.\n",
    "    e_z_weighted = weights * e_z\n",
    "    for k in range(k_num):\n",
    "        x_centered = x - np.expand_dims(mu[k, :], axis=0)\n",
    "        log_lik = log_lik - \\\n",
    "            0.5 * np.einsum('ni, ij, nj, n', \\\n",
    "                            x_centered, info[k, :, :], x_centered, e_z_weighted[:, k])\n",
    "        sign, logdet = np.linalg.slogdet(info[k, :, :])\n",
    "        assert sign > 0\n",
    "        log_lik = log_lik + 0.5 * logdet * np.sum(e_z_weighted[:, k])\n",
    "    return log_lik\n",
    "\n",
    "def indicator_log_likelihood(e_z, pi):\n",
    "    return np.sum(np.matmul(e_z, np.log(pi.T)))\n",
    "\n",
    "def mu_prior(mu, mu_prior_mean, mu_prior_info):\n",
    "    k_num = mu.shape[0]\n",
    "    d_num = len(mu_prior_mean)\n",
    "    assert mu.shape[1] == d_num\n",
    "    assert mu_prior_info.shape[0] == d_num\n",
    "    assert mu_prior_info.shape[1] == d_num\n",
    "    mu_prior_val = 0.0\n",
    "    for k in range(k_num):\n",
    "        mu_centered = mu[k, :] - mu_prior_mean\n",
    "        mu_prior_val += -0.5 * np.matmul(np.matmul(mu_centered, mu_prior_info), mu_centered)\n",
    "    return mu_prior_val\n",
    "    \n",
    "def pi_prior(pi, alpha):\n",
    "    return np.sum(alpha * np.log(pi))\n",
    "\n",
    "def info_prior(info, dof):\n",
    "    k_num = info.shape[0]\n",
    "    d_num = info.shape[1]\n",
    "    assert d_num == info.shape[2]\n",
    "    assert dof > d_num - 1\n",
    "    # Not a complete Wishart prior\n",
    "    # TODO: cache the log determinants.\n",
    "    info_prior_val = 0.0\n",
    "    for k in range(k_num):\n",
    "        sign, logdet = np.linalg.slogdet(info[k, :, :])\n",
    "        info_prior_val += 0.5 * (dof - d_num - 1) * logdet\n",
    "    return info_prior_val\n",
    "\n",
    "def multinoulli_entropy(e_z):\n",
    "    return -1 * np.sum(e_z * np.log(e_z))\n",
    "\n",
    "def get_sparse_multinoulli_entropy_hessian(e_z_vec):\n",
    "    k = len(e_z_vec)\n",
    "    vals = -1. / e_z_vec\n",
    "    return sp.sparse.csr_matrix((vals, ((range(k)), (range(k)))), (k, k))\n",
    "\n",
    "weights = np.full((n_num, 1), 1.0)\n",
    "e_z = params['e_z'].get()\n",
    "data_log_likelihood(true_mu, true_info, e_z, x, weights)\n",
    "indicator_log_likelihood(e_z, true_pi)\n",
    "mu_prior(true_mu, mu_prior_mean, mu_prior_info)\n",
    "pi_prior(true_pi, 2.0)\n",
    "info_prior(true_info, d_num + 2)\n",
    "multinoulli_entropy(e_z)\n",
    "\n",
    "get_multinoulli_entropy_hessian = autograd.hessian(multinoulli_entropy)\n",
    "e_z0 = e_z[0, :]\n",
    "\n",
    "print(np.max(np.abs(\n",
    "    get_multinoulli_entropy_hessian(e_z0) - get_sparse_multinoulli_entropy_hessian(e_z0).toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Objective(object):\n",
    "    def __init__(self, x, params, prior_params):\n",
    "        self.x = x\n",
    "        self.params = deepcopy(params)\n",
    "        self.prior_params = deepcopy(prior_params)\n",
    "        self.weights = np.full((x.shape[0], 1), 1.0)\n",
    "\n",
    "        # Autograd derivatives\n",
    "        self.kl_grad = autograd.grad(self.kl_wrapper)\n",
    "        self.kl_hessian = autograd.hessian(self.kl_wrapper)\n",
    "        self.kl_hvp = autograd.hessian_vector_product(self.kl_wrapper)\n",
    "\n",
    "        self.global_kl_grad = autograd.grad(self.global_kl_wrapper)\n",
    "        self.global_kl_hvp = autograd.hessian_vector_product(self.global_kl_wrapper)\n",
    "        self.global_kl_hessian = autograd.hessian(self.global_kl_wrapper)\n",
    "\n",
    "        self.get_z_nat_params = autograd.grad(self.expected_log_likelihood, argnum=0)\n",
    "\n",
    "        self.get_moment_jacobian = autograd.jacobian(self.get_interesting_moments)\n",
    "        \n",
    "        self.get_global_vector_jacobian = autograd.jacobian(self.vector_kl_wrapper, argnum=0)\n",
    "        self.get_global_vector_hessian = autograd.hessian(self.vector_kl_wrapper, argnum=0)\n",
    "        self.get_global_local_vector_hessian = \\\n",
    "            autograd.jacobian(self.get_global_vector_jacobian, argnum=1)\n",
    "\n",
    "        self.get_vector_jacobian = autograd.jacobian(self.full_vector_kl_wrapper)\n",
    "        self.get_vector_hessian = autograd.hessian(self.full_vector_kl_wrapper)\n",
    "\n",
    "            \n",
    "    def expected_log_likelihood(self, e_z, mu, info, pi, weights):\n",
    "        elbo = 0.0\n",
    "\n",
    "        # Data:\n",
    "        elbo += data_log_likelihood(mu, info, e_z, self.x, weights)\n",
    "        elbo += indicator_log_likelihood(e_z, pi)\n",
    "        \n",
    "        # Priors:\n",
    "        mu_prior_mean = self.prior_params['mu_prior_mean'].get()\n",
    "        mu_prior_info = self.prior_params['mu_prior_info'].get()\n",
    "        elbo += mu_prior(mu, mu_prior_mean, mu_prior_info)\n",
    "        elbo += pi_prior(pi, self.prior_params['alpha'].get())\n",
    "        elbo += info_prior(info, self.prior_params['dof'].get())\n",
    "\n",
    "        return elbo\n",
    "    \n",
    "    def optimize_z(self):\n",
    "        # Take a CAVI step on Z.\n",
    "        info = self.params['global']['info'].get()\n",
    "        mu = self.params['global']['mu'].get()\n",
    "        pi = self.params['global']['pi'].get()\n",
    "        e_z = self.params['e_z'].get()\n",
    "\n",
    "        natural_parameters = obj.get_z_nat_params(e_z, mu, info, pi, self.weights)\n",
    "        z_logsumexp = np.expand_dims(sp.misc.logsumexp(natural_parameters, 1), axis=1)\n",
    "        e_z = np.exp(natural_parameters - z_logsumexp)\n",
    "        self.params['e_z'].set(e_z)\n",
    "    \n",
    "    def kl(self, include_local_entropy=True):\n",
    "        info = self.params['global']['info'].get()\n",
    "        mu = self.params['global']['mu'].get()\n",
    "        pi = self.params['global']['pi'].get()\n",
    "        e_z = self.params['e_z'].get()\n",
    "\n",
    "        elbo = self.expected_log_likelihood(e_z, mu, info, pi, self.weights)\n",
    "        \n",
    "        if include_local_entropy:\n",
    "            elbo += multinoulli_entropy(e_z)\n",
    "        \n",
    "        return -1 * elbo\n",
    "\n",
    "    def kl_wrapper(self, free_params, verbose=False):\n",
    "        self.params.set_free(free_params)\n",
    "        kl = self.kl()\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def global_kl_wrapper(self, global_free_params, verbose=False):\n",
    "        self.params['global'].set_free(global_free_params)\n",
    "        kl = self.kl(include_local_entropy=False)\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def vector_kl_wrapper(self, global_vec_params, local_vec_params,\n",
    "                          verbose=False, include_local_entropy=True):\n",
    "        self.params['global'].set_vector(global_vec_params)\n",
    "        self.params['e_z'].set_vector(local_vec_params)\n",
    "        kl = self.kl(include_local_entropy=include_local_entropy)\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def full_vector_kl_wrapper(self, vec_params, \n",
    "                               verbose=False, include_local_entropy=True):\n",
    "        self.params.set_vector(vec_params)\n",
    "        kl = self.kl(include_local_entropy=include_local_entropy)\n",
    "        if verbose:\n",
    "            print(kl)\n",
    "        return kl\n",
    "\n",
    "    def get_sparse_local_vector_hessian(self, local_vec):\n",
    "        self.params['e_z'].set_vector(local_vec)\n",
    "        e_z = self.params['e_z'].get()\n",
    "        hess_vals = []\n",
    "        hess_rows = []\n",
    "        # This is the Hessian of the negative entropy, which enters the KL divergence.\n",
    "        for row in range(e_z.shape[0]):\n",
    "            row_inds = self.params['e_z'].get_vector_indices(row)\n",
    "            for col in range(e_z.shape[1]):\n",
    "                hess_vals.append(1. / e_z[row, col])\n",
    "                hess_rows.append(row_inds[col])\n",
    "        return sp.sparse.csr_matrix((hess_vals, (hess_rows, hess_rows)),\n",
    "                                    (len(local_vec), len(local_vec)))\n",
    "                \n",
    "    def get_sparse_vector_hessian(self, vec_params):\n",
    "        self.params.set_vector(vec_params)\n",
    "        global_vec = obj.params['global'].get_vector()\n",
    "        local_vec = obj.params['e_z'].get_vector()\n",
    "        global_vec_hess = obj.get_global_vector_hessian(global_vec, local_vec)\n",
    "        global_local_vec_hess = obj.get_global_local_vector_hessian(global_vec, local_vec)\n",
    "        local_vector_hessian = self.get_sparse_local_vector_hessian(local_vec)\n",
    "        return sp.sparse.bmat([ [global_vec_hess,         global_local_vec_hess],\n",
    "                                [global_local_vec_hess.T, local_vector_hessian]])\n",
    "    \n",
    "    def get_sparse_hessian(self, free_params):\n",
    "        self.params.set_free(free_params)\n",
    "        vec_par = self.params.get_vector()\n",
    "        sparse_vector_hessian = obj.get_sparse_vector_hessian(vec_par)\n",
    "        vector_jac = obj.get_vector_jacobian(vec_par)\n",
    "        return convert_vector_to_free_hessian(\n",
    "            self.params, free_params, vector_jac, vector_hessian)\n",
    "\n",
    "    def get_interesting_moments(self, free_params):\n",
    "        self.params.set_free(free_params)\n",
    "        return self.params['global']['mu'].get_vector()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian:  0.7005712985992432\n",
      "Hessian vector product 0.02076125144958496\n"
     ]
    }
   ],
   "source": [
    "from VariationalBayes.Parameters import convert_vector_to_free_hessian\n",
    "\n",
    "obj = Objective(x, params, prior_params)\n",
    "obj.optimize_z()\n",
    "\n",
    "free_par = params.get_free()\n",
    "vec_par = params.get_vector()\n",
    "\n",
    "global_free_par = params['global'].get_free()\n",
    "obj.kl_wrapper(free_par)\n",
    "\n",
    "grad = obj.kl_grad(free_par)\n",
    "\n",
    "hvp_time = time.time()\n",
    "hvp = obj.kl_hvp(free_par, grad)\n",
    "hvp_time = time.time() - hvp_time\n",
    "\n",
    "grad = obj.global_kl_grad(global_free_par)\n",
    "hvp = obj.global_kl_hvp(global_free_par, grad)\n",
    "\n",
    "# Not as slow!  You can ignore the autograd warning.\n",
    "sparse_hess_time = time.time()\n",
    "sparse_hessian = obj.get_sparse_hessian(free_par)\n",
    "sparse_hess_time = time.time() - sparse_hess_time\n",
    "\n",
    "\n",
    "print('Hessian: ', sparse_hess_time)\n",
    "print('Hessian vector product', hvp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Compare the full and sparse Hessians\n",
    "    get_vector_hessian = autograd.hessian(obj.full_vector_kl_wrapper)\n",
    "    hessian = obj.kl_hessian(free_par) # Slow\n",
    "    vector_hessian = get_vector_hessian(vec_par)  # Slow\n",
    "\n",
    "    # The slow full Hessian and sparse Hessian agree.\n",
    "    plt.matshow(sparse_hessian != 0)\n",
    "    np.max(np.abs(hessian - sparse_hessian))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kl: 57.22894450979601\t\tkl_diff = -73.26082248004457\t\tdiff = 2.99315870536525\n",
      " kl: 55.42022129872055\t\tkl_diff = -1.8087232110754599\t\tdiff = 0.1948069355314619\n",
      " kl: 52.002813548275086\t\tkl_diff = -3.417407750445463\t\tdiff = 0.3109368051645385\n",
      " kl: 45.95163884648977\t\tkl_diff = -6.051174701785314\t\tdiff = 0.6720873677798223\n",
      " kl: 40.24096531944176\t\tkl_diff = -5.710673527048009\t\tdiff = 1.121744826490196\n",
      " kl: 38.15924732409621\t\tkl_diff = -2.0817179953455565\t\tdiff = 0.7289031064870692\n",
      " kl: 37.44081722013852\t\tkl_diff = -0.7184301039576866\t\tdiff = 0.21403496112660747\n",
      " kl: 37.06808851954897\t\tkl_diff = -0.37272870058954766\t\tdiff = 0.08213906636051899\n",
      " kl: 36.808464514287095\t\tkl_diff = -0.2596240052618768\t\tdiff = 0.05581909875666813\n",
      " kl: 36.59298342086929\t\tkl_diff = -0.2154810934178073\t\tdiff = 0.051093336451820015\n",
      " kl: 36.39790535402318\t\tkl_diff = -0.19507806684610784\t\tdiff = 0.05397151175781634\n",
      " kl: 36.21286946936419\t\tkl_diff = -0.18503588465898702\t\tdiff = 0.050818158053584916\n",
      " kl: 36.03281210347321\t\tkl_diff = -0.1800573658909812\t\tdiff = 0.046788082238890416\n",
      " kl: 35.855194196770725\t\tkl_diff = -0.177617906702487\t\tdiff = 0.05300827353464754\n",
      " kl: 35.68017876652954\t\tkl_diff = -0.1750154302411886\t\tdiff = 0.05926494291951756\n",
      " kl: 35.5096966767776\t\tkl_diff = -0.17048208975193546\t\tdiff = 0.06595799547394443\n",
      " kl: 35.34783218226754\t\tkl_diff = -0.16186449451006268\t\tdiff = 0.07203807768699555\n",
      " kl: 35.200203803612986\t\tkl_diff = -0.14762837865455225\t\tdiff = 0.07661168954815634\n",
      " kl: 35.0725785293857\t\tkl_diff = -0.12762527422728454\t\tdiff = 0.07873313859729447\n",
      " kl: 34.9691765423738\t\tkl_diff = -0.10340198701189962\t\tdiff = 0.07744491643324958\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Perform EM.\n",
    "\n",
    "obj.params.set_free(init_par_vec)\n",
    "obj.optimize_z()\n",
    "global_param_vec = obj.params['global'].get_vector()\n",
    "kl = obj.kl()\n",
    "\n",
    "for step in range(20):\n",
    "    global_free_par = obj.params['global'].get_free()\n",
    "\n",
    "    # Different choices for the M step:\n",
    "    global_vb_opt = optimize.minimize(\n",
    "       lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "       x0=global_free_par, jac=obj.global_kl_grad, hessp=obj.global_kl_hvp,\n",
    "       method='trust-ncg', options={'maxiter': 50, 'gtol': 1e-2})\n",
    "    #global_vb_opt = optimize.minimize(\n",
    "    #    lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "    #    x0=global_free_par, jac=obj.global_kl_grad, hess=obj.global_kl_hessian,\n",
    "    #    method='trust-ncg', options={'maxiter': 50})\n",
    "    #global_vb_opt = optimize.minimize(\n",
    "    #   lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "    #   x0=global_free_par, method='nelder-mead', options={'maxiter': 500})\n",
    "    #global_vb_opt = optimize.minimize(\n",
    "    #   lambda par: obj.global_kl_wrapper(par, verbose=False),\n",
    "    #  x0=global_free_par, method='bfgs', options={'maxiter': 50})\n",
    "    obj.params['global'].set_free(global_vb_opt.x)\n",
    "\n",
    "    # E-step:\n",
    "    obj.optimize_z()\n",
    "\n",
    "    new_global_param_vec = obj.params['global'].get_vector()\n",
    "    diff = np.max(np.abs(new_global_param_vec - global_param_vec))\n",
    "    global_param_vec = deepcopy(new_global_param_vec)\n",
    "    \n",
    "    new_kl = obj.kl()\n",
    "    kl_diff = new_kl - kl\n",
    "    kl = new_kl\n",
    "    print(' kl: {}\\t\\tkl_diff = {}\\t\\tdiff = {}'.format(kl, kl_diff, diff))\n",
    "    if diff < 1e-8:\n",
    "        break\n",
    "\n",
    "em_free_par = obj.params.get_free()\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.9691765424\n",
      "34.9310780827\n",
      "34.9278961983\n",
      "34.9262368319\n",
      "34.8714487497\n",
      "34.8687572864\n",
      "34.8681604614\n",
      "34.8163373126\n",
      "34.815199034\n",
      "34.8062821346\n",
      "34.7760949797\n",
      "34.7758112051\n",
      "34.7725947073\n",
      "34.757357148\n",
      "34.7572854734\n",
      "34.7523860287\n",
      "34.7522958929\n",
      "34.7509068633\n",
      "34.750904853\n",
      "34.750354722\n",
      "34.7503025341\n",
      "34.7504798583\n",
      "34.7502563509\n",
      "34.7502562358\n",
      "34.7502957128\n",
      "34.7502475793\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Finish with one joint Newton optimization to ensure global optimality.\n",
    "vb_opt_cg = optimize.minimize(\n",
    "    lambda par: obj.kl_wrapper(par, verbose=True),\n",
    "    x0=em_free_par, jac=obj.kl_grad, hessp=obj.kl_hvp,\n",
    "    method='trust-ncg', options={'maxiter': 50})\n",
    "\n",
    "print('Done')\n",
    "obj.params.set_free(vb_opt_cg.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "(111, 111)\n",
      "(111,)\n",
      "(111, 1)\n"
     ]
    }
   ],
   "source": [
    "def jac_trans(free_par):\n",
    "    return np.expand_dims(obj.kl_grad(em_free_par), axis=1)\n",
    "\n",
    "print(type(obj.get_sparse_hessian(em_free_par)))\n",
    "print(obj.get_sparse_hessian(em_free_par).shape)\n",
    "print(obj.kl_grad(em_free_par).shape)\n",
    "print(jac_trans(em_free_par).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (111,1) and (111,1) not aligned: 1 (dim 1) != 111 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-84593c2bbf50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mpar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mem_free_par\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjac_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sparse_hessian\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     method='trust-ncg', options={'maxiter': 50})\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvb_opt_hess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trust-ncg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         return _minimize_trust_ncg(fun, x0, args, jac, hess, hessp,\n\u001b[0;32m--> 464\u001b[0;31m                                    callback=callback, **options)\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown solver %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/_trustregion_ncg.py\u001b[0m in \u001b[0;36m_minimize_trust_ncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, **trust_region_options)\u001b[0m\n\u001b[1;32m     39\u001b[0m     return _minimize_trust_region(fun, x0, args=args, jac=jac, hess=hess,\n\u001b[1;32m     40\u001b[0m                                   \u001b[0mhessp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhessp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubproblem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCGSteihaugSubproblem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                   **trust_region_options)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/_trustregion.py\u001b[0m in \u001b[0;36m_minimize_trust_region\u001b[0;34m(fun, x0, args, jac, hess, hessp, subproblem, initial_trust_radius, max_trust_radius, eta, gtol, maxiter, disp, return_all, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# has reached the trust region boundary or not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhits_boundary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrust_radius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mwarnflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/_trustregion_ncg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, trust_radius)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# do an iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mBd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdBd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdBd\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Look at the two boundary points.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (111,1) and (111,1) not aligned: 1 (dim 1) != 111 (dim 0)"
     ]
    }
   ],
   "source": [
    "vb_opt_hess = optimize.minimize(\n",
    "    lambda par: obj.kl_wrapper(par, verbose=True),\n",
    "    x0=em_free_par, jac=jac_trans, hess=obj.get_sparse_hessian,\n",
    "    method='trust-ncg', options={'maxiter': 50})\n",
    "\n",
    "print(obj.kl_wrapper(vb_opt_hess.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGYIdADJDsANAZgh2AMgMwQ4Amfl/A4SJITMYzcQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f226a07e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that the solution looks sensible.\n",
    "mu_fit = obj.params['global']['mu'].get()\n",
    "plt.plot(x[:,0], x[:,1], 'k.')\n",
    "for k in range(k_num):\n",
    "    plt.plot(mu_fit[k, 0], mu_fit[k, 1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is really slow for even problems of moderate size.  You'd want to build this up by hand if\n",
    "# you actualy needed it.\n",
    "\n",
    "# hess_time = time.time()\n",
    "# kl_hessian = obj.kl_hessian(obj.params.get_free())\n",
    "# hess_time = time.time() - hess_time\n",
    "# print(hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the sensitivity operator with conjugate gradient to avoid constructing the Hessian.\n",
    "\n",
    "moment_jac = obj.get_moment_jacobian(vb_opt.x)\n",
    "sensitivity_operator = np.full_like(moment_jac, float('nan'))\n",
    "free_param_size = len(vb_opt.x)\n",
    "\n",
    "KLHessVecProdLO = LinearOperator((free_param_size, free_param_size),\n",
    "                                 lambda vec: obj.kl_hvp(vb_opt.x, vec))\n",
    "for ind in range(sensitivity_operator.shape[0]):\n",
    "    cg_res, info = sp.sparse.linalg.cg(KLHessVecProdLO, moment_jac[ind, :].T)\n",
    "    sensitivity_operator[ind, :] = cg_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj.params.set_free(vb_opt.x)\n",
    "def kl_weight_fun(weights):\n",
    "    obj.weights = weights\n",
    "    return obj.kl()\n",
    "\n",
    "default_weights = np.full((n_num, 1), 1.0)\n",
    "get_kl_weight_grad = autograd.grad(kl_weight_fun)\n",
    "kl_weight_grad = get_kl_weight_grad(default_weights)\n",
    "mu_weight_sens = np.matmul(sensitivity_operator, kl_weight_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
