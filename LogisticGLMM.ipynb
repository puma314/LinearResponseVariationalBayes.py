{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "from VariationalBayes.NormalParams import MVNParam, UVNParam, UVNParamVector\n",
    "from VariationalBayes.GammaParams import GammaParam\n",
    "from VariationalBayes.ExponentialFamilies import \\\n",
    "    UnivariateNormalEntropy, MultivariateNormalEntropy, GammaEntropy, \\\n",
    "    MVNPrior, UVNPrior, GammaPrior\n",
    "\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as asp\n",
    "import scipy as sp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'y_group', u'mu_prior_var', u'mu_prior_t', u'mu_prior_var_c', u'K', u'beta_prior_var', u'tau_prior_beta', u'N', u'mu_prior_mean_c', u'mu_prior_epsilon', u'mu_prior_mean', u'y', u'x', u'NG', u'beta_prior_mean', u'tau_prior_alpha']\n",
      "10000\n",
      "0.4668\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "simulate_data = False\n",
    "prior_par = ModelParamsDict('Prior Parameters')\n",
    "\n",
    "if not simulate_data:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    analysis_name = 'simulated_data_large'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    json_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    stan_dat = json_dat['stan_dat']\n",
    "    vp_base = json_dat['vp_base']\n",
    "\n",
    "    print stan_dat.keys()\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "    beta_prior_info = np.linalg.inv(np.array(stan_dat['beta_prior_var']))\n",
    "    prior_par.push_param(PosDefMatrixParam('beta_prior_info', K, val=beta_prior_info))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "    prior_par.push_param(ScalarParam('mu_prior_info', val=1 / stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "    prior_par.push_param(ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "    def Logistic(u):\n",
    "        return np.exp(u) / (1 + np.exp(u))\n",
    "\n",
    "    NObs = NG * N\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "    true_u = np.random.normal(true_mu, 1 / np.sqrt(true_tau), NG)\n",
    "\n",
    "    x_mat = np.random.random(K * NObs).reshape(NObs, K) - 0.5\n",
    "    y_g_vec = [ g for g in range(NG) for n in range(N) ]\n",
    "    true_rho = Logistic(np.matmul(x_mat, true_beta) + true_u[y_g_vec])\n",
    "    y_vec = np.random.random(NObs) < true_rho\n",
    "    \n",
    "    prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.zeros(K)))\n",
    "    prior_par.push_param(PosDefMatrixParam('beta_prior_info', K, val=0.01 * np.eye(K)))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('mu_prior_mean', val=0))\n",
    "    prior_par.push_param(ScalarParam('mu_prior_info', val=0.5))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('tau_prior_alpha', val=3.0))\n",
    "    prior_par.push_param(ScalarParam('tau_prior_beta', val=10.0))\n",
    "\n",
    "print N * NG\n",
    "print np.mean(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "glmm_par.push_param(UVNParam('mu', min_info=vp_base['mu_info_min'][0]))\n",
    "glmm_par.push_param(GammaParam('tau',\n",
    "                               min_shape=vp_base['tau_alpha_min'][0],\n",
    "                               min_rate=vp_base['tau_beta_min'][0]))\n",
    "glmm_par.push_param(MVNParam('beta', K, min_info=vp_base['beta_diag_min'][0]))\n",
    "glmm_par.push_param(UVNParamVector('u', NG, min_info=vp_base['u_info_min'][0]))\n",
    "\n",
    "# Initialize with ADVI.  Don't forget to add the ADVI computation time to your final VB time!\n",
    "advi_fit = json_dat['advi_results']\n",
    "glmm_par['mu'].mean.set(advi_fit['mu_mean'][0])\n",
    "glmm_par['mu'].info.set(1 / advi_fit['mu_var'][0])\n",
    "\n",
    "tau_mean = advi_fit['tau_mean'][0]\n",
    "tau_var = advi_fit['tau_var'][0]\n",
    "glmm_par['tau'].shape.set((tau_mean ** 2) / tau_var)\n",
    "glmm_par['tau'].rate.set(tau_var / tau_mean)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.array(advi_fit['beta_mean']))\n",
    "glmm_par['beta'].info.set(np.array(advi_fit['beta_info']))\n",
    "\n",
    "glmm_par['u'].mean.set(np.array(advi_fit['u_mean']))\n",
    "glmm_par['u'].info.set(1 / np.array(advi_fit['u_var']))\n",
    "\n",
    "free_par_vec = glmm_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print glmm_par['tau'].shape._ScalarParam__lb\n",
    "print glmm_par['u'].info._VectorParam__lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "\n",
    "moment_par = ModelParamsDict('Moment Parameters')\n",
    "moment_par.push_param(VectorParam('e_beta', K))\n",
    "moment_par.push_param(PosDefMatrixParam('e_beta_outer', K))\n",
    "moment_par.push_param(ScalarParam('e_mu'))\n",
    "moment_par.push_param(ScalarParam('e_mu2'))\n",
    "moment_par.push_param(ScalarParam('e_tau'))\n",
    "moment_par.push_param(ScalarParam('e_log_tau'))\n",
    "moment_par.push_param(VectorParam('e_u', NG))\n",
    "moment_par.push_param(VectorParam('e_u2', NG))\n",
    "\n",
    "def set_moments(glmm_par, moment_par):\n",
    "    moment_par['e_beta'].set(glmm_par['beta'].e())\n",
    "    moment_par['e_beta_outer'].set(glmm_par['beta'].e_outer())\n",
    "    moment_par['e_mu'].set(glmm_par['mu'].e())\n",
    "    moment_par['e_mu2'].set(glmm_par['mu'].e_outer())\n",
    "    moment_par['e_tau'].set(glmm_par['tau'].e())\n",
    "    moment_par['e_log_tau'].set(glmm_par['tau'].e_log())\n",
    "    moment_par['e_u'].set(glmm_par['u'].e())\n",
    "    moment_par['e_u2'].set((glmm_par['u'].e_outer()))\n",
    "    \n",
    "set_moments(glmm_par, moment_par)\n",
    "\n",
    "# Moment indices.\n",
    "moment_indices = copy.deepcopy(moment_par)\n",
    "moment_indices.set_vector(1 + np.array(range(moment_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_combined_parameters(combined_free_par_vec, glmm_par, prior_par):\n",
    "    assert glmm_par.free_size() + prior_par.vector_size() == len(combined_free_par_vec) \n",
    "    glmm_par.set_free(combined_free_par_vec[0:glmm_par.free_size()])\n",
    "    prior_par.set_vector(combined_free_par_vec[glmm_par.free_size():])\n",
    "\n",
    "    \n",
    "def encode_combined_parameters(glmm_par, prior_par):\n",
    "    combined_free_par_vec = np.full(glmm_par.free_size() + prior_par.vector_size(), float('nan'))\n",
    "    combined_free_par_vec[0:glmm_par.free_size()] = glmm_par.get_free()\n",
    "    combined_free_par_vec[glmm_par.free_size():] = prior_par.get_vector()\n",
    "    return combined_free_par_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609255242.588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5789972.763644468"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inf_like(val):\n",
    "    return 1 / np.zeros_like(1, val)[0]\n",
    "\n",
    "\n",
    "def ELogPrior(prior_par, glmm_par_elbo):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "    beta_prior_info = prior_par['beta_prior_info'].get()\n",
    "    beta_prior_mean = prior_par['beta_prior_mean'].get()\n",
    "    e_log_p_beta = MVNPrior(beta_prior_mean, beta_prior_info, e_beta, cov_beta)\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "    e_log_p_mu = UVNPrior(prior_par['mu_prior_mean'].get(), prior_par['mu_prior_info'].get(), e_mu, var_mu) \n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    tau_prior_shape = prior_par['tau_prior_alpha'].get()\n",
    "    tau_prior_rate = prior_par['tau_prior_beta'].get()\n",
    "    e_log_p_tau = GammaPrior(tau_prior_shape, tau_prior_rate, e_tau, e_log_tau)\n",
    "    \n",
    "    return  e_log_p_beta + e_log_p_mu + e_log_p_tau\n",
    "           \n",
    "\n",
    "def DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta, e_u, var_u, std_draws):\n",
    "    z_mean = e_u + np.matmul(x_mat, e_beta)\n",
    "    z_sd = np.sqrt(var_u + np.einsum('nk,kj,nj->n', x_mat, cov_beta, x_mat))\n",
    "    z = np.einsum('i,j->ij', z_sd, std_draws) + np.expand_dims(z_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # p = exp(z) / (1 + exp(z))\n",
    "    # log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "    logit_term = -np.sum(np.log1p(np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * z_mean)\n",
    "    return y_term + logit_term\n",
    "\n",
    "\n",
    "def RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau):\n",
    "    return -0.5 * e_tau * np.sum(((e_mu - e_u) ** 2) + var_mu + var_u) + 0.5 * e_log_tau * len(e_u)\n",
    "\n",
    "    \n",
    "def Elbo(y_vec, x_mat, y_g_vec, glmm_par_elbo, std_draws, prior_par):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "    \n",
    "    e_u = glmm_par_elbo['u'].mean.get()\n",
    "    info_u = glmm_par_elbo['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "    \n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "        \n",
    "    ll = \\\n",
    "        DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta,\n",
    "                          e_u[y_g_vec], var_u[y_g_vec], std_draws) + \\\n",
    "        RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)\n",
    "    if np.isnan(ll):\n",
    "        return -np.inf\n",
    "\n",
    "    e_log_prior = ELogPrior(prior_par, glmm_par_elbo)\n",
    "    if np.isnan(e_log_prior):\n",
    "        return -np.inf\n",
    "    \n",
    "    tau_shape = glmm_par_elbo['tau'].shape.get()\n",
    "    tau_rate = glmm_par_elbo['tau'].rate.get()\n",
    "    entropy = \\\n",
    "        UnivariateNormalEntropy(info_mu) + \\\n",
    "        MultivariateNormalEntropy(info_beta) + \\\n",
    "        UnivariateNormalEntropy(info_u) + \\\n",
    "        GammaEntropy(tau_shape, tau_rate)\n",
    "\n",
    "    return ll[0] + e_log_prior[0] + entropy\n",
    "\n",
    "\n",
    "class KLWrapper(object):\n",
    "    def __init__(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = sp.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.y_g_vec,\n",
    "                   self.__glmm_par_ad, self.std_draws, self.__prior_par_ad)\n",
    "        if verbose: print kl\n",
    "            \n",
    "        # TODO: this is returning an array when it should be a scalar.\n",
    "        return kl\n",
    "    \n",
    "    def ExpectedLogPrior(self, combined_free_par_vec):\n",
    "        # Encode the glmm parameters first and the prior second.\n",
    "        decode_combined_parameters(combined_free_par_vec, self.__glmm_par_ad, self.__prior_par_ad)\n",
    "        e_log_prior = ELogPrior(self.__prior_par_ad, self.__glmm_par_ad)\n",
    "        return e_log_prior[0]\n",
    "        \n",
    "\n",
    "class MomentWrapper(object):\n",
    "    def __init__(self, glmm_par, moment_par):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__moment_par = copy.deepcopy(moment_par)\n",
    "\n",
    "    # Return a posterior moment of interest as a function of unconstrained parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par.get_vector()\n",
    "    \n",
    "    def GetMomentParameters(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par\n",
    "\n",
    "\n",
    "kl_wrapper = KLWrapper(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "\n",
    "moment_wrapper = MomentWrapper(glmm_par, moment_par)\n",
    "MomentJacobian = jacobian(moment_wrapper.GetMoments)\n",
    "\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par, prior_par)\n",
    "PriorHess = hessian(kl_wrapper.ExpectedLogPrior)\n",
    "kl_wrapper.ExpectedLogPrior(combined_free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.0206583976746\n",
      "Grad time:\n",
      "0.0409413814545\n",
      "Hessian vector product time:\n",
      "0.0825641870499\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "# print 'Moment jacobian time:'\n",
    "# print timeit.timeit(lambda: MomentJacobian(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# time_num = 1\n",
    "# print 'Prior Hessian time:'\n",
    "# print timeit.timeit(lambda: PriorHess(combined_free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region\n",
      "609255242.588\n",
      "224014466.07\n",
      "82383044.6089\n",
      "30300338.5125\n",
      "11144915.9478\n",
      "4099215.3155\n",
      "1507637.69336\n",
      "554462.411007\n",
      "203982.242169\n",
      "75213.2779358\n",
      "28006.9748586\n",
      "10807.8479768\n",
      "4650.26205266\n",
      "2554.40273042\n",
      "1938.07732647\n",
      "1812.43223317\n",
      "1730.34395129\n",
      "1681.70941656\n",
      "1660.32887607\n",
      "1649.22693388\n",
      "1644.78379579\n",
      "1644.31936791\n",
      "1644.26495942\n",
      "1640.38679467\n",
      "1640.33164449\n",
      "1639.97406248\n",
      "1639.24330499\n",
      "1639.24246142\n",
      "1639.23397031\n",
      "1639.07527383\n",
      "1639.06804101\n",
      "1639.05499256\n",
      "1639.05381341\n",
      "1639.05376167\n",
      "1639.05376148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1639.053761\n",
      "         Iterations: 34\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 0\n",
      "Done.\n",
      "0.587432952722\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class OptimizationPath(object):\n",
    "    def __init__(self):\n",
    "        self.x_history = []\n",
    "        pass\n",
    "    \n",
    "    def save(self, x):\n",
    "        self.x_history.append(x)\n",
    "\n",
    "bfgs_path = OptimizationPath()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "\n",
    "# Optimize.\n",
    "vb_time = time.time()\n",
    "# print 'Running BFGS'\n",
    "# vb_opt_bfgs = optimize.minimize(\n",
    "#     lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "#     method='bfgs', jac=KLGrad, tol=1e-2, callback=bfgs_path.save,\n",
    "#     options={'maxiter': 100, 'gtol': 1e-2, 'disp': True})\n",
    "\n",
    "trust_path = OptimizationPath()\n",
    "print 'Running Newton Trust Region'\n",
    "# trust_init = copy.deepcopy(vb_opt_bfgs.x)\n",
    "trust_init = copy.deepcopy(init_par_vec)\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    trust_init, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd,\n",
    "    tol=1e-6, callback=trust_path.save, options={'maxiter': 100, 'disp': True, 'gtol': 1e-6 })\n",
    "\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(vb_opt.x)\n",
    "\n",
    "print 'Done.'\n",
    "\n",
    "print vb_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Iteration 0\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 793.03053848]\n",
      "tau_rate: [ 0.00111538]\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 481.18719791]\n",
      "tau_rate: [ 0.00183676]\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 292.03452586]\n",
      "tau_rate: [ 0.00302497]\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 177.26119529]\n",
      "tau_rate: [ 0.00498212]\n",
      "\n",
      "Iteration 4\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 107.6048248]\n",
      "tau_rate: [ 0.00820574]\n",
      "\n",
      "Iteration 5\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 65.32508746]\n",
      "tau_rate: [ 0.0135152]\n",
      "\n",
      "Iteration 6\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 39.66110148]\n",
      "tau_rate: [ 0.02225919]\n",
      "\n",
      "Iteration 7\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 24.08359501]\n",
      "tau_rate: [ 0.03665527]\n",
      "\n",
      "Iteration 8\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 14.63045394]\n",
      "tau_rate: [ 0.0603385]\n",
      "\n",
      "Iteration 9\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 8.89778191]\n",
      "tau_rate: [ 0.09921749]\n",
      "\n",
      "Iteration 10\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 5.42828539]\n",
      "tau_rate: [ 0.16267264]\n",
      "\n",
      "Iteration 11\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 3.34104773]\n",
      "tau_rate: [ 0.26460639]\n",
      "\n",
      "Iteration 12\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 2.10881876]\n",
      "tau_rate: [ 0.42142371]\n",
      "\n",
      "Iteration 13\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 1.42623704]\n",
      "tau_rate: [ 0.63695399]\n",
      "\n",
      "Iteration 14\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 1.1251102]\n",
      "tau_rate: [ 0.87246729]\n",
      "\n",
      "Iteration 15\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 1.81588574]\n",
      "tau_rate: [ 1.95525058]\n",
      "\n",
      "Iteration 16\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 4.28283451]\n",
      "tau_rate: [ 4.87632649]\n",
      "\n",
      "Iteration 17\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 11.13464806]\n",
      "tau_rate: [ 12.87500805]\n",
      "\n",
      "Iteration 18\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 34.34959363]\n",
      "tau_rate: [ 41.05260949]\n",
      "\n",
      "Iteration 19\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 80.16567742]\n",
      "tau_rate: [ 95.76495541]\n",
      "\n",
      "Iteration 20\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 80.50605617]\n",
      "tau_rate: [ 95.78716364]\n",
      "\n",
      "Iteration 21\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 80.50222205]\n",
      "tau_rate: [ 96.09797732]\n",
      "\n",
      "Iteration 22\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 234.36950313]\n",
      "tau_rate: [ 299.493126]\n",
      "\n",
      "Iteration 23\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 233.74053232]\n",
      "tau_rate: [ 300.3411236]\n",
      "\n",
      "Iteration 24\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 234.62213178]\n",
      "tau_rate: [ 310.50971375]\n",
      "\n",
      "Iteration 25\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 248.056312]\n",
      "tau_rate: [ 369.37740093]\n",
      "\n",
      "Iteration 26\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 248.31608088]\n",
      "tau_rate: [ 369.00015957]\n",
      "\n",
      "Iteration 27\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 249.00195307]\n",
      "tau_rate: [ 370.04658743]\n",
      "\n",
      "Iteration 28\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 252.98341728]\n",
      "tau_rate: [ 374.62978684]\n",
      "\n",
      "Iteration 29\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 253.00834977]\n",
      "tau_rate: [ 374.59890352]\n",
      "\n",
      "Iteration 30\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 252.88380167]\n",
      "tau_rate: [ 373.75101845]\n",
      "\n",
      "Iteration 31\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 253.97426572]\n",
      "tau_rate: [ 375.97861509]\n",
      "\n",
      "Iteration 32\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 252.99808646]\n",
      "tau_rate: [ 374.52485352]\n",
      "\n",
      "Iteration 33\n",
      "\n",
      "tau:\n",
      "tau_shape: [ 253.00000008]\n",
      "tau_rate: [ 374.52775847]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print len(trust_path.x_history)\n",
    "\n",
    "# for i in range(len(path.x_history) - 1):\n",
    "#     print np.sum(path.x_history[i + 1] - path.x_history[i])\n",
    "\n",
    "glmm_par.set_free(trust_path.x_history[len(trust_path.x_history) - 1])\n",
    "# print glmm_par\n",
    "    \n",
    "for i in range(len(trust_path.x_history)):\n",
    "    glmm_par.set_free(trust_path.x_history[i])\n",
    "    print 'Iteration ' + str(i) + '\\n'\n",
    "    print str(glmm_par['tau']) + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(glmm_par_opt)\n",
    "if simulate_data:\n",
    "    print true_beta\n",
    "    print glmm_par_opt['beta']\n",
    "    print '---------------\\n'\n",
    "    print true_tau\n",
    "    print glmm_par_opt['tau'].e()\n",
    "\n",
    "    e_u = glmm_par_opt['u'].e()\n",
    "    info_u = glmm_par_opt['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    e_beta = glmm_par_opt['beta'].e()\n",
    "    e_beta_outer = glmm_par_opt['beta'].e_outer()\n",
    "    std_draws = kl_wrapper.std_draws\n",
    "\n",
    "    rho_mean = e_u[y_g_vec] + np.matmul(x_mat, e_beta)\n",
    "    rho_sd = np.sqrt(var_u[y_g_vec] + np.einsum('nk,kj,nj->n', x_mat, e_beta_outer, x_mat))\n",
    "    z = np.einsum('i,j->ij', rho_sd, std_draws) + np.expand_dims(rho_mean, 1)\n",
    "    logit_term = -np.einsum('ij->i', np.log1p(np.exp(z))) / std_draws.size\n",
    "\n",
    "    print rho_sd\n",
    "    print var_u[y_g_vec]\n",
    "    # print np.mean(var_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the random effect estimates.  This requires simulated data.\n",
    "if simulate_data:\n",
    "    from ggplot import *\n",
    "    import pandas as pd\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print glmm_par_opt['mu'].e()\n",
    "    print true_mu\n",
    "\n",
    "    print glmm_par_opt['tau'].e()\n",
    "    print true_tau\n",
    "\n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['u'].mean.get(), 'true': true_u })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "    \n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['beta'].mean.get(), 'true': true_beta })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "    \n",
    "    plot_df = pd.DataFrame({ 'opt': logit_term, 'true': np.log(1 - true_rho) })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LRVB with conjugate gradient.  This turns out to be way slower with any appreciable number of moments.\n",
    "if False:\n",
    "    from scipy.sparse.linalg import LinearOperator\n",
    "    import sys\n",
    "\n",
    "    # This will actually compute Hess^1 * moment_jac.T, leading to perhaps confusing\n",
    "    # naming of \"columns\".  \n",
    "    ObjHessVecProdLO = LinearOperator((vb_opt.x.size, vb_opt.x.size), lambda par: KLHessVecProd(vb_opt.x, par))\n",
    "    # print moment_jac.T.shape\n",
    "    # print ObjHessVecProdLO.shape\n",
    "    # cg_res, info = scipy.sparse.linalg.cg(ObjHessVecProdLO, moment_jac.T)\n",
    "\n",
    "    cg_time = time.time()\n",
    "    lrvb_term = np.full(moment_jac.T.shape, float('nan'))\n",
    "    for col in range(moment_jac.shape[0]):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        cg_res, info = sp.sparse.linalg.cg(ObjHessVecProdLO, moment_jac[col, :])\n",
    "        assert info == 0\n",
    "        lrvb_term[:, col] = cg_res\n",
    "    cg_time = time.time() - cg_time\n",
    "\n",
    "    print 'all done dude'\n",
    "else:\n",
    "    cg_time = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian:\n",
      "\n",
      "Log prior Hessian:\n",
      "\n",
      "hess_time: 68.996338\n",
      "cg_time: inf\n"
     ]
    }
   ],
   "source": [
    "# Slow, but probably faster than using CG.\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par_opt, prior_par)\n",
    "\n",
    "hess_time = time.time()\n",
    "print 'KL Hessian:\\n'\n",
    "kl_hess = KLHess(vb_opt.x)\n",
    "print 'Log prior Hessian:\\n'\n",
    "log_prior_hess_full = PriorHess(combined_free_par_vec)\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print 'hess_time: %f' % hess_time\n",
    "print 'cg_time: %f' % cg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glmm_inds = range(glmm_par_opt.free_size())\n",
    "prior_inds = range(glmm_par_opt.free_size(), len(combined_free_par_vec))\n",
    "log_prior_hess = log_prior_hess_full[np.ix_(prior_inds, glmm_inds)]\n",
    "\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LRVBLogitGLMM/LogitGLMMLRVB/inst/data/simulated_data_large_python_vb_results.json\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    run_name = 'debug'\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'run_name': run_name,\n",
    "                    'vb_time': vb_time,'hess_time': hess_time, \n",
    "                    'moment_indices': moment_indices.dictval(),\n",
    "                    'prior_indices': prior_indices.dictval(),\n",
    "                    'vp_indices': vp_indices.dictval(),\n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "\n",
    "    print(json_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_mu: -0.5253\n",
      "0.0706139471208\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "mu_ind = moment_indices['e_mu'].get() - 1 # moment indices is one-indexed\n",
    "print moment_par['e_mu']\n",
    "print math.sqrt(lrvb_cov[mu_ind, mu_ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
