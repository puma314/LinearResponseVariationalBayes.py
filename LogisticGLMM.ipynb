{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam\n",
    "from VariationalBayes.NormalParams import MVNParam, UVNParam\n",
    "from VariationalBayes.GammaParams import GammaParam\n",
    "\n",
    "# import math\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "import copy\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This should go in the main library.\n",
    "from VariationalBayes.Parameters import set_free_offset, get_free_offset\n",
    "\n",
    "class UVNParamVector(object):\n",
    "    def __init__(self, name, length, min_var=0.0):\n",
    "        self.name = name\n",
    "        self.mean = VectorParam(name + '_mean', length)\n",
    "        self.var = VectorParam(name + '_var', length, lb=min_var)\n",
    "        self.__free_size = self.mean.free_size() + self.var.free_size()\n",
    "    def __str__(self):\n",
    "        return self.name + ':\\n' + str(self.mean) + '\\n' + str(self.var)\n",
    "    def names(self):\n",
    "        return self.mean.names() + self.var.names()\n",
    "    def e(self):\n",
    "        return self.mean.get()\n",
    "    def e_outer(self):\n",
    "        mean = self.mean.get() ** 2 + self.var.get()\n",
    "    def set_free(self, free_val):\n",
    "        if free_val.size != self.__free_size: \\\n",
    "            raise ValueError('Wrong size for UVNParam ' + self.name)\n",
    "        offset = 0\n",
    "        offset = set_free_offset(self.mean, free_val, offset)\n",
    "        offset = set_free_offset(self.var, free_val, offset)\n",
    "    def get_free(self):\n",
    "        vec = np.empty(self.__free_size)\n",
    "        offset = 0\n",
    "        offset = get_free_offset(self.mean, vec, offset)\n",
    "        offset = get_free_offset(self.var, vec, offset)\n",
    "        return vec\n",
    "    def free_size(self):\n",
    "        return self.__free_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelParamsList:\n",
      "\tmu:\n",
      "mu_mean: 0.1\n",
      "mu_var: 1.0\n",
      "\ttau:\n",
      "tau_shape: 2.1\n",
      "tau_rate: 2.1\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 0.  0.]\n",
      "beta_cov:\n",
      "[[ 0.2  0. ]\n",
      " [ 0.   0.2]]\n",
      "\tu:\n",
      "u_mean:\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "u_var:\n",
      "[ 0.1  0.1  0.1  0.1  0.1]\n"
     ]
    }
   ],
   "source": [
    "N = 100     # observations per group\n",
    "K = 2       # dimension of regressors\n",
    "NG = 5      # number of groups\n",
    "\n",
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = ModelParamsDict()\n",
    "\n",
    "glmm_par.push_param(UVNParam('mu'))\n",
    "glmm_par.push_param(GammaParam('tau'))\n",
    "glmm_par.push_param(MVNParam('beta', K))\n",
    "glmm_par.push_param(UVNParamVector('u', NG))\n",
    "\n",
    "glmm_par['mu'].mean.set(0.1)\n",
    "glmm_par['mu'].var.set(1.0)\n",
    "\n",
    "glmm_par['tau'].shape.set(2.1)\n",
    "glmm_par['tau'].rate.set(2.1)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.full(K, 0.))\n",
    "glmm_par['beta'].cov.set(0.2 * np.eye(K))\n",
    "\n",
    "glmm_par['u'].mean.set(np.full(NG, 0.))\n",
    "glmm_par['u'].var.set(np.full(NG, 0.1))\n",
    "    \n",
    "print glmm_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "def Logistic(u):\n",
    "    return np.exp(u) / (1 + np.exp(u))\n",
    "\n",
    "NObs = NG * N\n",
    "true_beta = np.random.rand(K) - 0.5\n",
    "true_mu = 0.2\n",
    "true_tau = 4.0\n",
    "true_u = np.random.normal(true_mu, 1 / np.sqrt(true_tau), NG)\n",
    "\n",
    "x_mat = np.random.random(K * NObs).reshape(NObs, K) - 0.5\n",
    "y_g_vec = [ g for g in range(NG) for n in range(N) ]\n",
    "true_rho = Logistic(np.matmul(x_mat, true_beta) + true_u[y_g_vec])\n",
    "y_vec = np.random.random(NObs) < true_rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DataLogLikelihood(x_mat, y_vec, e_beta, e_beta_outer, e_u, var_u, std_draws):\n",
    "    rho_mean = e_u + np.matmul(x_mat, e_beta)\n",
    "    rho_sd = np.sqrt(var_u + np.einsum('nk,kj,nj->n', x_mat, e_beta_outer, x_mat))\n",
    "    z = np.einsum('i,j->ij', rho_sd, std_draws) + np.expand_dims(rho_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # log(1 - p) = log(1 / (1 + exp(u))) = -log(1 + exp(u))\n",
    "    logit_term = -np.sum(np.log1p(np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * rho_mean)\n",
    "    return y_term + logit_term\n",
    "\n",
    "\n",
    "def RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau):\n",
    "    return -0.5 * e_tau * np.sum((e_mu - e_u) ** 2 + var_mu + var_u) \\\n",
    "           - 0.5 * e_log_tau * len(e_u)\n",
    "\n",
    "def UnivariateNormalEntropy(var_obs):\n",
    "    return 0.5 * np.sum(np.log(var_obs))\n",
    "\n",
    "def MultivariateNormalEntropy(cov_obs):\n",
    "    sign, logdet = np.linalg.slogdet(cov_obs)\n",
    "    assert sign > 0\n",
    "    return 0.5 * logdet\n",
    "\n",
    "def GammaEntropy(shape, rate):\n",
    "    return np.sum(shape - np.log(rate) + scipy.special.gammaln(shape) + \\\n",
    "                  (1 - shape) * scipy.special.digamma(shape))\n",
    "\n",
    "def MVNPrior(prior_mean, prior_info, e_obs, cov_obs):\n",
    "    obs_diff = e_obs - prior_mean\n",
    "    return -0.5 * (np.dot(obs_diff, np.matmul(prior_info, obs_diff)) + \\\n",
    "                   np.trace(np.matmul(prior_info, cov_obs)))\n",
    "\n",
    "def UVNPrior(prior_mean, prior_info, e_obs, var_obs):\n",
    "    return -0.5 * (prior_info * ((e_obs - prior_mean) ** 2 + var_obs))\n",
    "\n",
    "\n",
    "def Elbo(y_vec, x_mat, y_g_vec, glmm_par_elbo, std_draws):\n",
    "    e_beta = glmm_par['beta'].mean.get()\n",
    "    cov_beta = glmm_par['beta'].cov.get()\n",
    "    e_beta_outer = glmm_par['beta'].e_outer()\n",
    "    \n",
    "    e_u = glmm_par['u'].mean.get()\n",
    "    var_u = glmm_par['u'].var.get()\n",
    "    \n",
    "    e_mu = glmm_par['mu'].mean.get()\n",
    "    var_mu = glmm_par['mu'].var.get()\n",
    "    \n",
    "    e_tau = glmm_par['tau'].e()\n",
    "    e_log_tau = glmm_par['tau'].e_log()\n",
    "\n",
    "    ll = \\\n",
    "        DataLogLikelihood(x_mat, y_vec, e_beta, e_beta_outer,\n",
    "                          e_u[y_g_vec], var_u[y_g_vec], std_draws) + \\\n",
    "        RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)\n",
    "\n",
    "    K = len(e_beta)\n",
    "    beta_prior_info = 0.01 * np.eye(K)\n",
    "    beta_prior_mean = np.full(K, 0.)\n",
    "    e_log_prior = \\\n",
    "        MVNPrior(beta_prior_mean, beta_prior_info, e_beta, cov_beta) + \\\n",
    "        UVNPrior(0., 0.01, e_mu, var_mu)\n",
    "    # TODO: add the other priors.\n",
    "        \n",
    "    entropy = \\\n",
    "        UnivariateNormalEntropy(var_mu) + \\\n",
    "        MultivariateNormalEntropy(cov_beta) + \\\n",
    "        UnivariateNormalEntropy(var_u) + \\\n",
    "        GammaEntropy(glmm_par['tau'].shape.get(), glmm_par['tau'].rate.get())\n",
    "\n",
    "    return ll + e_log_prior + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, glmm_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = scipy.stats.norm.ppf(target_quantiles)\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.y_g_vec,\n",
    "                   self.__glmm_par_ad, std_draws=self.std_draws)\n",
    "        if verbose: print kl\n",
    "        return kl\n",
    "    \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        return self.__glmm_par_ad['beta'].mean.get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.39495753257819"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_wrapper = KLWrapper(glmm_par, x_mat, y_vec, y_g_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMoments)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "free_par_vec = glmm_par.get_free()\n",
    "kl_wrapper.Eval(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.000590014457703\n",
      "Grad time:\n",
      "0.000948405265808\n",
      "Hessian vector product time:\n",
      "0.00117259025574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:16: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "# so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "profile = False\n",
    "if profile:\n",
    "    cProfile.run('kl_wrapper.Eval(free_par_vec)', '/tmp/cprofilestats_func.prof')\n",
    "    cProfile.run('KLHess(free_par_vec)', '/tmp/cprofilestats_hess.prof')\n",
    "    cProfile.run('KLGrad(free_par_vec)', '/tmp/cprofilestats_grad.prof')\n",
    "\n",
    "# A better way to visualize this https://jiffyclub.github.io/snakeviz/\n",
    "# snakeviz /tmp/cprofilestats_hess.prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mvn_par' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a7d9f335ae12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmu_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmvn_par\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e_mu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmvn_par\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'var_mu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0minit_par_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmvn_par\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_free\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mvn_par' is not defined"
     ]
    }
   ],
   "source": [
    "# Set initial values.\n",
    "xtx = np.matmul(x_mat.T, x_mat)\n",
    "mu_reg = np.linalg.solve(xtx, np.matmul(x_mat.T, y_vec))\n",
    "\n",
    "mvn_par['e_mu'].set(mu_reg)\n",
    "mvn_par['var_mu'].set(np.full(K, 1.))\n",
    "init_par_vec = mvn_par.get_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimize.\n",
    "# print 'Running BFGS'\n",
    "# vb_opt_bfgs = optimize.minimize(\n",
    "#     lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "#     method='bfgs', jac=KLGrad, tol=1e-2)\n",
    "\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    init_par_vec, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd)\n",
    "mvn_par_opt = copy.deepcopy(mvn_par)\n",
    "mvn_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean parameters match, as expected.\n",
    "from ggplot import *\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "plot_df = pd.DataFrame({ 'opt': mvn_par_opt['e_mu'].get(), 'true': true_mu })\n",
    "ggplot(plot_df, aes(x='opt', y='true')) + geom_point() + geom_abline(slope=1, intercept=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB with conjugate gradient\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "import sys\n",
    "\n",
    "# The we will actually compute Hess^1 * moment_jac.T, leading to perhaps confusing\n",
    "# naming of \"columns\".  \n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "ObjHessVecProdLO = LinearOperator((vb_opt.x.size, vb_opt.x.size), lambda par: KLHessVecProd(vb_opt.x, par))\n",
    "# print moment_jac.T.shape\n",
    "# print ObjHessVecProdLO.shape\n",
    "# cg_res, info = scipy.sparse.linalg.cg(ObjHessVecProdLO, moment_jac.T)\n",
    "\n",
    "lrvb_term = np.full(moment_jac.T.shape, float('nan'))\n",
    "for col in range(moment_jac.shape[0]):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "    cg_res, info = scipy.sparse.linalg.cg(ObjHessVecProdLO, moment_jac[col, :])\n",
    "    assert info == 0\n",
    "    lrvb_term[:, col] = cg_res\n",
    "\n",
    "print 'all done dude'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slow:\n",
    "kl_hess = KLHess(vb_opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu_cov_hess = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "mu_cov = np.matmul(moment_jac, lrvb_term)\n",
    "print np.diag(mu_cov)\n",
    "print np.diag(mu_cov_hess)\n",
    "print mvn_par_opt['var_mu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
