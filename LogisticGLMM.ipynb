{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "from VariationalBayes.NormalParams import MVNParam, UVNParam, UVNParamVector\n",
    "from VariationalBayes.GammaParams import GammaParam\n",
    "from VariationalBayes.ExponentialFamilies import \\\n",
    "    UnivariateNormalEntropy, MultivariateNormalEntropy, GammaEntropy, \\\n",
    "    MVNPrior, UVNPrior, GammaPrior\n",
    "\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as asp\n",
    "import scipy as sp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'y_group', u'mu_prior_var', u'mu_prior_t', u'mu_prior_var_c', u'K', u'beta_prior_var', u'tau_prior_beta', u'N', u'mu_prior_mean_c', u'mu_prior_epsilon', u'mu_prior_mean', u'y', u'x', u'NG', u'beta_prior_mean', u'tau_prior_alpha']\n",
      "1000\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "simulate_data = False\n",
    "prior_par = ModelParamsDict('Prior Parameters')\n",
    "\n",
    "if not simulate_data:\n",
    "    analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    stan_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    print stan_dat.keys()\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "    prior_par.push_param(PosDefMatrixParam('beta_prior_var', K, val=np.array(stan_dat['beta_prior_var'])))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "    prior_par.push_param(ScalarParam('mu_prior_var', val=stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "    prior_par.push_param(ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "    def Logistic(u):\n",
    "        return np.exp(u) / (1 + np.exp(u))\n",
    "\n",
    "    NObs = NG * N\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "    true_u = np.random.normal(true_mu, 1 / np.sqrt(true_tau), NG)\n",
    "\n",
    "    x_mat = np.random.random(K * NObs).reshape(NObs, K) - 0.5\n",
    "    y_g_vec = [ g for g in range(NG) for n in range(N) ]\n",
    "    true_rho = Logistic(np.matmul(x_mat, true_beta) + true_u[y_g_vec])\n",
    "    y_vec = np.random.random(NObs) < true_rho\n",
    "    \n",
    "    prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.zeros(K)))\n",
    "    prior_par.push_param(PosDefMatrixParam('beta_prior_var', K, val=10 * np.eye(K)))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('mu_prior_mean', val=0))\n",
    "    prior_par.push_param(ScalarParam('mu_prior_var', val=2))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('tau_prior_alpha', val=3.0))\n",
    "    prior_par.push_param(ScalarParam('tau_prior_beta', val=10.0))\n",
    "\n",
    "print N * NG\n",
    "print np.mean(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM Parameters:\n",
      "\tmu:\n",
      "mu_mean: 0.1\n",
      "mu_info: 1.0\n",
      "\ttau:\n",
      "tau_shape: 2.1\n",
      "tau_rate: 2.1\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "beta_info:\n",
      "[[ 0.05  0.    0.    0.    0.  ]\n",
      " [ 0.    0.05  0.    0.    0.  ]\n",
      " [ 0.    0.    0.05  0.    0.  ]\n",
      " [ 0.    0.    0.    0.05  0.  ]\n",
      " [ 0.    0.    0.    0.    0.05]]\n",
      "\tu:\n",
      "u_mean:\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "u_info:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "glmm_par.push_param(UVNParam('mu'))\n",
    "glmm_par.push_param(GammaParam('tau'))\n",
    "glmm_par.push_param(MVNParam('beta', K))\n",
    "glmm_par.push_param(UVNParamVector('u', NG))\n",
    "\n",
    "glmm_par['mu'].mean.set(0.1)\n",
    "glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "glmm_par['tau'].shape.set(2.1)\n",
    "glmm_par['tau'].rate.set(2.1)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.full(K, 0.))\n",
    "glmm_par['beta'].info.set(np.eye(K) / 20)\n",
    "\n",
    "glmm_par['u'].mean.set(np.full(NG, 0.))\n",
    "glmm_par['u'].info.set(np.full(NG, 1))\n",
    "\n",
    "print glmm_par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "\n",
    "moment_par = ModelParamsDict('Moment Parameters')\n",
    "moment_par.push_param(VectorParam('e_beta', K))\n",
    "moment_par.push_param(PosDefMatrixParam('e_beta_outer', K))\n",
    "moment_par.push_param(ScalarParam('e_mu'))\n",
    "moment_par.push_param(ScalarParam('e_mu2'))\n",
    "moment_par.push_param(ScalarParam('e_tau'))\n",
    "moment_par.push_param(ScalarParam('e_log_tau'))\n",
    "moment_par.push_param(VectorParam('e_u', NG))\n",
    "moment_par.push_param(VectorParam('e_u2', NG))\n",
    "\n",
    "def set_moments(glmm_par, moment_par):\n",
    "    moment_par['e_beta'].set(glmm_par['beta'].e())\n",
    "    moment_par['e_beta_outer'].set(glmm_par['beta'].e_outer())\n",
    "    moment_par['e_mu'].set(glmm_par['mu'].e())\n",
    "    moment_par['e_mu2'].set(glmm_par['mu'].e_outer())\n",
    "    moment_par['e_tau'].set(glmm_par['tau'].e())\n",
    "    moment_par['e_log_tau'].set(glmm_par['tau'].e_log())\n",
    "    moment_par['e_u'].set(glmm_par['u'].e())\n",
    "    moment_par['e_u2'].set((glmm_par['u'].e_outer()))\n",
    "    \n",
    "set_moments(glmm_par, moment_par)\n",
    "\n",
    "# Moment indices.\n",
    "moment_indices = copy.deepcopy(moment_par)\n",
    "moment_indices.set_vector(1 + np.array(range(moment_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_combined_parameters(combined_free_par_vec, glmm_par, prior_par):\n",
    "    assert glmm_par.free_size() + prior_par.vector_size() == len(combined_free_par_vec) \n",
    "    glmm_par.set_free(combined_free_par_vec[0:glmm_par.free_size()])\n",
    "    prior_par.set_vector(combined_free_par_vec[glmm_par.free_size():])\n",
    "\n",
    "    \n",
    "def encode_combined_parameters(glmm_par, prior_par):\n",
    "    combined_free_par_vec = np.full(glmm_par.free_size() + prior_par.vector_size(), float('nan'))\n",
    "    combined_free_par_vec[0:glmm_par.free_size()] = glmm_par.get_free()\n",
    "    combined_free_par_vec[glmm_par.free_size():] = prior_par.get_vector()\n",
    "    return combined_free_par_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExpMatrixDiagonal(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.47116027061\n",
      "(224, 224)\n",
      "[[-0.00018254  0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[[  1.90470432e-02  -1.00000000e+00]\n",
      " [ -1.00000000e+00   5.30000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "glmm_par_elbo = copy.deepcopy(glmm_par)\n",
    "\n",
    "def DebugFun(glmm_par_elbo, prior_par):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "\n",
    "    e_u = glmm_par_elbo['u'].mean.get()\n",
    "    info_u = glmm_par_elbo['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "\n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    \n",
    "    tau_shape = glmm_par_elbo['tau'].shape.get()\n",
    "    tau_rate = glmm_par_elbo['tau'].rate.get()\n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    tau_prior_shape = prior_par['tau_prior_alpha'].get()\n",
    "    tau_prior_rate = prior_par['tau_prior_beta'].get()\n",
    "    e_log_p_tau = GammaPrior(tau_prior_shape, tau_prior_rate, e_tau, e_log_tau)\n",
    "\n",
    "#     return RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)[0] + \\\n",
    "#            GammaEntropy(tau_shape, tau_rate) + \\\n",
    "#            e_log_p_tau[0]\n",
    "#     return RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)[0]\n",
    "    return GammaEntropy(tau_shape, tau_rate)\n",
    "\n",
    "\n",
    "\n",
    "class DebugWrapper():\n",
    "    def __init__(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = sp.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    def Eval(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        return DebugFun(self.__glmm_par_ad, self.__prior_par_ad)\n",
    "\n",
    "\n",
    "debug_wrapper = DebugWrapper(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "DebugGrad = grad(debug_wrapper.Eval)\n",
    "DebugHess = hessian(debug_wrapper.Eval)\n",
    "KLHessVecProd = hessian_vector_product(debug_wrapper.Eval)  \n",
    "\n",
    "free_par_vec = glmm_par_opt.get_free()\n",
    "print debug_wrapper.Eval(free_par_vec)\n",
    "foo = DebugHess(free_par_vec)\n",
    "print foo.shape\n",
    "\n",
    "inds = np.hstack([ vp_indices['tau'].shape.get() - 1, vp_indices['tau'].rate.get() - 1 ])\n",
    "print foo[np.ix_(inds, inds)]\n",
    "\n",
    "print kl_hess[np.ix_(inds, inds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510.57620581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-4.0182527520990901"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ELogPrior(prior_par, glmm_par_elbo):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "    beta_prior_info = np.linalg.inv(prior_par['beta_prior_var'].get())\n",
    "    beta_prior_mean = prior_par['beta_prior_mean'].get()\n",
    "    e_log_p_beta = MVNPrior(beta_prior_mean, beta_prior_info, e_beta, cov_beta)\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "    e_log_p_mu = UVNPrior(prior_par['mu_prior_mean'].get(), 1 / prior_par['mu_prior_var'].get(), e_mu, var_mu) \n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    tau_prior_shape = prior_par['tau_prior_alpha'].get()\n",
    "    tau_prior_rate = prior_par['tau_prior_beta'].get()\n",
    "    e_log_p_tau = GammaPrior(tau_prior_shape, tau_prior_rate, e_tau, e_log_tau)\n",
    "    \n",
    "    return  e_log_p_beta + e_log_p_mu + e_log_p_tau\n",
    "           \n",
    "\n",
    "def DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta, e_u, var_u, std_draws):\n",
    "    z_mean = e_u + np.matmul(x_mat, e_beta)\n",
    "    z_sd = np.sqrt(var_u + np.einsum('nk,kj,nj->n', x_mat, cov_beta, x_mat))\n",
    "    z = np.einsum('i,j->ij', z_sd, std_draws) + np.expand_dims(z_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # p = exp(z) / (1 + exp(z))\n",
    "    # log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "    logit_term = -np.sum(np.log1p(np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * z_mean)\n",
    "    return y_term + logit_term\n",
    "\n",
    "\n",
    "def RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau):\n",
    "    return -0.5 * e_tau * np.sum(((e_mu - e_u) ** 2) + var_mu + var_u) + 0.5 * e_log_tau * len(e_u)\n",
    "\n",
    "    \n",
    "def Elbo(y_vec, x_mat, y_g_vec, glmm_par_elbo, std_draws, prior_par):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "    \n",
    "    e_u = glmm_par_elbo['u'].mean.get()\n",
    "    info_u = glmm_par_elbo['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "    \n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "        \n",
    "    ll = \\\n",
    "        DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta,\n",
    "                          e_u[y_g_vec], var_u[y_g_vec], std_draws) + \\\n",
    "        RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)\n",
    "\n",
    "    e_log_prior = ELogPrior(prior_par, glmm_par_elbo)\n",
    "    \n",
    "    tau_shape = glmm_par_elbo['tau'].shape.get()\n",
    "    tau_rate = glmm_par_elbo['tau'].rate.get()\n",
    "    entropy = \\\n",
    "        UnivariateNormalEntropy(info_mu) + \\\n",
    "        MultivariateNormalEntropy(info_beta) + \\\n",
    "        UnivariateNormalEntropy(info_u) + \\\n",
    "        GammaEntropy(tau_shape, tau_rate)\n",
    "\n",
    "    return ll[0] + e_log_prior[0] + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, glmm_par, moment_par, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__moment_par = copy.deepcopy(moment_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = sp.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.y_g_vec,\n",
    "                   self.__glmm_par_ad, self.std_draws, self.__prior_par_ad)\n",
    "        if verbose: print kl\n",
    "            \n",
    "        # TODO: this is returning an array when it should be a scalar.\n",
    "        return kl\n",
    "    \n",
    "    def ExpectedLogPrior(self, combined_free_par_vec):\n",
    "        # Encode the glmm parameters first and the prior second.\n",
    "        decode_combined_parameters(combined_free_par_vec, self.__glmm_par_ad, self.__prior_par_ad)\n",
    "        e_log_prior = ELogPrior(self.__prior_par_ad, self.__glmm_par_ad)\n",
    "        return e_log_prior[0]\n",
    "        \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par.get_vector()\n",
    "\n",
    "\n",
    "# TODO: get the log prior derivatives, too.\n",
    "\n",
    "kl_wrapper = KLWrapper(glmm_par, moment_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMoments)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "free_par_vec = glmm_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par, prior_par)\n",
    "PriorHess = hessian(kl_wrapper.ExpectedLogPrior)\n",
    "kl_wrapper.ExpectedLogPrior(combined_free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.00283751487732\n",
      "Grad time:\n",
      "0.00551421642303\n",
      "Hessian vector product time:\n",
      "0.0135607004166\n",
      "Moment jacobian time:\n",
      "0.273039007187\n",
      "Prior Hessian time:\n",
      "1.50568199158\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "print 'Moment jacobian time:'\n",
    "print timeit.timeit(lambda: MomentJacobian(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "time_num = 1\n",
    "print 'Prior Hessian time:'\n",
    "print timeit.timeit(lambda: PriorHess(combined_free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFGS\n",
      "2510.58125581\n",
      "1046.62437767\n",
      "477.986038794\n",
      "509.352926099\n",
      "2303.00072308\n",
      "457.501539022\n",
      "424.262543429\n",
      "396.148479601\n",
      "423.628938131\n",
      "384.112663038\n",
      "366.21220642\n",
      "338.154912571\n",
      "286.221053822\n",
      "221.236740423\n",
      "187.368785983\n",
      "158.754124957\n",
      "127.329197245\n",
      "365.453470956\n",
      "123.622970441\n",
      "116.796067127\n",
      "109.42422653\n",
      "105.598849302\n",
      "99.45348213\n",
      "93.1313269342\n",
      "86.6817240982\n",
      "84.3033676422\n",
      "80.7469177195\n",
      "75.9488390205\n",
      "72.7405705004\n",
      "69.8493152857\n",
      "67.0484654038\n",
      "64.7996062471\n",
      "63.4963622295\n",
      "62.748819517\n",
      "62.1460723526\n",
      "61.7712666281\n",
      "61.5049602845\n",
      "61.3365719915\n",
      "61.2414604059\n",
      "61.1903960561\n",
      "61.1369239976\n",
      "61.0948269615\n",
      "61.0230594925\n",
      "60.909298438\n",
      "60.7855267769\n",
      "60.7184358853\n",
      "60.662291295\n",
      "60.6111653362\n",
      "60.5582046421\n",
      "60.5125868717\n",
      "60.4809305491\n",
      "60.4609918105\n",
      "60.4474370416\n",
      "60.4390550401\n",
      "60.4343640444\n",
      "60.4307584721\n",
      "60.425000496\n",
      "60.4153936288\n",
      "60.399940822\n",
      "60.3793269425\n",
      "60.3682827318\n",
      "60.3637113106\n",
      "60.3627530888\n",
      "60.3611585726\n",
      "60.3583981352\n",
      "60.3535072308\n",
      "60.3448213682\n",
      "60.3297445392\n",
      "60.3053887826\n",
      "60.2738486189\n",
      "60.2524792421\n",
      "60.232868528\n",
      "60.2302462234\n",
      "60.2260747539\n",
      "60.219418698\n",
      "60.2092468354\n",
      "60.1964397513\n",
      "60.1865736253\n",
      "60.1791524997\n",
      "60.1774689238\n",
      "60.1749455964\n",
      "60.1712063926\n",
      "60.1664365804\n",
      "60.1588614009\n",
      "60.1468826936\n",
      "60.1307655777\n",
      "60.1218359473\n",
      "60.1166390455\n",
      "60.1145223444\n",
      "60.1139093471\n",
      "60.113312245\n",
      "60.112317878\n",
      "60.1105641829\n",
      "60.1074373144\n",
      "60.1020470775\n",
      "60.0938918627\n",
      "60.0875016349\n",
      "60.0841522434\n",
      "60.0823488956\n",
      "60.0818950173\n",
      "60.0811421197\n",
      "60.0798182774\n",
      "60.0774219285\n",
      "60.0730635041\n",
      "60.0652585804\n",
      "60.051877815\n",
      "60.0312421833\n",
      "60.0094092833\n",
      "59.9929444263\n",
      "59.9856395245\n",
      "59.9847767855\n",
      "59.9833552728\n",
      "59.9811830665\n",
      "59.9783737082\n",
      "59.9737777633\n",
      "59.9658648316\n",
      "59.9527777216\n",
      "59.9357127926\n",
      "59.9276608383\n",
      "59.9213710947\n",
      "59.917684543\n",
      "59.9154053023\n",
      "59.9138086941\n",
      "59.9118451121\n",
      "59.9087596356\n",
      "59.9042123025\n",
      "59.8983787781\n",
      "59.8892438468\n",
      "59.877715441\n",
      "59.8728830708\n",
      "59.8674417011\n",
      "59.8663865737\n",
      "59.8662561498\n",
      "59.8662226283\n",
      "59.8661826078\n",
      "59.8661302014\n",
      "59.8660457039\n",
      "59.8659089004\n",
      "59.8656826969\n",
      "59.8652962249\n",
      "59.8646221847\n",
      "59.8634492698\n",
      "59.861478868\n",
      "59.8585045992\n",
      "59.8559352785\n",
      "59.8545995012\n",
      "59.8540363279\n",
      "59.8539480885\n",
      "59.853934373\n",
      "59.8539125014\n",
      "59.8538752715\n",
      "59.8538088014\n",
      "59.853687468\n",
      "59.8534645698\n",
      "59.8530565494\n",
      "59.8523178215\n",
      "59.8510023905\n",
      "59.8487033097\n",
      "59.8447366256\n",
      "59.8378788087\n",
      "59.8258170727\n",
      "59.8041085963\n",
      "59.7643783443\n",
      "59.6926919268\n",
      "59.5885980759\n",
      "59.9353568942\n",
      "59.5572154209\n",
      "59.5229483015\n",
      "59.464858981\n",
      "59.3649048286\n",
      "59.2047141113\n",
      "59.0084399001\n",
      "58.8554843701\n",
      "58.7107296054\n",
      "58.5610014978\n",
      "58.2764343406\n",
      "61.5638379572\n",
      "58.1697123396\n",
      "58.1055770453\n",
      "58.0541661858\n",
      "58.0684435366\n",
      "58.0445533082\n",
      "58.034849912\n",
      "58.0224354806\n",
      "58.0095842865\n",
      "57.9998239737\n",
      "57.9927610702\n",
      "57.9911838182\n",
      "57.9891016932\n",
      "57.9853335376\n",
      "57.9787118867\n",
      "57.9677798269\n",
      "57.951716061\n",
      "57.9335515068\n",
      "57.9073001302\n",
      "57.890927178\n",
      "57.8877899172\n",
      "57.8870570651\n",
      "57.8863991593\n",
      "57.885513795\n",
      "57.8843423276\n",
      "57.8824168804\n",
      "57.879081123\n",
      "57.8731783712\n",
      "57.8628087784\n",
      "57.8453721604\n",
      "57.8198229559\n",
      "57.7969316064\n",
      "57.7757260396\n",
      "57.7676519019\n",
      "57.7648863846\n",
      "57.7644797375\n",
      "57.7642151234\n",
      "57.7641342448\n",
      "57.7639929087\n",
      "57.7637398193\n",
      "57.7632834707\n",
      "57.7624641673\n",
      "57.7610132772\n",
      "57.7585048415\n",
      "57.7543325905\n",
      "57.7478483023\n",
      "57.7396108261\n",
      "57.7318425167\n",
      "57.7257751578\n",
      "57.7247719227\n",
      "57.724713144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 57.724713\n",
      "         Iterations: 219\n",
      "         Function evaluations: 227\n",
      "         Gradient evaluations: 227\n",
      "Running Newton Trust Region\n",
      "57.724713144\n",
      "57.723993981\n",
      "57.7237066297\n",
      "57.7230495551\n",
      "57.7230320752\n",
      "57.7228819841\n",
      "57.7227743785\n",
      "57.7227733302\n",
      "57.7227731565\n",
      "57.7227731565\n",
      "57.7227731565\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 57.722773\n",
      "         Iterations: 10\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "         Hessian evaluations: 0\n",
      "Done.\n",
      "0.135110553106\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "init_par_vec = free_par_vec\n",
    "\n",
    "# Optimize.\n",
    "vb_time = time.time()\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-2, options={'maxiter': 5000, 'disp': True})\n",
    "\n",
    "init_par_vec = free_par_vec\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd,\n",
    "    tol=1e-8, options={'maxiter': 5000, 'disp': True})\n",
    "\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(vb_opt.x)\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "\n",
    "print 'Done.'\n",
    "\n",
    "print vb_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(glmm_par_opt)\n",
    "if simulate_data:\n",
    "    print true_beta\n",
    "    print glmm_par_opt['beta']\n",
    "    print '---------------\\n'\n",
    "    print true_tau\n",
    "    print glmm_par_opt['tau'].e()\n",
    "\n",
    "    e_u = glmm_par_opt['u'].e()\n",
    "    info_u = glmm_par_opt['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    e_beta = glmm_par_opt['beta'].e()\n",
    "    e_beta_outer = glmm_par_opt['beta'].e_outer()\n",
    "    std_draws = kl_wrapper.std_draws\n",
    "\n",
    "    rho_mean = e_u[y_g_vec] + np.matmul(x_mat, e_beta)\n",
    "    rho_sd = np.sqrt(var_u[y_g_vec] + np.einsum('nk,kj,nj->n', x_mat, e_beta_outer, x_mat))\n",
    "    z = np.einsum('i,j->ij', rho_sd, std_draws) + np.expand_dims(rho_mean, 1)\n",
    "    logit_term = -np.einsum('ij->i', np.log1p(np.exp(z))) / std_draws.size\n",
    "\n",
    "    print rho_sd\n",
    "    print var_u[y_g_vec]\n",
    "    # print np.mean(var_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the random effect estimates.  This requires simulated data.\n",
    "if simulate_data:\n",
    "    from ggplot import *\n",
    "    import pandas as pd\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print glmm_par_opt['mu'].e()\n",
    "    print true_mu\n",
    "\n",
    "    print glmm_par_opt['tau'].e()\n",
    "    print true_tau\n",
    "\n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['u'].mean.get(), 'true': true_u })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "    \n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['beta'].mean.get(), 'true': true_beta })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "    \n",
    "    plot_df = pd.DataFrame({ 'opt': logit_term, 'true': np.log(1 - true_rho) })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB with conjugate gradient.  This turns out to be way slower with any appreciable number of moments.\n",
    "if False:\n",
    "    from scipy.sparse.linalg import LinearOperator\n",
    "    import sys\n",
    "\n",
    "    # This will actually compute Hess^1 * moment_jac.T, leading to perhaps confusing\n",
    "    # naming of \"columns\".  \n",
    "    ObjHessVecProdLO = LinearOperator((vb_opt.x.size, vb_opt.x.size), lambda par: KLHessVecProd(vb_opt.x, par))\n",
    "    # print moment_jac.T.shape\n",
    "    # print ObjHessVecProdLO.shape\n",
    "    # cg_res, info = scipy.sparse.linalg.cg(ObjHessVecProdLO, moment_jac.T)\n",
    "\n",
    "    cg_time = time.time()\n",
    "    lrvb_term = np.full(moment_jac.T.shape, float('nan'))\n",
    "    for col in range(moment_jac.shape[0]):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        cg_res, info = sp.sparse.linalg.cg(ObjHessVecProdLO, moment_jac[col, :])\n",
    "        assert info == 0\n",
    "        lrvb_term[:, col] = cg_res\n",
    "    cg_time = time.time() - cg_time\n",
    "\n",
    "    print 'all done dude'\n",
    "else:\n",
    "    cg_time = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess_time: 3.098619\n",
      "cg_time: inf\n"
     ]
    }
   ],
   "source": [
    "# Slow, but probably faster than using CG.\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par_opt, prior_par)\n",
    "\n",
    "hess_time = time.time()\n",
    "kl_hess = KLHess(vb_opt.x)\n",
    "log_prior_hess_full = PriorHess(combined_free_par_vec)\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print 'hess_time: %f' % hess_time\n",
    "print 'cg_time: %f' % cg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6843418860808015e-14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(np.matmul(kl_hess, vb_opt.x + 1) - KLHessVecProd(vb_opt.x, vb_opt.x + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glmm_inds = range(glmm_par_opt.free_size())\n",
    "prior_inds = range(glmm_par_opt.free_size(), len(combined_free_par_vec))\n",
    "log_prior_hess = log_prior_hess_full[np.ix_(prior_inds, glmm_inds)]\n",
    "\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LRVBLogitGLMM/LogitGLMMLRVB/inst/data/simulated_data_small_python_vb_results.json\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(),\n",
    "                    'vb_time': vb_time,'hess_time': hess_time, \n",
    "                    'moment_indices': moment_indices.dictval(),\n",
    "                    'prior_indices': prior_indices.dictval(),\n",
    "                    'vp_indices': vp_indices.dictval(),\n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "\n",
    "    print(json_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_moments(glmm_par_opt, moment_par)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
