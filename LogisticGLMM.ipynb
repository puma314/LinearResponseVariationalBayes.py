{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "from VariationalBayes.NormalParams import MVNParam, UVNParam, UVNParamVector\n",
    "from VariationalBayes.GammaParams import GammaParam\n",
    "from VariationalBayes.ExponentialFamilies import \\\n",
    "    UnivariateNormalEntropy, MultivariateNormalEntropy, GammaEntropy, \\\n",
    "    MVNPrior, UVNPrior, GammaPrior\n",
    "\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as asp\n",
    "import scipy as sp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'y_group', u'mu_prior_var', u'mu_prior_t', u'mu_prior_var_c', u'K', u'beta_prior_var', u'tau_prior_beta', u'N', u'mu_prior_mean_c', u'mu_prior_epsilon', u'mu_prior_mean', u'y', u'x', u'NG', u'beta_prior_mean', u'tau_prior_alpha']\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "analysis_name = 'simulated_data_small'\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "json_file = open(json_filename, 'r')\n",
    "stan_dat = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "print stan_dat.keys()\n",
    "K = stan_dat['K'][0]\n",
    "NObs = stan_dat['N'][0]\n",
    "NG = stan_dat['NG'][0]\n",
    "N = NObs / NG\n",
    "y_g_vec = np.array(stan_dat['y_group'])\n",
    "y_vec = np.array(stan_dat['y'])\n",
    "x_mat = np.array(stan_dat['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a class to contain prior parameters.\n",
    "prior_par = ModelParamsDict('Prior Parameters')\n",
    "\n",
    "prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "prior_par.push_param(PosDefMatrixParam('beta_prior_var', K, val=np.array(stan_dat['beta_prior_var'])))\n",
    "\n",
    "prior_par.push_param(ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "prior_par.push_param(ScalarParam('mu_prior_var', val=stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "prior_par.push_param(ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "prior_par.push_param(ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "# An index set to make sure jacobians match the order expected by R.\n",
    "prior_par_indices = copy.deepcopy(prior_par)\n",
    "prior_par_indices.set_name('Prior Indices')\n",
    "prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate data instead of loading it if you like\n",
    "if False:\n",
    "    N = 20     # observations per group\n",
    "    K = 25      # dimension of regressors\n",
    "    NG = 500      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "    def Logistic(u):\n",
    "        return np.exp(u) / (1 + np.exp(u))\n",
    "\n",
    "    NObs = NG * N\n",
    "    true_beta = np.random.rand(K) - 0.5\n",
    "    true_mu = 0.2\n",
    "    true_tau = 4.0\n",
    "    true_u = np.random.normal(true_mu, 1 / np.sqrt(true_tau), NG)\n",
    "\n",
    "    x_mat = np.random.random(K * NObs).reshape(NObs, K) - 0.5\n",
    "    y_g_vec = [ g for g in range(NG) for n in range(N) ]\n",
    "    true_rho = Logistic(np.matmul(x_mat, true_beta) + true_u[y_g_vec])\n",
    "    y_vec = np.random.random(NObs) < true_rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "GLMM Parameters:\n",
      "\tmu:\n",
      "mu_mean: 0.1\n",
      "mu_var: 1.0\n",
      "\ttau:\n",
      "tau_shape: 2.1\n",
      "tau_rate: 2.1\n",
      "\tbeta:\n",
      "beta_mean:\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "beta_cov:\n",
      "[[ 0.2  0.   0.   0.   0. ]\n",
      " [ 0.   0.2  0.   0.   0. ]\n",
      " [ 0.   0.   0.2  0.   0. ]\n",
      " [ 0.   0.   0.   0.2  0. ]\n",
      " [ 0.   0.   0.   0.   0.2]]\n",
      "\tu:\n",
      "u_mean:\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "u_var:\n",
      "[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
      "  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]\n"
     ]
    }
   ],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "glmm_par.push_param(UVNParam('mu'))\n",
    "glmm_par.push_param(GammaParam('tau'))\n",
    "glmm_par.push_param(MVNParam('beta', K))\n",
    "glmm_par.push_param(UVNParamVector('u', NG))\n",
    "\n",
    "glmm_par['mu'].mean.set(0.1)\n",
    "glmm_par['mu'].var.set(1.0)\n",
    "\n",
    "glmm_par['tau'].shape.set(2.1)\n",
    "glmm_par['tau'].rate.set(2.1)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.full(K, 0.))\n",
    "glmm_par['beta'].cov.set(0.2 * np.eye(K))\n",
    "\n",
    "glmm_par['u'].mean.set(np.full(NG, 0.))\n",
    "glmm_par['u'].var.set(np.full(NG, 0.1))\n",
    "    \n",
    "print N * NG\n",
    "print glmm_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DataLogLikelihood(x_mat, y_vec, e_beta, e_beta_outer, e_u, var_u, std_draws):\n",
    "    rho_mean = e_u + np.matmul(x_mat, e_beta)\n",
    "    rho_sd = np.sqrt(var_u + np.einsum('nk,kj,nj->n', x_mat, e_beta_outer, x_mat))\n",
    "    z = np.einsum('i,j->ij', rho_sd, std_draws) + np.expand_dims(rho_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # log(1 - p) = log(1 / (1 + exp(u))) = -log(1 + exp(u))\n",
    "    logit_term = -np.sum(np.log1p(np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * rho_mean)\n",
    "    return y_term + logit_term\n",
    "\n",
    "\n",
    "def RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau):\n",
    "    return -0.5 * e_tau * np.sum((e_mu - e_u) ** 2 + var_mu + var_u) + \\\n",
    "           0.5 * e_log_tau * len(e_u)\n",
    "\n",
    "    \n",
    "def ELogPrior(prior_par, glmm_par_elbo):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    cov_beta = glmm_par_elbo['beta'].cov.get()\n",
    "    beta_prior_info = np.linalg.inv(prior_par['beta_prior_var'].get())\n",
    "    e_log_p_beta = MVNPrior(prior_par['beta_prior_mean'].get(), beta_prior_info, e_beta, cov_beta)\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    var_mu = glmm_par_elbo['mu'].var.get()\n",
    "    e_log_p_mu = UVNPrior(prior_par['mu_prior_mean'].get(), 1 / prior_par['mu_prior_var'].get(), e_mu, var_mu) \n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    e_log_p_tau = GammaPrior(prior_par['tau_prior_alpha'].get(), prior_par['tau_prior_beta'].get(), e_tau, e_log_tau)\n",
    "    \n",
    "    return  e_log_p_beta + e_log_p_mu + e_log_p_tau\n",
    "           \n",
    "\n",
    "def Elbo(y_vec, x_mat, y_g_vec, glmm_par_elbo, std_draws, prior_par):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    cov_beta = glmm_par_elbo['beta'].cov.get()\n",
    "    e_beta_outer = glmm_par_elbo['beta'].e_outer()\n",
    "    \n",
    "    e_u = glmm_par_elbo['u'].mean.get()\n",
    "    var_u = glmm_par_elbo['u'].var.get()\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    var_mu = glmm_par_elbo['mu'].var.get()\n",
    "    \n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "\n",
    "    ll = \\\n",
    "        DataLogLikelihood(x_mat, y_vec, e_beta, e_beta_outer,\n",
    "                          e_u[y_g_vec], var_u[y_g_vec], std_draws) + \\\n",
    "        RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)\n",
    "\n",
    "    e_log_prior = ELogPrior(prior_par, glmm_par_elbo)\n",
    "        \n",
    "    entropy = \\\n",
    "        UnivariateNormalEntropy(var_mu) + \\\n",
    "        MultivariateNormalEntropy(cov_beta) + \\\n",
    "        UnivariateNormalEntropy(var_u) + \\\n",
    "        GammaEntropy(glmm_par_elbo['tau'].shape.get(), glmm_par_elbo['tau'].rate.get())\n",
    "\n",
    "    return ll[0] + e_log_prior[0] + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = sp.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.y_g_vec,\n",
    "                   self.__glmm_par_ad, self.std_draws, self.__prior_par_ad)\n",
    "        if verbose: print kl\n",
    "            \n",
    "        # TODO: this is returning an array when it should be a scalar.\n",
    "        return kl\n",
    "\n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        return self.__glmm_par_ad['beta'].mean.get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936.04894851014171"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_wrapper = KLWrapper(glmm_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMoments)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "free_par_vec = glmm_par.get_free()\n",
    "kl_wrapper.Eval(free_par_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.00170300006866\n",
      "Grad time:\n",
      "0.00758290290833\n",
      "Hessian vector product time:\n",
      "0.0122497081757\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "# so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFGS\n",
      "936.04894851\n",
      "701.325426322\n",
      "1162.00208558\n",
      "658.340124091\n",
      "593.589380967\n",
      "598.039218339\n",
      "562.806638028\n",
      "584.918328018\n",
      "560.668416946\n",
      "558.243307464\n",
      "553.994889368\n",
      "556.177902171\n",
      "552.085511979\n",
      "553.63630969\n",
      "550.597771658\n",
      "548.629990277\n",
      "545.06746098\n",
      "538.179127719\n",
      "516.623049522\n",
      "621.052240193\n",
      "512.032616641\n",
      "507.482995116\n",
      "498.962350711\n",
      "486.871271999\n",
      "512.348635113\n",
      "484.111951048\n",
      "479.710434769\n",
      "472.166122053\n",
      "467.780014566\n",
      "461.373511183\n",
      "451.290957489\n",
      "465.239446864\n",
      "448.451390612\n",
      "443.398692654\n",
      "445.409031432\n",
      "441.3342983\n",
      "437.557528884\n",
      "439.46757112\n",
      "436.085119658\n",
      "433.458877625\n",
      "432.766863832\n",
      "431.459865897\n",
      "429.77978142\n",
      "427.14762188\n",
      "425.895548828\n",
      "425.283296305\n",
      "425.158526449\n",
      "425.07372301\n",
      "425.025467822\n",
      "424.964210392\n",
      "424.861683477\n",
      "424.715491894\n",
      "424.64270358\n",
      "424.570532443\n",
      "424.510280805\n",
      "424.431868505\n",
      "424.356759579\n",
      "424.298476545\n",
      "424.228217623\n",
      "424.164562035\n",
      "424.123302086\n",
      "424.067630437\n",
      "423.980955955\n",
      "423.851751955\n",
      "423.705116492\n",
      "423.666747446\n",
      "423.614253264\n",
      "423.584072042\n",
      "423.558265912\n",
      "423.534017721\n",
      "423.498850926\n",
      "423.469642504\n",
      "423.450095298\n",
      "423.423759454\n",
      "423.412603498\n",
      "423.401882511\n",
      "423.400325358\n",
      "423.397863659\n",
      "423.394113413\n",
      "423.38867879\n",
      "423.381819774\n",
      "423.377655917\n",
      "423.375162854\n",
      "423.37438956\n",
      "423.373693225\n",
      "423.372970787\n",
      "423.371944576\n",
      "423.371356115\n",
      "423.370973937\n",
      "423.370840555\n",
      "423.370777079\n",
      "423.370727\n",
      "423.37070418\n",
      "423.370671627\n",
      "423.370658844\n",
      "423.370654985\n",
      "Running Newton Trust Region\n",
      "423.370654985\n",
      "423.370650163\n",
      "423.370649593\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "init_par_vec = free_par_vec\n",
    "\n",
    "# Optimize.\n",
    "vb_time = time.time()\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-2)\n",
    "\n",
    "init_par_vec = free_par_vec\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd, options={'maxiter': 5000})\n",
    "\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(vb_opt.x)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0275339523951\n"
     ]
    }
   ],
   "source": [
    "print vb_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the random effect estimates.  This requires simulated data.\n",
    "if False:\n",
    "    from ggplot import *\n",
    "    import pandas as pd\n",
    "    %matplotlib inline\n",
    "\n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['u'].mean.get(), 'true': true_u })\n",
    "    ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....all done dude\n"
     ]
    }
   ],
   "source": [
    "# LRVB with conjugate gradient\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "import sys\n",
    "\n",
    "# The we will actually compute Hess^1 * moment_jac.T, leading to perhaps confusing\n",
    "# naming of \"columns\".  \n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "ObjHessVecProdLO = LinearOperator((vb_opt.x.size, vb_opt.x.size), lambda par: KLHessVecProd(vb_opt.x, par))\n",
    "# print moment_jac.T.shape\n",
    "# print ObjHessVecProdLO.shape\n",
    "# cg_res, info = scipy.sparse.linalg.cg(ObjHessVecProdLO, moment_jac.T)\n",
    "\n",
    "cg_time = timeit.timeit()\n",
    "lrvb_term = np.full(moment_jac.T.shape, float('nan'))\n",
    "for col in range(moment_jac.shape[0]):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "    cg_res, info = sp.sparse.linalg.cg(ObjHessVecProdLO, moment_jac[col, :])\n",
    "    assert info == 0\n",
    "    lrvb_term[:, col] = cg_res\n",
    "cg_time = timeit.timeit() - cg_time\n",
    "\n",
    "print 'all done dude'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slow, but maybe faster than using CG.\n",
    "hess_time = timeit.timeit()\n",
    "kl_hess = KLHess(vb_opt.x)\n",
    "hess_time =  timeit.timeit() - hess_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n",
      "(5, 224)\n",
      "[ 0.01968077  0.0199127   0.02947166  0.02782511  0.03439231]\n",
      "[ 0.01968077  0.0199127   0.02947166  0.0278251   0.03439231]\n",
      "[ 0.03307707  0.03099166  0.04033834  0.03494382  0.03577844]\n"
     ]
    }
   ],
   "source": [
    "print kl_hess[:,:].shape\n",
    "print moment_jac.shape\n",
    "\n",
    "beta_cov_hess = np.matmul(moment_jac, np.linalg.solve(kl_hess[:, :], moment_jac.T))\n",
    "beta_cov = np.matmul(moment_jac, lrvb_term)\n",
    "print np.diag(beta_cov)\n",
    "print np.diag(beta_cov_hess)\n",
    "print np.diag(glmm_par_opt['beta'].cov.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LRVBLogitGLMM/LogitGLMMLRVB/inst/data/simulated_data_small_python_vb_results.json\n"
     ]
    }
   ],
   "source": [
    "result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(), 'vb_time': vb_time }\n",
    "\n",
    "result_json = json.dumps(result_dict)\n",
    "json_file = open(json_output_filename, 'w')\n",
    "json_file.write(result_json)\n",
    "json_file.close()\n",
    "\n",
    "print(json_output_filename)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
