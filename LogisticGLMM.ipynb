{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VariationalBayes import ScalarParam, ModelParamsDict, VectorParam, PosDefMatrixParam\n",
    "from VariationalBayes.NormalParams import MVNParam, UVNParam, UVNParamVector\n",
    "from VariationalBayes.GammaParams import GammaParam\n",
    "from VariationalBayes.ExponentialFamilies import \\\n",
    "    UnivariateNormalEntropy, MultivariateNormalEntropy, GammaEntropy, \\\n",
    "    MVNPrior, UVNPrior, GammaPrior\n",
    "\n",
    "\n",
    "from autograd import grad, hessian, jacobian, hessian_vector_product\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy as asp\n",
    "import scipy as sp\n",
    "\n",
    "import copy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'y_group', u'mu_prior_var', u'mu_prior_t', u'mu_prior_var_c', u'K', u'beta_prior_var', u'tau_prior_beta', u'N', u'mu_prior_mean_c', u'mu_prior_epsilon', u'mu_prior_mean', u'y', u'x', u'NG', u'beta_prior_mean', u'tau_prior_alpha']\n",
      "1000\n",
      "0.324\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "import os\n",
    "import json\n",
    "\n",
    "simulate_data = False\n",
    "prior_par = ModelParamsDict('Prior Parameters')\n",
    "\n",
    "if not simulate_data:\n",
    "    analysis_name = 'simulated_data_small'\n",
    "    #analysis_name = 'simulated_data_large'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'], 'LRVBLogitGLMM/LogitGLMMLRVB/inst/data/')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    json_output_filename = os.path.join(data_dir, '%s_python_vb_results.json' % analysis_name)\n",
    "\n",
    "    json_file = open(json_filename, 'r')\n",
    "    stan_dat = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    print stan_dat.keys()\n",
    "    K = stan_dat['K'][0]\n",
    "    NObs = stan_dat['N'][0]\n",
    "    NG = stan_dat['NG'][0]\n",
    "    N = NObs / NG\n",
    "    y_g_vec = np.array(stan_dat['y_group'])\n",
    "    y_vec = np.array(stan_dat['y'])\n",
    "    x_mat = np.array(stan_dat['x'])\n",
    "    \n",
    "    # Define a class to contain prior parameters.\n",
    "    prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.array(stan_dat['beta_prior_mean'])))\n",
    "    prior_par.push_param(PosDefMatrixParam('beta_prior_var', K, val=np.array(stan_dat['beta_prior_var'])))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('mu_prior_mean', val=stan_dat['mu_prior_mean'][0]))\n",
    "    prior_par.push_param(ScalarParam('mu_prior_var', val=stan_dat['mu_prior_var'][0]))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('tau_prior_alpha', val=stan_dat['tau_prior_alpha'][0]))\n",
    "    prior_par.push_param(ScalarParam('tau_prior_beta', val=stan_dat['tau_prior_beta'][0]))\n",
    "\n",
    "    # An index set to make sure jacobians match the order expected by R.\n",
    "    prior_par_indices = copy.deepcopy(prior_par)\n",
    "    prior_par_indices.set_name('Prior Indices')\n",
    "    prior_par_indices.set_vector(np.array(range(prior_par_indices.vector_size())))\n",
    "else:\n",
    "    # Simulate data instead of loading it if you like\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    # Generate data\n",
    "    def Logistic(u):\n",
    "        return np.exp(u) / (1 + np.exp(u))\n",
    "\n",
    "    NObs = NG * N\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "    true_u = np.random.normal(true_mu, 1 / np.sqrt(true_tau), NG)\n",
    "\n",
    "    x_mat = np.random.random(K * NObs).reshape(NObs, K) - 0.5\n",
    "    y_g_vec = [ g for g in range(NG) for n in range(N) ]\n",
    "    true_rho = Logistic(np.matmul(x_mat, true_beta) + true_u[y_g_vec])\n",
    "    y_vec = np.random.random(NObs) < true_rho\n",
    "    \n",
    "    prior_par.push_param(VectorParam('beta_prior_mean', K, val=np.zeros(K)))\n",
    "    prior_par.push_param(PosDefMatrixParam('beta_prior_var', K, val=10 * np.eye(K)))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('mu_prior_mean', val=0))\n",
    "    prior_par.push_param(ScalarParam('mu_prior_var', val=2))\n",
    "\n",
    "    prior_par.push_param(ScalarParam('tau_prior_alpha', val=3.0))\n",
    "    prior_par.push_param(ScalarParam('tau_prior_beta', val=10.0))\n",
    "\n",
    "print N * NG\n",
    "print np.mean(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build an object to contain a variational approximation to a K-dimensional multivariate normal.\n",
    "glmm_par = ModelParamsDict('GLMM Parameters')\n",
    "\n",
    "glmm_par.push_param(UVNParam('mu'))\n",
    "glmm_par.push_param(GammaParam('tau'))\n",
    "glmm_par.push_param(MVNParam('beta', K))\n",
    "glmm_par.push_param(UVNParamVector('u', NG))\n",
    "\n",
    "glmm_par['mu'].mean.set(0.1)\n",
    "glmm_par['mu'].info.set(1.0)\n",
    "\n",
    "glmm_par['tau'].shape.set(2.1)\n",
    "glmm_par['tau'].rate.set(2.1)\n",
    "\n",
    "glmm_par['beta'].mean.set(np.full(K, 0.))\n",
    "glmm_par['beta'].info.set(np.eye(K) / 20)\n",
    "\n",
    "glmm_par['u'].mean.set(np.full(NG, 0.))\n",
    "glmm_par['u'].info.set(np.full(NG, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define moment parameters\n",
    "\n",
    "moment_par = ModelParamsDict('Moment Parameters')\n",
    "moment_par.push_param(VectorParam('e_beta', K))\n",
    "moment_par.push_param(PosDefMatrixParam('e_beta_outer', K))\n",
    "moment_par.push_param(ScalarParam('e_mu'))\n",
    "moment_par.push_param(ScalarParam('e_mu2'))\n",
    "moment_par.push_param(ScalarParam('e_tau'))\n",
    "moment_par.push_param(ScalarParam('e_log_tau'))\n",
    "moment_par.push_param(VectorParam('e_u', NG))\n",
    "moment_par.push_param(VectorParam('e_u2', NG))\n",
    "\n",
    "def set_moments(glmm_par, moment_par):\n",
    "    moment_par['e_beta'].set(glmm_par['beta'].e())\n",
    "    moment_par['e_beta_outer'].set(glmm_par['beta'].e_outer())\n",
    "    moment_par['e_mu'].set(glmm_par['mu'].e())\n",
    "    moment_par['e_mu2'].set(glmm_par['mu'].e_outer())\n",
    "    moment_par['e_tau'].set(glmm_par['tau'].e())\n",
    "    moment_par['e_log_tau'].set(glmm_par['tau'].e_log())\n",
    "    moment_par['e_u'].set(glmm_par['u'].e())\n",
    "    moment_par['e_u2'].set((glmm_par['u'].e_outer()))\n",
    "    \n",
    "set_moments(glmm_par, moment_par)\n",
    "\n",
    "# Moment indices.\n",
    "moment_indices = copy.deepcopy(moment_par)\n",
    "moment_indices.set_vector(1 + np.array(range(moment_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_combined_parameters(combined_free_par_vec, glmm_par, prior_par):\n",
    "    assert glmm_par.free_size() + prior_par.vector_size() == len(combined_free_par_vec) \n",
    "    glmm_par.set_free(combined_free_par_vec[0:glmm_par.free_size()])\n",
    "    prior_par.set_vector(combined_free_par_vec[glmm_par.free_size():])\n",
    "\n",
    "    \n",
    "def encode_combined_parameters(glmm_par, prior_par):\n",
    "    combined_free_par_vec = np.full(glmm_par.free_size() + prior_par.vector_size(), float('nan'))\n",
    "    combined_free_par_vec[0:glmm_par.free_size()] = glmm_par.get_free()\n",
    "    combined_free_par_vec[glmm_par.free_size():] = prior_par.get_vector()\n",
    "    return combined_free_par_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510.57620581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-4.0182527520990901"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ELogPrior(prior_par, glmm_par_elbo):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "    beta_prior_info = np.linalg.inv(prior_par['beta_prior_var'].get())\n",
    "    beta_prior_mean = prior_par['beta_prior_mean'].get()\n",
    "    e_log_p_beta = MVNPrior(beta_prior_mean, beta_prior_info, e_beta, cov_beta)\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "    e_log_p_mu = UVNPrior(prior_par['mu_prior_mean'].get(), 1 / prior_par['mu_prior_var'].get(), e_mu, var_mu) \n",
    "\n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    tau_prior_shape = prior_par['tau_prior_alpha'].get()\n",
    "    tau_prior_rate = prior_par['tau_prior_beta'].get()\n",
    "    e_log_p_tau = GammaPrior(tau_prior_shape, tau_prior_rate, e_tau, e_log_tau)\n",
    "    \n",
    "    return  e_log_p_beta + e_log_p_mu + e_log_p_tau\n",
    "           \n",
    "\n",
    "def DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta, e_u, var_u, std_draws):\n",
    "    z_mean = e_u + np.matmul(x_mat, e_beta)\n",
    "    z_sd = np.sqrt(var_u + np.einsum('nk,kj,nj->n', x_mat, cov_beta, x_mat))\n",
    "    z = np.einsum('i,j->ij', z_sd, std_draws) + np.expand_dims(z_mean, 1)\n",
    "\n",
    "    # The sum is over observations and draws, so dividing by the draws size\n",
    "    # gives the sum of sample expectations over the draws.\n",
    "    # p = exp(z) / (1 + exp(z))\n",
    "    # log(1 - p) = log(1 / (1 + exp(z))) = -log(1 + exp(z))\n",
    "    logit_term = -np.sum(np.log1p(np.exp(z))) / std_draws.size\n",
    "    y_term = np.sum(y_vec * z_mean)\n",
    "    return y_term + logit_term\n",
    "\n",
    "\n",
    "def RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau):\n",
    "    return -0.5 * e_tau * np.sum(((e_mu - e_u) ** 2) + var_mu + var_u) + 0.5 * e_log_tau * len(e_u)\n",
    "\n",
    "    \n",
    "def Elbo(y_vec, x_mat, y_g_vec, glmm_par_elbo, std_draws, prior_par):\n",
    "    e_beta = glmm_par_elbo['beta'].mean.get()\n",
    "    info_beta = glmm_par_elbo['beta'].info.get()\n",
    "    cov_beta = np.linalg.inv(info_beta)\n",
    "    \n",
    "    e_u = glmm_par_elbo['u'].mean.get()\n",
    "    info_u = glmm_par_elbo['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    \n",
    "    e_mu = glmm_par_elbo['mu'].mean.get()\n",
    "    info_mu = glmm_par_elbo['mu'].info.get()\n",
    "    var_mu = 1 / info_mu\n",
    "    \n",
    "    e_tau = glmm_par_elbo['tau'].e()\n",
    "    e_log_tau = glmm_par_elbo['tau'].e_log()\n",
    "    \n",
    "    ll = \\\n",
    "        DataLogLikelihood(x_mat, y_vec, e_beta, cov_beta,\n",
    "                          e_u[y_g_vec], var_u[y_g_vec], std_draws) + \\\n",
    "        RandomEffectLogLikelihood(e_u, var_u, e_mu, var_mu, e_tau, e_log_tau)\n",
    "\n",
    "    e_log_prior = ELogPrior(prior_par, glmm_par_elbo)\n",
    "    \n",
    "    tau_shape = glmm_par_elbo['tau'].shape.get()\n",
    "    tau_rate = glmm_par_elbo['tau'].rate.get()\n",
    "    entropy = \\\n",
    "        UnivariateNormalEntropy(info_mu) + \\\n",
    "        MultivariateNormalEntropy(info_beta) + \\\n",
    "        UnivariateNormalEntropy(info_u) + \\\n",
    "        GammaEntropy(tau_shape, tau_rate)\n",
    "\n",
    "    return ll[0] + e_log_prior[0] + entropy\n",
    "\n",
    "\n",
    "class KLWrapper():\n",
    "    def __init__(self, glmm_par, moment_par, prior_par, x_mat, y_vec, y_g_vec, num_draws):\n",
    "        self.__glmm_par_ad = copy.deepcopy(glmm_par)\n",
    "        self.__moment_par = copy.deepcopy(moment_par)\n",
    "        self.__prior_par_ad = copy.deepcopy(prior_par)\n",
    "        self.x_mat = x_mat\n",
    "        self.y_vec = y_vec\n",
    "        self.y_g_vec = y_g_vec\n",
    "        draw_spacing = 1 / float(num_draws + 1)\n",
    "        target_quantiles = np.linspace(draw_spacing, 1 - draw_spacing, num_draws)\n",
    "        self.std_draws = sp.stats.norm.ppf(target_quantiles)\n",
    "\n",
    "    def Eval(self, free_par_vec, verbose=False):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        kl = -Elbo(self.y_vec, self.x_mat, self.y_g_vec,\n",
    "                   self.__glmm_par_ad, self.std_draws, self.__prior_par_ad)\n",
    "        if verbose: print kl\n",
    "            \n",
    "        # TODO: this is returning an array when it should be a scalar.\n",
    "        return kl\n",
    "    \n",
    "    def ExpectedLogPrior(self, combined_free_par_vec):\n",
    "        # Encode the glmm parameters first and the prior second.\n",
    "        decode_combined_parameters(combined_free_par_vec, self.__glmm_par_ad, self.__prior_par_ad)\n",
    "        e_log_prior = ELogPrior(self.__prior_par_ad, self.__glmm_par_ad)\n",
    "        return e_log_prior[0]\n",
    "        \n",
    "    # Return a posterior moment of interest as a function of\n",
    "    # unconstrained parameters.  In this case it is a bit silly,\n",
    "    # but in full generality posterior moments may be a complicated\n",
    "    # function of moment parameters.\n",
    "    def GetMoments(self, free_par_vec):\n",
    "        self.__glmm_par_ad.set_free(free_par_vec)\n",
    "        set_moments(self.__glmm_par_ad, self.__moment_par)\n",
    "        return self.__moment_par.get_vector()\n",
    "\n",
    "\n",
    "# TODO: get the log prior derivatives, too.\n",
    "    \n",
    "kl_wrapper = KLWrapper(glmm_par, moment_par, prior_par, x_mat, y_vec, y_g_vec, 10)\n",
    "KLGrad = grad(kl_wrapper.Eval)\n",
    "KLHess = hessian(kl_wrapper.Eval)\n",
    "MomentJacobian = jacobian(kl_wrapper.GetMoments)\n",
    "KLHessVecProd = hessian_vector_product(kl_wrapper.Eval)  \n",
    "free_par_vec = glmm_par.get_free()\n",
    "print kl_wrapper.Eval(free_par_vec)\n",
    "\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par, prior_par)\n",
    "PriorHess = hessian(kl_wrapper.ExpectedLogPrior)\n",
    "kl_wrapper.ExpectedLogPrior(combined_free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function time:\n",
      "0.00111980438232\n",
      "Grad time:\n",
      "0.00724110603333\n",
      "Hessian vector product time:\n",
      "0.0112826824188\n",
      "Moment jacobian time:\n",
      "0.275002884865\n",
      "Prior Hessian time:\n",
      "1.14284586906\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "print 'Function time:'\n",
    "print timeit.timeit(lambda: kl_wrapper.Eval(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Grad time:'\n",
    "print timeit.timeit(lambda: KLGrad(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "print 'Hessian vector product time:'\n",
    "print timeit.timeit(lambda: KLHessVecProd(free_par_vec, free_par_vec + 1), number=time_num) / time_num\n",
    "\n",
    "print 'Moment jacobian time:'\n",
    "print timeit.timeit(lambda: MomentJacobian(free_par_vec), number=time_num) / time_num\n",
    "\n",
    "time_num = 1\n",
    "print 'Prior Hessian time:'\n",
    "print timeit.timeit(lambda: PriorHess(combined_free_par_vec), number=time_num) / time_num\n",
    "\n",
    "# so slow\n",
    "# print 'Hessian time:'\n",
    "# print timeit.timeit(lambda: KLHess(free_par_vec), number=time_num) / time_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFGS\n",
      "2510.58125581\n",
      "2040.58097081\n",
      "1349.01022072\n",
      "811.550590708\n",
      "1548.70726251\n",
      "681.978486144\n",
      "753.996632598\n",
      "630.174862822\n",
      "567.969199502\n",
      "463.177871467\n",
      "316.609258581\n",
      "505.19654637\n",
      "280.205351773\n",
      "293.608626559\n",
      "273.313156887\n",
      "260.327159263\n",
      "238.470451433\n",
      "220.785269558\n",
      "202.383385417\n",
      "174.095881405\n",
      "149.980245473\n",
      "157.846120279\n",
      "144.681592189\n",
      "137.766991078\n",
      "126.182131319\n",
      "114.960414265\n",
      "117.317774619\n",
      "110.187341948\n",
      "101.719193349\n",
      "101.358924037\n",
      "100.641097565\n",
      "97.9657846192\n",
      "92.3908164077\n",
      "88.1288098056\n",
      "81.4398091022\n",
      "78.3171351843\n",
      "73.5748009003\n",
      "69.0995126894\n",
      "70.6346494375\n",
      "67.2598302639\n",
      "68.7315202264\n",
      "66.6108739468\n",
      "65.6388043489\n",
      "64.219560144\n",
      "62.6466928964\n",
      "61.7057551878\n",
      "60.7316566753\n",
      "59.8469956811\n",
      "59.3204072841\n",
      "59.0094407467\n",
      "58.8866617861\n",
      "58.7759157941\n",
      "58.7209728396\n",
      "58.6664397431\n",
      "58.5971762296\n",
      "58.4916839048\n",
      "58.3638874433\n",
      "58.2583471524\n",
      "58.166266301\n",
      "58.1065310915\n",
      "58.0732231176\n",
      "58.0478572107\n",
      "58.0401061358\n",
      "58.0350871781\n",
      "58.0318172496\n",
      "58.0298659616\n",
      "58.0290876906\n",
      "58.0287741811\n",
      "58.0285930706\n",
      "58.0284018722\n",
      "58.0281224795\n",
      "58.0276840314\n",
      "58.0270013328\n",
      "58.0259627815\n",
      "58.0244657416\n",
      "58.0220580067\n",
      "58.0180765341\n",
      "58.0113806052\n",
      "58.0001152988\n",
      "57.9815112112\n",
      "57.9520813605\n",
      "57.9091576177\n",
      "57.86128917\n",
      "57.810599329\n",
      "57.7790039449\n",
      "57.7612232191\n",
      "57.7560353879\n",
      "57.7477514863\n",
      "57.7391719365\n",
      "57.7361472522\n",
      "57.7317463156\n",
      "57.7281591011\n",
      "57.7250783599\n",
      "57.7236458453\n",
      "57.7232317544\n",
      "57.7231155571\n",
      "57.7229542281\n",
      "57.7228627908\n",
      "57.7228193405\n",
      "57.7227958481\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 57.722796\n",
      "         Iterations: 90\n",
      "         Function evaluations: 100\n",
      "         Gradient evaluations: 100\n",
      "Running Newton Trust Region\n",
      "57.7227958481\n",
      "57.7227779933\n",
      "57.722775543\n",
      "57.7227731572\n",
      "57.7227731566\n",
      "57.7227731565\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 57.722773\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "         Hessian evaluations: 0\n",
      "Done.\n",
      "0.0640934348106\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "init_par_vec = free_par_vec\n",
    "\n",
    "# Optimize.\n",
    "vb_time = time.time()\n",
    "print 'Running BFGS'\n",
    "vb_opt_bfgs = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True), init_par_vec,\n",
    "    method='bfgs', jac=KLGrad, tol=1e-2, options={'maxiter': 5000, 'disp': True})\n",
    "\n",
    "init_par_vec = free_par_vec\n",
    "print 'Running Newton Trust Region'\n",
    "vb_opt = optimize.minimize(\n",
    "    lambda par: kl_wrapper.Eval(par, verbose=True),\n",
    "    vb_opt_bfgs.x, method='trust-ncg', jac=KLGrad, hessp=KLHessVecProd,\n",
    "    tol=1e-8, options={'maxiter': 5000, 'disp': True})\n",
    "\n",
    "vb_time = time.time() - vb_time\n",
    "\n",
    "glmm_par_opt = copy.deepcopy(glmm_par)\n",
    "glmm_par_opt.set_free(vb_opt.x)\n",
    "moment_jac = MomentJacobian(vb_opt.x)\n",
    "\n",
    "print 'Done.'\n",
    "\n",
    "print vb_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(glmm_par_opt)\n",
    "if simulate_data:\n",
    "    print true_beta\n",
    "    print glmm_par_opt['beta']\n",
    "    print '---------------\\n'\n",
    "    print true_tau\n",
    "    print glmm_par_opt['tau'].e()\n",
    "\n",
    "    e_u = glmm_par_opt['u'].e()\n",
    "    info_u = glmm_par_opt['u'].info.get()\n",
    "    var_u = 1 / info_u\n",
    "    e_beta = glmm_par_opt['beta'].e()\n",
    "    e_beta_outer = glmm_par_opt['beta'].e_outer()\n",
    "    std_draws = kl_wrapper.std_draws\n",
    "\n",
    "    rho_mean = e_u[y_g_vec] + np.matmul(x_mat, e_beta)\n",
    "    rho_sd = np.sqrt(var_u[y_g_vec] + np.einsum('nk,kj,nj->n', x_mat, e_beta_outer, x_mat))\n",
    "    z = np.einsum('i,j->ij', rho_sd, std_draws) + np.expand_dims(rho_mean, 1)\n",
    "    logit_term = -np.einsum('ij->i', np.log1p(np.exp(z))) / std_draws.size\n",
    "\n",
    "    print rho_sd\n",
    "    print var_u[y_g_vec]\n",
    "    # print np.mean(var_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the random effect estimates.  This requires simulated data.\n",
    "if simulate_data:\n",
    "    from ggplot import *\n",
    "    import pandas as pd\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print glmm_par_opt['mu'].e()\n",
    "    print true_mu\n",
    "\n",
    "    print glmm_par_opt['tau'].e()\n",
    "    print true_tau\n",
    "\n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['u'].mean.get(), 'true': true_u })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "    \n",
    "    plot_df = pd.DataFrame({ 'opt': glmm_par_opt['beta'].mean.get(), 'true': true_beta })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)\n",
    "    \n",
    "    plot_df = pd.DataFrame({ 'opt': logit_term, 'true': np.log(1 - true_rho) })\n",
    "    print ggplot(plot_df, aes(x='true', y='opt')) + geom_point() + geom_abline(slope=1, intercept=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LRVB with conjugate gradient.  This turns out to be way slower with any appreciable number of moments.\n",
    "if False:\n",
    "    from scipy.sparse.linalg import LinearOperator\n",
    "    import sys\n",
    "\n",
    "    # This will actually compute Hess^1 * moment_jac.T, leading to perhaps confusing\n",
    "    # naming of \"columns\".  \n",
    "    ObjHessVecProdLO = LinearOperator((vb_opt.x.size, vb_opt.x.size), lambda par: KLHessVecProd(vb_opt.x, par))\n",
    "    # print moment_jac.T.shape\n",
    "    # print ObjHessVecProdLO.shape\n",
    "    # cg_res, info = scipy.sparse.linalg.cg(ObjHessVecProdLO, moment_jac.T)\n",
    "\n",
    "    cg_time = time.time()\n",
    "    lrvb_term = np.full(moment_jac.T.shape, float('nan'))\n",
    "    for col in range(moment_jac.shape[0]):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        cg_res, info = sp.sparse.linalg.cg(ObjHessVecProdLO, moment_jac[col, :])\n",
    "        assert info == 0\n",
    "        lrvb_term[:, col] = cg_res\n",
    "    cg_time = time.time() - cg_time\n",
    "\n",
    "    print 'all done dude'\n",
    "else:\n",
    "    cg_time = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess_time: 2.305816\n",
      "cg_time: inf\n"
     ]
    }
   ],
   "source": [
    "# Slow, but probably faster than using CG.\n",
    "combined_free_par_vec = encode_combined_parameters(glmm_par_opt, prior_par)\n",
    "\n",
    "hess_time = time.time()\n",
    "kl_hess = KLHess(vb_opt.x)\n",
    "log_prior_hess_full = PriorHess(combined_free_par_vec)\n",
    "hess_time =  time.time() - hess_time\n",
    "elbo_hess = -kl_hess\n",
    "\n",
    "print 'hess_time: %f' % hess_time\n",
    "print 'cg_time: %f' % cg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0658141036401503e-13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(np.matmul(kl_hess, vb_opt.x + 1) - KLHessVecProd(vb_opt.x, vb_opt.x + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glmm_inds = range(glmm_par_opt.free_size())\n",
    "prior_inds = range(glmm_par_opt.free_size(), len(combined_free_par_vec))\n",
    "log_prior_hess = log_prior_hess_full[np.ix_(prior_inds, glmm_inds)]\n",
    "\n",
    "lrvb_cov = np.matmul(moment_jac, np.linalg.solve(kl_hess, moment_jac.T))\n",
    "\n",
    "prior_indices = copy.deepcopy(prior_par)\n",
    "prior_indices.set_vector(1 + np.array(range(prior_indices.vector_size())))\n",
    "\n",
    "vp_indices = copy.deepcopy(glmm_par_opt)\n",
    "vp_indices.set_vector(1 + np.array(range(vp_indices.vector_size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LRVBLogitGLMM/LogitGLMMLRVB/inst/data/simulated_data_small_python_vb_results.json\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    result_dict = { 'glmm_par_opt': glmm_par_opt.dictval(),\n",
    "                    'vb_time': vb_time,'hess_time': hess_time, \n",
    "                    'moment_indices': moment_indices.dictval(),\n",
    "                    'prior_indices': prior_indices.dictval(),\n",
    "                    'vp_indices': vp_indices.dictval(),\n",
    "                    'lrvb_cov': lrvb_cov.tolist(), 'moment_jac': moment_jac.tolist(),\n",
    "                    'elbo_hess': elbo_hess.tolist(), 'log_prior_hess': log_prior_hess.tolist() }\n",
    "\n",
    "    result_json = json.dumps(result_dict)\n",
    "    json_file = open(json_output_filename, 'w')\n",
    "    json_file.write(result_json)\n",
    "    json_file.close()\n",
    "\n",
    "    print(json_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.30063600e-02   1.05473262e-01   2.28656174e-01   3.50253562e-01\n",
      "   4.87453346e-01   2.61203387e-01   5.08504430e-01   1.96533403e+00\n",
      "   1.43620015e+00   3.65776899e+00   1.27208868e+01   2.50044698e+00\n",
      "   6.03095355e+00   1.67345539e+01   3.25545766e+01   3.83653282e+00\n",
      "   9.40550610e+00   2.56254424e+01   4.34688050e+01   7.09154116e+01\n",
      "   2.50931187e-01   1.69695071e+01   2.86234272e-02   1.72868261e-01\n",
      "   1.51244484e+00   2.07011365e+00   1.09815161e+00   2.39214402e+00\n",
      "   1.30190736e+00   2.00574061e+00   2.32762503e+00   2.20052591e+00\n",
      "   1.56725779e+00   1.61145713e+00   1.45661745e+00   1.66237941e+00\n",
      "   1.59060585e+00   1.42100028e+00   2.61919680e+00   1.10515671e+00\n",
      "   1.66010222e+00   2.29470636e+00   1.92665766e+00   1.75140265e+00\n",
      "   1.26756160e+00   2.31915347e+00   1.06228088e+00   2.65344357e+00\n",
      "   1.21267775e+00   2.09622145e+00   1.28455082e+00   1.68451221e+00\n",
      "   1.90548724e+00   1.25875793e+00   1.32346485e+00   1.49871783e+00\n",
      "   1.31778853e+00   2.04719978e+00   1.77371270e+00   2.12915764e+00\n",
      "   2.10632590e+00   2.13395081e+00   2.17787661e+00   1.67161015e+00\n",
      "   2.15952626e+00   1.75757090e+00   1.31030641e+00   1.97839459e+00\n",
      "   1.55479335e+00   1.83652838e+00   8.80382784e-01   1.20379030e+00\n",
      "   1.42631190e+00   2.10108345e+00   1.44553008e+00   1.47273009e+00\n",
      "   1.03005575e+00   1.49988250e+00   1.38741205e+00   1.07136339e+00\n",
      "   1.37254758e+00   1.32534793e+00   2.58110824e+00   1.62502270e+00\n",
      "   1.19263586e+00   1.93234447e+00   2.67257999e+00   1.30214590e+00\n",
      "   1.40436626e+00   1.44150287e+00   1.74044069e+00   1.47094215e+00\n",
      "   9.65098052e-01   2.02237622e+00   1.22501971e+00   1.33336334e+00\n",
      "   1.39818337e+00   2.09742179e+00   1.53865944e+00   1.39610923e+00\n",
      "   1.33040676e+00   9.92099501e-01   2.16002311e+00   1.96921653e+00\n",
      "   1.79800576e+00   2.23481269e+00   1.60821152e+00   1.49838956e+00\n",
      "   1.48979799e+00   1.77915099e+00   1.53749549e+00   1.17394553e+00\n",
      "   2.08385173e+00   2.41552863e+00   1.41871104e+00   1.98790015e+00\n",
      "   1.35973383e+00   1.72327363e+00   1.64233450e+00   1.35225991e+00\n",
      "   1.37064381e+00   1.36368717e+00   1.20678392e+00   1.21467031e+00\n",
      "   6.39273337e+01   1.50774805e+02   8.80288663e+01   3.40999800e+02\n",
      "   8.79716097e+01   1.95447844e+02   1.94123457e+02   1.95605292e+02\n",
      "   4.36705714e+01   1.04847579e+02   4.40853871e+01   8.72117803e+01\n",
      "   1.28484427e+02   1.18414154e+02   1.94891927e+02   4.81784579e+01\n",
      "   8.99515324e+01   2.76700818e+02   1.71962618e+02   6.90833814e+01\n",
      "   3.07845843e+01   1.87250830e+02   7.92087299e+01   4.10467191e+02\n",
      "   6.43343339e+01   2.66264360e+02   9.63727161e+01   1.22998973e+02\n",
      "   9.68456542e+01   4.81596726e+01   9.33458931e+01   7.39330372e+01\n",
      "   9.03665653e+01   2.03730444e+02   8.33836350e+01   4.24024355e+02\n",
      "   1.84594369e+02   1.95216606e+02   2.33527959e+02   9.84730920e+01\n",
      "   1.82049024e+02   1.18118988e+02   4.75483070e+01   2.69239437e+02\n",
      "   1.75456474e+02   1.97691230e+02   3.96604455e+01   9.71272075e+01\n",
      "   7.01016622e+01   1.43107636e+02   8.54374988e+01   1.47147768e+02\n",
      "   5.57268639e+01   1.21631003e+02   8.97596014e+01   3.22406061e+01\n",
      "   6.88379897e+01   1.31703123e+02   4.34925369e+02   7.68178273e+01\n",
      "   7.67246999e+01   1.40657219e+02   1.99695639e+02   7.46954000e+01\n",
      "   9.80349963e+01   2.19767765e+01   1.61091497e+02   1.29473163e+02\n",
      "   2.14339369e+01   1.64305194e+02   1.02657922e+02   1.30817113e+02\n",
      "   9.03267603e+01   3.78067969e+02   1.45974445e+02   5.05069382e+01\n",
      "   1.18724210e+02   4.71150290e+01   1.93568542e+02   2.31007614e+02\n",
      "   8.41545136e+01   2.84080234e+02   1.55378904e+02   7.50938847e+01\n",
      "   1.16894103e+02   8.26712983e+01   1.11645958e+02   2.78698836e+01\n",
      "   2.05836658e+02   3.26979348e+02   1.02723904e+02   2.21955595e+02\n",
      "   5.66528642e+01   8.05008886e+01   1.43354966e+02   1.03033987e+02\n",
      "   1.03578286e+02   1.17645180e+02   8.35614102e+01   5.59011878e+01]\n"
     ]
    }
   ],
   "source": [
    "set_moments(glmm_par_opt, moment_par)\n",
    "print np.diag(lrvb_cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
